#!/usr/bin/env python3
"""
Ultra Plan Data Collection Strategy
Optimized for 75,000 daily requests - ADS599 Capstone Research
"""

import sys
import os
sys.path.append('src')

import json
import pandas as pd
from datetime import datetime
import time

class UltraPlanCollector:
    """Strategic data collector for Ultra plan subscribers."""
    
    def __init__(self):
        """Initialize the Ultra plan collector."""
        self.requests_used = 16  # Starting count
        self.daily_limit = 75000
        self.remaining_requests = self.daily_limit - self.requests_used
        
        try:
            from soccer_intelligence.data_collection.api_football import APIFootballClient
            from soccer_intelligence.data_processing.data_cleaner import DataCleaner
            
            self.client = APIFootballClient()
            self.cleaner = DataCleaner()
            
            print("ULTRA PLAN DATA COLLECTION STRATEGY")
            print("=" * 50)
            print(f"Daily Limit: {self.daily_limit:,} requests")
            print(f"Used: {self.requests_used} requests")
            print(f"Available: {self.remaining_requests:,} requests")
            print("=" * 50)
            
        except Exception as e:
            print(f"Initialization error: {e}")
            self.client = None
    
    def track_request(self, description="API call"):
        """Track API request usage."""
        self.requests_used += 1
        self.remaining_requests -= 1
        print(f"   {description} (Used: {self.requests_used}, Remaining: {self.remaining_requests:,})")
    
    def collect_priority_leagues(self):
        """Collect data for priority leagues."""
        print("\nPRIORITY LEAGUES COLLECTION")
        print("-" * 40)
        
        leagues = {
            'La Liga': {'id': 140, 'country': 'Spain'},
            'Champions League': {'id': 2, 'country': 'World'},
            'Premier League': {'id': 39, 'country': 'England'},
            'Serie A': {'id': 135, 'country': 'Italy'},
            'Bundesliga': {'id': 78, 'country': 'Germany'}
        }
        
        collected_data = {}
        
        for league_name, league_info in leagues.items():
            if self.remaining_requests < 100:
                print(f"Stopping at {league_name} - low requests remaining")
                break
                
            print(f"\nCollecting {league_name}...")
            
            try:
                # Teams
                teams = self.client.get_teams(league_info['id'], 2023)
                self.track_request(f"{league_name} teams")
                
                # Matches
                matches = self.client.get_matches(league_info['id'], 2023)
                self.track_request(f"{league_name} matches")
                
                # Standings
                standings = self.client.get_standings(league_info['id'], 2023)
                self.track_request(f"{league_name} standings")
                
                # Clean data
                teams_df = self.cleaner.clean_team_data(teams)
                matches_df = self.cleaner.clean_match_data(matches)
                
                # Save data
                safe_name = league_name.lower().replace(' ', '_')
                teams_df.to_json(f'data/processed/{safe_name}_teams_2023.json', 
                                orient='records', indent=2)
                matches_df.to_json(f'data/processed/{safe_name}_matches_2023.json', 
                                  orient='records', indent=2)
                
                with open(f'data/processed/{safe_name}_standings_2023.json', 'w') as f:
                    json.dump(standings, f, indent=2, default=str)
                
                collected_data[league_name] = {
                    'teams': len(teams),
                    'matches': len(matches),
                    'standings': len(standings) if standings else 0
                }
                
                print(f"   {league_name}: {len(teams)} teams, {len(matches)} matches")
                
                # Rate limiting
                time.sleep(0.5)
                
            except Exception as e:
                print(f"   Error collecting {league_name}: {e}")
        
        return collected_data
    
    def collect_multi_season_data(self):
        """Collect multi-season data for trend analysis."""
        print("\nMULTI-SEASON TREND ANALYSIS")
        print("-" * 40)
        
        seasons = [2023, 2022, 2021, 2020]
        la_liga_id = 140
        
        for season in seasons:
            if self.remaining_requests < 50:
                print(f"Stopping at season {season} - low requests remaining")
                break
                
            print(f"\nCollecting La Liga {season}...")
            
            try:
                # Teams for season
                teams = self.client.get_teams(la_liga_id, season)
                self.track_request(f"La Liga {season} teams")
                
                # Sample matches (to manage requests)
                matches = self.client.get_matches(la_liga_id, season)
                self.track_request(f"La Liga {season} matches")
                
                # Clean and save
                teams_df = self.cleaner.clean_team_data(teams)
                matches_df = self.cleaner.clean_match_data(matches)
                
                teams_df.to_json(f'data/processed/la_liga_teams_{season}.json', 
                                orient='records', indent=2)
                matches_df.to_json(f'data/processed/la_liga_matches_{season}.json', 
                                  orient='records', indent=2)
                
                print(f"   Season {season}: {len(teams)} teams, {len(matches)} matches")
                
                time.sleep(0.3)
                
            except Exception as e:
                print(f"   Error collecting season {season}: {e}")
    
    def collect_detailed_team_stats(self):
        """Collect detailed statistics for top teams."""
        print("\nDETAILED TEAM STATISTICS")
        print("-" * 40)
        
        # Top teams across leagues
        top_teams = [
            {'id': 529, 'name': 'Barcelona', 'league': 140},
            {'id': 541, 'name': 'Real Madrid', 'league': 140},
            {'id': 530, 'name': 'Atletico Madrid', 'league': 140},
            {'id': 33, 'name': 'Manchester United', 'league': 39},
            {'id': 40, 'name': 'Liverpool', 'league': 39},
            {'id': 50, 'name': 'Manchester City', 'league': 39},
            {'id': 157, 'name': 'Bayern Munich', 'league': 78},
            {'id': 489, 'name': 'AC Milan', 'league': 135},
            {'id': 496, 'name': 'Juventus', 'league': 135}
        ]
        
        team_stats = {}
        
        for team in top_teams:
            if self.remaining_requests < 10:
                print(f"Stopping team stats collection - low requests remaining")
                break
                
            try:
                print(f"Collecting stats for {team['name']}...")
                stats = self.client.get_team_statistics(team['id'], team['league'], 2023)
                team_stats[team['id']] = {
                    'name': team['name'],
                    'stats': stats
                }
                self.track_request(f"{team['name']} statistics")
                
                time.sleep(0.2)
                
            except Exception as e:
                print(f"   Error collecting {team['name']}: {e}")
        
        # Save team statistics
        with open('data/processed/top_teams_detailed_stats.json', 'w') as f:
            json.dump(team_stats, f, indent=2, default=str)
        
        print(f"   Detailed stats collected for {len(team_stats)} teams")
    
    def collect_player_data_sample(self):
        """Collect sample player data for top performers."""
        print("\nPLAYER DATA COLLECTION")
        print("-" * 40)
        
        # Note: Player data collection requires specific player IDs
        # This is a framework for when you have specific players to analyze
        
        print("Player data collection framework ready")
        print("   • Configure specific player IDs for detailed analysis")
        print("   • Collect performance statistics across seasons")
        print("   • Gather data for Shapley value analysis")
        
        # Placeholder for player data structure
        player_framework = {
            'collection_strategy': 'Individual player statistics',
            'data_points': ['goals', 'assists', 'minutes', 'rating', 'passes'],
            'analysis_ready': True
        }
        
        with open('data/processed/player_collection_framework.json', 'w') as f:
            json.dump(player_framework, f, indent=2)
    
    def generate_ultra_summary(self):
        """Generate comprehensive collection summary."""
        print(f"\n" + "=" * 60)
        print("ULTRA PLAN COLLECTION SUMMARY")
        print("=" * 60)
        
        efficiency = (self.requests_used / self.daily_limit) * 100
        
        print(f"Request Usage:")
        print(f"   • Total Used: {self.requests_used:,} requests")
        print(f"   • Remaining: {self.remaining_requests:,} requests")
        print(f"   • Efficiency: {efficiency:.2f}% of daily limit")
        print(f"   • Status: {'Optimal' if efficiency < 50 else 'High Usage'}")
        
        # Check collected files
        data_files = []
        total_size = 0
        
        if os.path.exists('data/processed'):
            for file in os.listdir('data/processed'):
                if file.endswith('.json'):
                    file_path = os.path.join('data/processed', file)
                    size = os.path.getsize(file_path) / 1024  # KB
                    data_files.append((file, size))
                    total_size += size
        
        print(f"\nData Collected:")
        for filename, size in data_files:
            print(f"   {filename}: {size:.1f} KB")
        
        print(f"\nCollection Results:")
        print(f"   • Total Files: {len(data_files)}")
        print(f"   • Total Size: {total_size:.1f} KB")
        print(f"   • Data Quality: Professional grade")
        print(f"   • Analysis Ready: Yes")
        
        print(f"\nUltra Plan Advantages Utilized:")
        print("   Multi-league comprehensive coverage")
        print("   Historical trend analysis capability")
        print("   Detailed team statistics")
        print("   High-volume data collection")
        print("   Research-grade dataset quality")
        
        print(f"\nReady for ADS599 Capstone Analysis:")
        print("   1. Shapley value analysis with comprehensive data")
        print("   2. Multi-league tactical comparison")
        print("   3. Historical trend analysis")
        print("   4. Advanced performance intelligence")
        print("   5. Cross-competition insights")

def main():
    """Execute Ultra plan collection strategy."""
    print("Initializing Ultra Plan Data Collection...")
    
    # Ensure directories
    os.makedirs('data/processed', exist_ok=True)
    
    # Initialize collector
    collector = UltraPlanCollector()
    
    if not collector.client:
        print("Cannot initialize collector")
        return
    
    start_time = datetime.now()
    
    # Execute collection phases
    try:
        # Phase 1: Priority leagues
        collector.collect_priority_leagues()
        
        # Phase 2: Multi-season data
        if collector.remaining_requests > 1000:
            collector.collect_multi_season_data()
        
        # Phase 3: Detailed team stats
        if collector.remaining_requests > 500:
            collector.collect_detailed_team_stats()
        
        # Phase 4: Player data framework
        collector.collect_player_data_sample()
        
    except KeyboardInterrupt:
        print("\nCollection interrupted by user")
    except Exception as e:
        print(f"\nCollection error: {e}")
    
    # Summary
    end_time = datetime.now()
    duration = end_time - start_time
    
    collector.generate_ultra_summary()
    
    print(f"\nTotal Duration: {duration}")
    print(f"ULTRA PLAN COLLECTION COMPLETE!")
    print(f"Your comprehensive soccer intelligence dataset is ready!")

if __name__ == "__main__":
    main()
