{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Soccer_Performance_Score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 | Combine 2 seasons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found CSV files: ['/Users/mariamoramora/Documents/GitHub/ADS599_Capstone/Soccer_Performance_Score/data/real_madrid/real_madrid_23_24.csv', '/Users/mariamoramora/Documents/GitHub/ADS599_Capstone/Soccer_Performance_Score/data/real_madrid/real_madrid_24_25.csv']\n",
      "\n",
      "File: /Users/mariamoramora/Documents/GitHub/ADS599_Capstone/Soccer_Performance_Score/data/real_madrid/real_madrid_23_24.csv\n",
      "Shape: (774, 73)\n",
      "Columns: ['Date', 'Competition', 'Opponent', 'Player', '#', 'Nation', 'Pos', 'Age', 'Min', ' Gls', ' Ast', ' PK', ' PKatt', ' Sh', ' SoT', ' CrdY', ' CrdR', ' Touches', ' Tkl', ' Int', ' Blocks', 'Expected xG', 'Expected npxG', 'Expected xAG', 'SCA', 'GCA', 'Passes Cmp', 'Passes Att', 'Passes Cmp%', 'Passes PrgP', 'Carries Carries', 'Carries PrgC', 'Take-Ons Att', 'Take-Ons Succ', 'Tackles Tkl', 'Tackles TklW', 'Tackles Def 3rd', 'Tackles Mid 3rd', 'Tackles Att 3rd', 'Challenges Tkl', 'Challenges Att', 'Challenges Tkl%', 'Challenges Lost', 'Blocks Blocks', 'Blocks Sh', 'Blocks Pass', 'Int', 'Tkl+Int', 'Clr', 'Err', 'Total Cmp', 'Total Att', 'Total Cmp%', 'Total TotDist', 'Total PrgDist', 'Short Cmp', 'Short Att', 'Short Cmp%', 'Medium Cmp', 'Medium Att', 'Medium Cmp%', 'Long Cmp', 'Long Att', 'Long Cmp%', 'Ast', 'xAG', 'xA', 'KP', ' 1/3', 'PPA', 'CrsPA', 'PrgP', 'Match URL']\n",
      "\n",
      "File: /Users/mariamoramora/Documents/GitHub/ADS599_Capstone/Soccer_Performance_Score/data/real_madrid/real_madrid_24_25.csv\n",
      "Shape: (776, 73)\n",
      "Columns: ['Date', 'Competition', 'Opponent', 'Player', '#', 'Nation', 'Pos', 'Age', 'Min', ' Gls', ' Ast', ' PK', ' PKatt', ' Sh', ' SoT', ' CrdY', ' CrdR', ' Int', ' Touches', ' Tkl', ' Blocks', 'Expected xG', 'Expected npxG', 'Expected xAG', 'SCA', 'GCA', 'Passes Cmp', 'Passes Att', 'Passes Cmp%', 'Passes PrgP', 'Carries Carries', 'Carries PrgC', 'Take-Ons Att', 'Take-Ons Succ', 'Tackles Tkl', 'Tackles TklW', 'Tackles Def 3rd', 'Tackles Mid 3rd', 'Tackles Att 3rd', 'Challenges Tkl', 'Challenges Att', 'Challenges Tkl%', 'Challenges Lost', 'Blocks Blocks', 'Blocks Sh', 'Blocks Pass', 'Int', 'Tkl+Int', 'Clr', 'Err', 'Total Cmp', 'Total Att', 'Total Cmp%', 'Total TotDist', 'Total PrgDist', 'Short Cmp', 'Short Att', 'Short Cmp%', 'Medium Cmp', 'Medium Att', 'Medium Cmp%', 'Long Cmp', 'Long Att', 'Long Cmp%', 'Ast', 'xAG', 'xA', 'KP', ' 1/3', 'PPA', 'CrsPA', 'PrgP', 'Match URL']\n",
      "\n",
      "Combined DataFrame Shape (before removing duplicates): (1550, 73)\n",
      "Removed 0 duplicate rows\n",
      "Final DataFrame Shape: (1550, 73)\n",
      "Combined DataFrame Columns: ['Date', 'Competition', 'Opponent', 'Player', '#', 'Nation', 'Pos', 'Age', 'Min', ' Gls', ' Ast', ' PK', ' PKatt', ' Sh', ' SoT', ' CrdY', ' CrdR', ' Touches', ' Tkl', ' Int', ' Blocks', 'Expected xG', 'Expected npxG', 'Expected xAG', 'SCA', 'GCA', 'Passes Cmp', 'Passes Att', 'Passes Cmp%', 'Passes PrgP', 'Carries Carries', 'Carries PrgC', 'Take-Ons Att', 'Take-Ons Succ', 'Tackles Tkl', 'Tackles TklW', 'Tackles Def 3rd', 'Tackles Mid 3rd', 'Tackles Att 3rd', 'Challenges Tkl', 'Challenges Att', 'Challenges Tkl%', 'Challenges Lost', 'Blocks Blocks', 'Blocks Sh', 'Blocks Pass', 'Int', 'Tkl+Int', 'Clr', 'Err', 'Total Cmp', 'Total Att', 'Total Cmp%', 'Total TotDist', 'Total PrgDist', 'Short Cmp', 'Short Att', 'Short Cmp%', 'Medium Cmp', 'Medium Att', 'Medium Cmp%', 'Long Cmp', 'Long Att', 'Long Cmp%', 'Ast', 'xAG', 'xA', 'KP', ' 1/3', 'PPA', 'CrsPA', 'PrgP', 'Match URL']\n",
      "\n",
      "Head of combined DataFrame:\n",
      "      Date Competition       Opponent           Player   #   Nation Pos  \\\n",
      "0  8/12/23     La Liga  Athletic Club  Vinicius JÃºnior   7   br BRA  FW   \n",
      "1  8/12/23     La Liga  Athletic Club      Luka ModriÄ‡  10   hr CRO  FW   \n",
      "2  8/12/23     La Liga  Athletic Club          Rodrygo  11   br BRA  FW   \n",
      "3  8/12/23     La Liga  Athletic Club           Joselu  14   es ESP  FW   \n",
      "4  8/12/23     La Liga  Athletic Club  Jude Bellingham   5  eng ENG  AM   \n",
      "\n",
      "      Age  Min   Gls  ...  Long Cmp%  Ast  xAG   xA  KP   1/3  PPA  CrsPA  \\\n",
      "0  23-031   79     0  ...      100.0    0  0.0  0.1   0     1    1      0   \n",
      "1  37-337   11     0  ...      100.0    0  0.0  0.2   0     4    1      0   \n",
      "2  22-215   79     1  ...        NaN    0  0.1  0.1   2     2    4      0   \n",
      "3  33-138   11     0  ...        NaN    0  0.1  0.1   1     0    0      0   \n",
      "4  20-044   90     1  ...        0.0    0  0.1  0.0   1     4    2      0   \n",
      "\n",
      "   PrgP                                          Match URL  \n",
      "0     2  https://fbref.com/en/matches/c31f0a31/Athletic...  \n",
      "1     3  https://fbref.com/en/matches/c31f0a31/Athletic...  \n",
      "2     5  https://fbref.com/en/matches/c31f0a31/Athletic...  \n",
      "3     0  https://fbref.com/en/matches/c31f0a31/Athletic...  \n",
      "4     6  https://fbref.com/en/matches/c31f0a31/Athletic...  \n",
      "\n",
      "[5 rows x 73 columns]\n",
      "\n",
      "Combined CSV saved to: /Users/mariamoramora/Documents/GitHub/ADS599_Capstone/Soccer_Performance_Score/data/real_madrid_combined/combined_real_madrid.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "# Set the directory path\n",
    "data_dir = \"/Users/mariamoramora/Documents/GitHub/ADS599_Capstone/Soccer_Performance_Score/data/real_madrid\"\n",
    "\n",
    "# Get all CSV files in the directory\n",
    "csv_files = []\n",
    "for file in os.listdir(data_dir):\n",
    "    if file.endswith('.csv'):\n",
    "        csv_files.append(os.path.join(data_dir, file))\n",
    "\n",
    "print(f\"Found CSV files: {csv_files}\")\n",
    "\n",
    "# Read and combine all CSV files\n",
    "dataframes = []\n",
    "for file in csv_files:\n",
    "    df = pd.read_csv(file)\n",
    "    print(f\"\\nFile: {file}\")\n",
    "    print(f\"Shape: {df.shape}\")\n",
    "    print(f\"Columns: {list(df.columns)}\")\n",
    "    dataframes.append(df)\n",
    "\n",
    "# Combine all dataframes\n",
    "if len(dataframes) == 2:\n",
    "    # If the CSV files have the same structure, use concat\n",
    "    combined_df = pd.concat(dataframes, ignore_index=True)\n",
    "    \n",
    "    # Alternative: if you want to merge on a common column instead\n",
    "    # combined_df = pd.merge(dataframes[0], dataframes[1], on='common_column', how='outer')\n",
    "    \n",
    "elif len(dataframes) > 2:\n",
    "    # For more than 2 files\n",
    "    combined_df = pd.concat(dataframes, ignore_index=True)\n",
    "else:\n",
    "    combined_df = dataframes[0] if dataframes else pd.DataFrame()\n",
    "\n",
    "print(f\"\\nCombined DataFrame Shape (before removing duplicates): {combined_df.shape}\")\n",
    "\n",
    "# Remove duplicates\n",
    "initial_shape = combined_df.shape[0]\n",
    "combined_df = combined_df.drop_duplicates()\n",
    "final_shape = combined_df.shape[0]\n",
    "\n",
    "print(f\"Removed {initial_shape - final_shape} duplicate rows\")\n",
    "print(f\"Final DataFrame Shape: {combined_df.shape}\")\n",
    "print(f\"Combined DataFrame Columns: {list(combined_df.columns)}\")\n",
    "\n",
    "# Display the head of the combined dataframe\n",
    "print(\"\\nHead of combined DataFrame:\")\n",
    "print(combined_df.head())\n",
    "\n",
    "# Create output directory and save the combined dataframe\n",
    "output_dir = \"/Users/mariamoramora/Documents/GitHub/ADS599_Capstone/Soccer_Performance_Score/data/real_madrid_combined\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Save the combined dataframe to the new folder\n",
    "output_file = os.path.join(output_dir, 'combined_real_madrid.csv')\n",
    "combined_df.to_csv(output_file, index=False)\n",
    "\n",
    "print(f\"\\nCombined CSV saved to: {output_file}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create weighted metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== HANDLING DUPLICATES ===\n",
      "Initial dataset shape: (1550, 73)\n",
      "Removed 0 exact duplicate rows\n",
      "Final dataset shape: (1550, 73)\n",
      "=== DATASET COLUMN ANALYSIS ===\n",
      "Total columns: 75\n",
      "Column names: ['Date', 'Competition', 'Opponent', 'Player', 'number', 'Nation', 'Pos', 'Age', 'Min', ' Gls', ' Ast', ' PK', ' PKatt', ' Sh', ' SoT', ' CrdY', ' CrdR', ' Touches', ' Tkl', ' Int', ' Blocks', 'Expected xG', 'Expected npxG', 'Expected xAG', 'SCA', 'GCA', 'Passes Cmp', 'Passes Att', 'Passes Cmp%', 'Passes PrgP', 'Carries Carries', 'Carries PrgC', 'Take-Ons Att', 'Take-Ons Succ', 'Tackles Tkl', 'Tackles TklW', 'Tackles Def 3rd', 'Tackles Mid 3rd', 'Tackles Att 3rd', 'Challenges Tkl', 'Challenges Att', 'Challenges Tkl%', 'Challenges Lost', 'Blocks Blocks', 'Blocks Sh', 'Blocks Pass', 'Int', 'Tkl+Int', 'Clr', 'Err', 'Total Cmp', 'Total Att', 'Total Cmp%', 'Total TotDist', 'Total PrgDist', 'Short Cmp', 'Short Att', 'Short Cmp%', 'Medium Cmp', 'Medium Att', 'Medium Cmp%', 'Long Cmp', 'Long Att', 'Long Cmp%', 'Ast', 'xAG', 'xA', 'KP', ' 1/3', 'PPA', 'CrsPA', 'PrgP', 'Match URL', 'Season', 'Position_Group']\n",
      "\n",
      "Found these numeric columns: ['Int', 'Clr', 'Total Cmp%', 'Long Cmp%', 'Passes PrgP', 'Carries PrgC', 'SCA', 'KP', 'Ast', ' Gls', ' Sh', ' SoT', 'Take-Ons Att', 'Take-Ons Succ', 'Expected xG', 'Total Att', 'Min', 'Total Cmp', 'Total TotDist', 'Total PrgDist']\n",
      "Renamed columns: {' Gls': 'Gls', ' Ast': 'Ast', ' PK': 'PK', ' PKatt': 'PKatt', ' Sh': 'Sh', ' SoT': 'SoT', ' CrdY': 'CrdY', ' CrdR': 'CrdR', ' Touches': 'Touches', ' Tkl': 'Tkl', ' Int': 'Int', ' Blocks': 'Blocks', ' 1/3': '1/3'}\n",
      "\n",
      "Final check - Key columns available:\n",
      "âœ“ Gls\n",
      "âœ“ Ast\n",
      "âœ“ Sh\n",
      "âœ“ SoT\n",
      "âœ“ Min\n",
      "âœ“ Tkl\n",
      "âœ“ Int\n",
      "\n",
      "Processing Forward players...\n",
      "Found 211 Forward records\n",
      "  - Processing 211 forward records\n",
      "  - Available columns: Gls=True, Ast=True, Sh=True\n",
      "  - Min values shape: (211,)\n",
      "  - Goals values shape: (211,)\n",
      "  - Error processing assists: arg must be a list, tuple, 1-d array, or Series\n",
      "  - Completed forward scoring. Score range: 0.0 - 42.0\n",
      "âœ“ Successfully calculated scores for Forward\n",
      "\n",
      "Processing Midfield players...\n",
      "Found 410 Midfield records\n",
      "âœ— Error processing Midfield: operands could not be broadcast together with shapes (820,) (410,) \n",
      "\n",
      "Processing Defense players...\n",
      "Found 483 Defense records\n",
      "âœ— Error processing Defense: operands could not be broadcast together with shapes (966,) (483,) \n",
      "\n",
      "Processing Goalkeeper players...\n",
      "Found 104 Goalkeeper records\n",
      "âœ“ Successfully calculated scores for Goalkeeper\n",
      "\n",
      "Completed performance score calculation. Score range: 0.0 - 100.0\n",
      "Error creating season position summary: 'DataFrame' object has no attribute 'name'\n",
      "Error creating player season summary: 'DataFrame' object has no attribute 'name'\n",
      "\n",
      "=== REAL MADRID PERFORMANCE SCORING SYSTEM ===\n",
      "Top 10 Players by Average Performance Score:\n",
      "           Player Position_Group  Season  Avg_Performance_Score\n",
      "             Fran     Goalkeeper 2024-25              89.000000\n",
      "     Andriy Lunin     Goalkeeper 2024-25              81.517778\n",
      " Thibaut Courtois     Goalkeeper 2023-24              79.888000\n",
      "Kepa Arrizabalaga     Goalkeeper 2023-24              74.402222\n",
      "     Andriy Lunin     Goalkeeper 2023-24              73.327586\n",
      " Thibaut Courtois     Goalkeeper 2024-25              68.973810\n",
      "  Antonio RÃ¼diger        Defense 2023-24              50.000000\n",
      "  Antonio RÃ¼diger        Defense 2024-25              50.000000\n",
      "       Arda GÃ¼ler       Midfield 2023-24              50.000000\n",
      "       Arda GÃ¼ler       Midfield 2024-25              50.000000\n",
      "\n",
      "\n",
      "=== SUMMARY BY SEASON AND POSITION ===\n",
      " Season Position_Group  Avg_Performance\n",
      "2023-24        Defense        50.000000\n",
      "2023-24        Forward         4.701409\n",
      "2023-24     Goalkeeper        74.330385\n",
      "2023-24       Midfield        50.000000\n",
      "2024-25        Defense        50.000000\n",
      "2024-25        Forward         6.879834\n",
      "2024-25     Goalkeeper        71.530000\n",
      "2024-25       Midfield        50.000000\n",
      "\n",
      "\n",
      "=== TOP PERFORMERS BY SEASON ===\n",
      "\n",
      "2023-24 Season - Top 5 Performers:\n",
      "           Player Position_Group  Avg_Performance_Score\n",
      " Thibaut Courtois     Goalkeeper              79.888000\n",
      "Kepa Arrizabalaga     Goalkeeper              74.402222\n",
      "     Andriy Lunin     Goalkeeper              73.327586\n",
      "  Antonio RÃ¼diger        Defense              50.000000\n",
      "       Arda GÃ¼ler       Midfield              50.000000\n",
      "\n",
      "2024-25 Season - Top 5 Performers:\n",
      "          Player Position_Group  Avg_Performance_Score\n",
      "            Fran     Goalkeeper              89.000000\n",
      "    Andriy Lunin     Goalkeeper              81.517778\n",
      "Thibaut Courtois     Goalkeeper              68.973810\n",
      " Antonio RÃ¼diger        Defense              50.000000\n",
      "      Arda GÃ¼ler       Midfield              50.000000\n",
      "\n",
      "\n",
      "=== POSITION ANALYSIS ACROSS SEASONS ===\n",
      "Season          2023-24  2024-25\n",
      "Position_Group                  \n",
      "Defense           50.00    50.00\n",
      "Forward            4.70     6.88\n",
      "Goalkeeper        74.33    71.53\n",
      "Midfield          50.00    50.00\n",
      "âœ“ Enhanced dataset saved: /Users/mariamoramora/Documents/GitHub/ADS599_Capstone/Soccer_Performance_Score/data/real_madrid_combined/real_madrid_enhanced_complete.csv\n",
      "âœ“ Season-Position summary saved: /Users/mariamoramora/Documents/GitHub/ADS599_Capstone/Soccer_Performance_Score/data/real_madrid_combined/summary_by_season_position.csv\n",
      "âœ“ Player summary saved: /Users/mariamoramora/Documents/GitHub/ADS599_Capstone/Soccer_Performance_Score/data/real_madrid_combined/player_summary_by_season.csv\n",
      "âœ“ Position analysis saved: /Users/mariamoramora/Documents/GitHub/ADS599_Capstone/Soccer_Performance_Score/data/real_madrid_combined/position_performance_across_seasons.csv\n",
      "\n",
      "=== DATASET INFO ===\n",
      "Total records in enhanced dataset: 1550\n",
      "Seasons covered: ['2023-24', '2024-25']\n",
      "Position groups: {'Defense': 483, 'Midfield': 410, 'Forward': 211, 'Goalkeeper': 104}\n",
      "Unique players: 37\n",
      "\n",
      "=== SAMPLE OF ENHANCED DATASET ===\n",
      "      Date  Season              Player Position_Group  Performance_Score  Min  Gls  Ast  Ast\n",
      "2023-08-12 2023-24     Vinicius JÃºnior        Forward           4.329114   79    0    0    0\n",
      "2023-08-12 2023-24         Luka ModriÄ‡        Forward          14.545455   11    0    0    0\n",
      "2023-08-12 2023-24             Rodrygo        Forward           3.291139   79    1    0    0\n",
      "2023-08-12 2023-24              Joselu        Forward           0.000000   11    0    0    0\n",
      "2023-08-12 2023-24     Jude Bellingham       Midfield          50.000000   90    1    0    0\n",
      "2023-08-12 2023-24   Eduardo Camavinga       Midfield          50.000000   70    0    0    0\n",
      "2023-08-12 2023-24          Toni Kroos       Midfield          50.000000   20    0    0    0\n",
      "2023-08-12 2023-24   Federico Valverde       Midfield          50.000000   90    0    0    0\n",
      "2023-08-12 2023-24 AurÃ©lien TchouamÃ©ni       Midfield          50.000000   90    0    0    0\n",
      "2023-08-12 2023-24         Fran Garcia        Defense          50.000000   90    0    0    0\n",
      "2023-08-12 2023-24         David Alaba        Defense          50.000000   90    0    1    1\n",
      "2023-08-12 2023-24        Ã‰der MilitÃ£o        Defense          50.000000   49    0    0    0\n",
      "2023-08-12 2023-24     Antonio RÃ¼diger        Defense          50.000000   41    0    0    0\n",
      "2023-08-12 2023-24       Dani Carvajal        Defense          50.000000   90    0    1    1\n",
      "2023-08-12 2023-24        Andriy Lunin     Goalkeeper          87.620000   90    0    0    0\n",
      "\n",
      "ðŸ† REAL MADRID PERFORMANCE ANALYSIS COMPLETE! ðŸ†\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/qw/jyz61sns2534v_vwqrk2t1nc0000gn/T/ipykernel_54811/1318013363.py:446: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '[ 4.32911392 14.54545455  3.29113924  0.          6.61516854  6.66666667\n",
      "  7.26760563  3.5        10.          0.          8.88383838  4.\n",
      "  5.22222222  1.97674419  0.         16.39344262 10.11111111  3.61111111\n",
      "  3.55555556  0.44444444  4.16666667  8.83928571  3.92156863  9.12790698\n",
      " 10.          0.         10.86956522  8.20137694  0.          1.14864865\n",
      "  0.          7.21126761  4.47368421  4.22222222  3.70689655  0.\n",
      "  1.53846154  0.          4.61111111  3.92857143  0.          0.28089888\n",
      "  0.         10.56451613  5.17857143  6.66666667  4.88888889 15.98684211\n",
      "  0.         12.42165242  0.          9.96969697 12.88311688  0.38888889\n",
      "  0.         10.93023256 15.29411765  9.58333333  0.          0.07246377\n",
      "  6.47222222  6.64556962  0.          6.22222222  8.27777778 11.00401606\n",
      "  0.          2.84019975  0.          6.4         0.          6.31961259\n",
      "  0.          6.22222222  5.11111111  2.66666667  0.          5.04054054\n",
      "  8.75        6.7816092   0.          1.26666667 11.21428571  7.\n",
      "  0.          9.30555556  0.          3.76811594  6.66666667  0.96385542\n",
      "  2.85714286 13.94444444  5.17977528 10.          0.          3.33333333\n",
      "  4.9086758   3.82352941  9.70833333  0.          3.55633803  0.\n",
      "  2.54901961  0.          0.61111111  5.          8.85802469  0.\n",
      "  0.          0.          6.66666667  0.          4.83333333  2.77777778\n",
      "  7.11111111  7.125       2.44444444  8.88888889 12.66666667  2.83333333\n",
      "  2.94444444  5.22222222  0.          7.38888889 11.05882353 42.\n",
      "  8.         13.4939759  35.          6.43258427  0.         10.83333333\n",
      "  9.22222222 11.79746835  2.24806202  1.25        7.55555556 12.32142857\n",
      " 10.          8.01282051  2.92857143  5.33950617  4.13483146 10.\n",
      "  2.03968254  4.66666667  7.3015873  12.61111111  6.11111111  2.5\n",
      "  9.18292683  6.47222222  0.          6.38888889  0.          6.3030303\n",
      "  5.77777778  4.63218391  0.          4.125       0.         16.85714286\n",
      "  2.91666667  7.05555556  3.33333333 12.66666667 11.80952381  0.25\n",
      "  0.          3.05555556  7.66666667  7.27777778  5.66666667  8.10861423\n",
      " 11.86507937  4.84269663  0.         21.75324675  0.          6.95238095\n",
      "  5.          2.5         2.66666667  3.72222222 11.83333333 11.19230769\n",
      "  0.          3.23934837  0.          1.42857143  8.88888889  0.\n",
      " 12.28571429  6.25        8.5         0.33333333  8.          0.\n",
      "  3.33333333 10.34246575  0.          8.53174603 10.          1.58730159\n",
      " 12.44444444 10.61111111  7.05479452  4.70588235  8.44444444  0.87719298\n",
      " 12.44444444]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  df.loc[original_indices, 'Performance_Score'] = subset['Performance_Score'].values\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "\n",
    "# Load your combined Real Madrid data\n",
    "df = pd.read_csv('/Users/mariamoramora/Documents/GitHub/ADS599_Capstone/Soccer_Performance_Score/data/real_madrid_combined/combined_real_madrid.csv')\n",
    "\n",
    "# Check for and handle duplicates\n",
    "print(\"=== HANDLING DUPLICATES ===\")\n",
    "print(f\"Initial dataset shape: {df.shape}\")\n",
    "initial_count = len(df)\n",
    "\n",
    "# Remove exact duplicate rows\n",
    "df_no_duplicates = df.drop_duplicates()\n",
    "duplicates_removed = initial_count - len(df_no_duplicates)\n",
    "print(f\"Removed {duplicates_removed} exact duplicate rows\")\n",
    "\n",
    "# Reset index to avoid duplicate index issues\n",
    "df = df_no_duplicates.reset_index(drop=True)\n",
    "print(f\"Final dataset shape: {df.shape}\")\n",
    "\n",
    "# Convert Date to datetime and add Season\n",
    "df['Date'] = pd.to_datetime(df['Date'], format='%m/%d/%y')\n",
    "df['Season'] = df['Date'].apply(lambda x: \n",
    "    f\"{x.year}-{str(x.year + 1)[-2:]}\" if x.month >= 8 \n",
    "    else f\"{x.year - 1}-{str(x.year)[-2:]}\"\n",
    ")\n",
    "\n",
    "# Position grouping\n",
    "position_mapping = {\n",
    "    'GK': 'Goalkeeper',\n",
    "    'CB': 'Defense', 'LB': 'Defense', 'RB': 'Defense',\n",
    "    'DM': 'Midfield', 'CM': 'Midfield', 'LM': 'Midfield', 'RM': 'Midfield', 'AM': 'Midfield',\n",
    "    'FW': 'Forward'\n",
    "}\n",
    "df['Position_Group'] = df['Pos'].map(position_mapping)\n",
    "\n",
    "# First, let's check what columns we actually have\n",
    "print(\"=== DATASET COLUMN ANALYSIS ===\")\n",
    "print(f\"Total columns: {len(df.columns)}\")\n",
    "print(f\"Column names: {list(df.columns)}\")\n",
    "\n",
    "# Handle missing values and convert to numeric - check if columns exist first\n",
    "potential_numeric_columns = ['Tkl', 'Int', 'Blocks', 'Clr', 'Total Cmp%', 'Long Cmp%', 'Passes PrgP', \n",
    "                            'Carries PrgC', 'SCA', 'KP', 'Ast', 'Gls', ' Gls', 'Sh', ' Sh', 'SoT', ' SoT',\n",
    "                            'Take-Ons Att', 'Take-Ons Succ', 'Expected xG', 'Total Att', 'Min', ' Min',\n",
    "                            'Total Cmp', 'Total TotDist', 'Total PrgDist']\n",
    "\n",
    "# Find which columns actually exist (handle spaces in column names)\n",
    "existing_numeric_columns = []\n",
    "for col in potential_numeric_columns:\n",
    "    if col in df.columns:\n",
    "        existing_numeric_columns.append(col)\n",
    "\n",
    "print(f\"\\nFound these numeric columns: {existing_numeric_columns}\")\n",
    "\n",
    "# Convert existing columns to numeric\n",
    "for col in existing_numeric_columns:\n",
    "    df[col] = pd.to_numeric(df[col], errors='coerce').fillna(0)\n",
    "\n",
    "# Create standardized column names (remove leading spaces)\n",
    "column_mapping = {}\n",
    "for col in df.columns:\n",
    "    clean_col = col.strip()\n",
    "    if col != clean_col:\n",
    "        column_mapping[col] = clean_col\n",
    "\n",
    "if column_mapping:\n",
    "    df.rename(columns=column_mapping, inplace=True)\n",
    "    print(f\"Renamed columns: {column_mapping}\")\n",
    "\n",
    "# Now check for the key columns we need\n",
    "required_columns = ['Gls', 'Ast', 'Tkl', 'Int', 'Blocks', 'SCA', 'KP', 'Sh', 'SoT', 'Min']\n",
    "missing_columns = []\n",
    "for col in required_columns:\n",
    "    if col not in df.columns:\n",
    "        missing_columns.append(col)\n",
    "        df[col] = 0  # Create missing columns with zeros\n",
    "\n",
    "if missing_columns:\n",
    "    print(f\"Created missing columns with zeros: {missing_columns}\")\n",
    "\n",
    "# Calculate Take-on Success Rate - check if columns exist\n",
    "if 'Take-Ons Att' in df.columns and 'Take-Ons Succ' in df.columns:\n",
    "    df['Take-Ons Succ%'] = np.where(df['Take-Ons Att'] > 0, \n",
    "                                    (df['Take-Ons Succ'] / df['Take-Ons Att'] * 100), 0)\n",
    "else:\n",
    "    df['Take-Ons Succ%'] = 0\n",
    "    print(\"Take-on columns not found, setting Take-Ons Succ% to 0\")\n",
    "\n",
    "# Check for alternate column names that might exist\n",
    "alternate_names = {\n",
    "    'Gls': [' Gls', 'Goals', 'G'],\n",
    "    'Ast': [' Ast', 'Assists', 'A'], \n",
    "    'Sh': [' Sh', 'Shots', 'Shot'],\n",
    "    'SoT': [' SoT', 'Shots on Target', 'ShotsonTarget'],\n",
    "    'Min': [' Min', 'Minutes', 'Playing Time'],\n",
    "    'Tkl': [' Tkl', 'Tackles'],\n",
    "    'Int': [' Int', 'Interceptions'],\n",
    "    'SCA': [' SCA', 'Shot Creating Actions'],\n",
    "    'KP': [' KP', 'Key Passes']\n",
    "}\n",
    "\n",
    "# Map alternate column names\n",
    "for standard_name, alternates in alternate_names.items():\n",
    "    if standard_name not in df.columns:\n",
    "        for alt_name in alternates:\n",
    "            if alt_name in df.columns:\n",
    "                df[standard_name] = df[alt_name]\n",
    "                print(f\"Mapped {alt_name} to {standard_name}\")\n",
    "                break\n",
    "\n",
    "print(f\"\\nFinal check - Key columns available:\")\n",
    "for col in ['Gls', 'Ast', 'Sh', 'SoT', 'Min', 'Tkl', 'Int']:\n",
    "    status = \"âœ“\" if col in df.columns else \"âœ—\"\n",
    "    print(f\"{status} {col}\")\n",
    "\n",
    "# GOALKEEPER PERFORMANCE SCORE\n",
    "def calculate_gk_score(df_gk):\n",
    "    if df_gk.empty:\n",
    "        return df_gk\n",
    "    \n",
    "    # Reset index to ensure no duplicates\n",
    "    df_gk = df_gk.reset_index(drop=True).copy()\n",
    "    \n",
    "    # Normalize metrics (0-100 scale)\n",
    "    df_gk['GK_Distribution'] = np.where(df_gk['Total Cmp%'] > 0, df_gk['Total Cmp%'], 0)\n",
    "    df_gk['GK_LongBall'] = np.where(df_gk['Long Cmp%'] > 0, df_gk['Long Cmp%'], 0)\n",
    "    \n",
    "    # Weighted score\n",
    "    df_gk['Performance_Score'] = (\n",
    "        df_gk['GK_Distribution'] * 0.6 +  # 60% - Distribution accuracy\n",
    "        df_gk['GK_LongBall'] * 0.4       # 40% - Long ball accuracy\n",
    "    )\n",
    "    \n",
    "    return df_gk\n",
    "\n",
    "# DEFENSE PERFORMANCE SCORE\n",
    "def calculate_def_score(df_def):\n",
    "    if df_def.empty:\n",
    "        return df_def\n",
    "    \n",
    "    # Reset index to ensure no duplicates\n",
    "    df_def = df_def.reset_index(drop=True).copy()\n",
    "    \n",
    "    # Check if required columns exist, use 0 if not\n",
    "    tkl_col = 'Tkl' if 'Tkl' in df_def.columns else None\n",
    "    int_col = 'Int' if 'Int' in df_def.columns else None\n",
    "    blocks_col = 'Blocks' if 'Blocks' in df_def.columns else None\n",
    "    clr_col = 'Clr' if 'Clr' in df_def.columns else None\n",
    "    pass_acc_col = 'Total Cmp%' if 'Total Cmp%' in df_def.columns else None\n",
    "    \n",
    "    # Convert to numpy arrays and ensure they're 1D\n",
    "    min_values = np.array(df_def['Min']).flatten()\n",
    "    \n",
    "    # Normalize per 90 minutes using numpy operations\n",
    "    if tkl_col is not None:\n",
    "        tkl_values = np.array(df_def[tkl_col]).flatten()\n",
    "        df_def['Tkl_per90'] = np.where(min_values > 0, tkl_values / min_values * 90, 0)\n",
    "    else:\n",
    "        df_def['Tkl_per90'] = 0\n",
    "        \n",
    "    if int_col is not None:\n",
    "        int_values = np.array(df_def[int_col]).flatten()\n",
    "        df_def['Int_per90'] = np.where(min_values > 0, int_values / min_values * 90, 0)\n",
    "    else:\n",
    "        df_def['Int_per90'] = 0\n",
    "        \n",
    "    if blocks_col is not None:\n",
    "        blocks_values = np.array(df_def[blocks_col]).flatten()\n",
    "        df_def['Blocks_per90'] = np.where(min_values > 0, blocks_values / min_values * 90, 0)\n",
    "    else:\n",
    "        df_def['Blocks_per90'] = 0\n",
    "        \n",
    "    if clr_col is not None:\n",
    "        clr_values = np.array(df_def[clr_col]).flatten()\n",
    "        df_def['Clr_per90'] = np.where(min_values > 0, clr_values / min_values * 90, 0)\n",
    "    else:\n",
    "        df_def['Clr_per90'] = 0\n",
    "    \n",
    "    # Scale to 0-100\n",
    "    max_tkl = df_def['Tkl_per90'].max() if df_def['Tkl_per90'].max() > 0 else 1\n",
    "    max_int = df_def['Int_per90'].max() if df_def['Int_per90'].max() > 0 else 1\n",
    "    max_blocks = df_def['Blocks_per90'].max() if df_def['Blocks_per90'].max() > 0 else 1\n",
    "    max_clr = df_def['Clr_per90'].max() if df_def['Clr_per90'].max() > 0 else 1\n",
    "    \n",
    "    df_def['DEF_Tackles'] = (df_def['Tkl_per90'] / max_tkl * 100)\n",
    "    df_def['DEF_Interceptions'] = (df_def['Int_per90'] / max_int * 100)\n",
    "    df_def['DEF_Blocks'] = (df_def['Blocks_per90'] / max_blocks * 100)\n",
    "    df_def['DEF_Clearances'] = (df_def['Clr_per90'] / max_clr * 100)\n",
    "    df_def['DEF_PassAccuracy'] = df_def[pass_acc_col] if pass_acc_col else 0\n",
    "    \n",
    "    # Weighted score\n",
    "    df_def['Performance_Score'] = (\n",
    "        df_def['DEF_Tackles'] * 0.25 +       # 25% - Tackles\n",
    "        df_def['DEF_Interceptions'] * 0.25 + # 25% - Interceptions\n",
    "        df_def['DEF_Blocks'] * 0.20 +        # 20% - Blocks\n",
    "        df_def['DEF_Clearances'] * 0.15 +    # 15% - Clearances\n",
    "        df_def['DEF_PassAccuracy'] * 0.15    # 15% - Pass accuracy\n",
    "    )\n",
    "    \n",
    "    return df_def\n",
    "\n",
    "# MIDFIELD PERFORMANCE SCORE\n",
    "def calculate_mid_score(df_mid):\n",
    "    if df_mid.empty:\n",
    "        return df_mid\n",
    "    \n",
    "    # Reset index to ensure no duplicates\n",
    "    df_mid = df_mid.reset_index(drop=True).copy()\n",
    "    \n",
    "    # Check if required columns exist\n",
    "    total_att_col = 'Total Att' if 'Total Att' in df_mid.columns else None\n",
    "    prog_passes_col = 'Passes PrgP' if 'Passes PrgP' in df_mid.columns else None\n",
    "    sca_col = 'SCA' if 'SCA' in df_mid.columns else None\n",
    "    kp_col = 'KP' if 'KP' in df_mid.columns else None\n",
    "    ast_col = 'Ast' if 'Ast' in df_mid.columns else None\n",
    "    pass_acc_col = 'Total Cmp%' if 'Total Cmp%' in df_mid.columns else None\n",
    "    \n",
    "    # Convert to numpy arrays and ensure they're 1D\n",
    "    min_values = np.array(df_mid['Min']).flatten()\n",
    "    \n",
    "    # Normalize per 90 minutes using numpy operations\n",
    "    if total_att_col is not None:\n",
    "        passes_values = np.array(df_mid[total_att_col]).flatten()\n",
    "        df_mid['Passes_per90'] = np.where(min_values > 0, passes_values / min_values * 90, 0)\n",
    "    else:\n",
    "        df_mid['Passes_per90'] = 0\n",
    "        \n",
    "    if prog_passes_col is not None:\n",
    "        prog_values = np.array(df_mid[prog_passes_col]).flatten()\n",
    "        df_mid['ProgPasses_per90'] = np.where(min_values > 0, prog_values / min_values * 90, 0)\n",
    "    else:\n",
    "        df_mid['ProgPasses_per90'] = 0\n",
    "        \n",
    "    if sca_col is not None:\n",
    "        sca_values = np.array(df_mid[sca_col]).flatten()\n",
    "        df_mid['SCA_per90'] = np.where(min_values > 0, sca_values / min_values * 90, 0)\n",
    "    else:\n",
    "        df_mid['SCA_per90'] = 0\n",
    "        \n",
    "    if kp_col is not None:\n",
    "        kp_values = np.array(df_mid[kp_col]).flatten()\n",
    "        df_mid['KP_per90'] = np.where(min_values > 0, kp_values / min_values * 90, 0)\n",
    "    else:\n",
    "        df_mid['KP_per90'] = 0\n",
    "        \n",
    "    if ast_col is not None:\n",
    "        ast_values = np.array(df_mid[ast_col]).flatten()\n",
    "        df_mid['Ast_per90'] = np.where(min_values > 0, ast_values / min_values * 90, 0)\n",
    "    else:\n",
    "        df_mid['Ast_per90'] = 0\n",
    "    \n",
    "    # Scale to 0-100\n",
    "    max_passes = df_mid['Passes_per90'].max() if df_mid['Passes_per90'].max() > 0 else 1\n",
    "    max_prog = df_mid['ProgPasses_per90'].max() if df_mid['ProgPasses_per90'].max() > 0 else 1\n",
    "    max_sca = df_mid['SCA_per90'].max() if df_mid['SCA_per90'].max() > 0 else 1\n",
    "    max_kp = df_mid['KP_per90'].max() if df_mid['KP_per90'].max() > 0 else 1\n",
    "    \n",
    "    df_mid['MID_PassVolume'] = (df_mid['Passes_per90'] / max_passes * 100)\n",
    "    df_mid['MID_Progressive'] = (df_mid['ProgPasses_per90'] / max_prog * 100)\n",
    "    df_mid['MID_Creativity'] = (df_mid['SCA_per90'] / max_sca * 100)\n",
    "    df_mid['MID_KeyPasses'] = (df_mid['KP_per90'] / max_kp * 100)\n",
    "    df_mid['MID_PassAccuracy'] = df_mid[pass_acc_col] if pass_acc_col else 80  # Default decent accuracy\n",
    "    df_mid['MID_Assists'] = (df_mid['Ast_per90'] * 50)  # Assists bonus\n",
    "    \n",
    "    # Weighted score\n",
    "    df_mid['Performance_Score'] = (\n",
    "        df_mid['MID_PassAccuracy'] * 0.20 +   # 20% - Pass accuracy\n",
    "        df_mid['MID_Progressive'] * 0.20 +    # 20% - Progressive passes\n",
    "        df_mid['MID_Creativity'] * 0.20 +     # 20% - Shot creating actions\n",
    "        df_mid['MID_KeyPasses'] * 0.15 +      # 15% - Key passes\n",
    "        df_mid['MID_PassVolume'] * 0.15 +     # 15% - Pass volume\n",
    "        df_mid['MID_Assists'] * 0.10          # 10% - Assists\n",
    "    )\n",
    "    \n",
    "    return df_mid\n",
    "\n",
    "# FORWARD PERFORMANCE SCORE\n",
    "def calculate_fwd_score(df_fwd):\n",
    "    if df_fwd.empty:\n",
    "        print(\"  - Forward subset is empty\")\n",
    "        return df_fwd\n",
    "    \n",
    "    print(f\"  - Processing {len(df_fwd)} forward records\")\n",
    "    \n",
    "    # Ensure we have a clean copy with reset index\n",
    "    df_fwd = df_fwd.copy().reset_index(drop=True)\n",
    "    \n",
    "    # Check if required columns exist\n",
    "    gls_col = 'Gls' if 'Gls' in df_fwd.columns else None\n",
    "    ast_col = 'Ast' if 'Ast' in df_fwd.columns else None\n",
    "    sh_col = 'Sh' if 'Sh' in df_fwd.columns else None\n",
    "    sot_col = 'SoT' if 'SoT' in df_fwd.columns else None\n",
    "    xg_col = 'Expected xG' if 'Expected xG' in df_fwd.columns else None\n",
    "    \n",
    "    print(f\"  - Available columns: Gls={gls_col is not None}, Ast={ast_col is not None}, Sh={sh_col is not None}\")\n",
    "    \n",
    "    # Safely extract minutes as 1D array\n",
    "    try:\n",
    "        min_values = pd.to_numeric(df_fwd['Min'], errors='coerce').fillna(0).values\n",
    "        min_values = np.array(min_values).flatten()\n",
    "        print(f\"  - Min values shape: {min_values.shape}\")\n",
    "    except Exception as e:\n",
    "        print(f\"  - Error extracting minutes: {e}\")\n",
    "        min_values = np.zeros(len(df_fwd))\n",
    "    \n",
    "    # Normalize per 90 minutes using safe operations\n",
    "    if gls_col is not None:\n",
    "        try:\n",
    "            gls_values = pd.to_numeric(df_fwd[gls_col], errors='coerce').fillna(0).values\n",
    "            gls_values = np.array(gls_values).flatten()\n",
    "            print(f\"  - Goals values shape: {gls_values.shape}\")\n",
    "            \n",
    "            if len(gls_values) == len(min_values):\n",
    "                df_fwd['Gls_per90'] = np.where(min_values > 0, gls_values / min_values * 90, 0)\n",
    "            else:\n",
    "                print(f\"  - Shape mismatch for goals: {len(gls_values)} vs {len(min_values)}\")\n",
    "                df_fwd['Gls_per90'] = 0\n",
    "        except Exception as e:\n",
    "            print(f\"  - Error processing goals: {e}\")\n",
    "            df_fwd['Gls_per90'] = 0\n",
    "    else:\n",
    "        df_fwd['Gls_per90'] = 0\n",
    "        \n",
    "    if ast_col is not None:\n",
    "        try:\n",
    "            ast_values = pd.to_numeric(df_fwd[ast_col], errors='coerce').fillna(0).values\n",
    "            ast_values = np.array(ast_values).flatten()\n",
    "            print(f\"  - Assists values shape: {ast_values.shape}\")\n",
    "            \n",
    "            if len(ast_values) == len(min_values):\n",
    "                df_fwd['Ast_per90'] = np.where(min_values > 0, ast_values / min_values * 90, 0)\n",
    "            else:\n",
    "                print(f\"  - Shape mismatch for assists: {len(ast_values)} vs {len(min_values)}\")\n",
    "                df_fwd['Ast_per90'] = 0\n",
    "        except Exception as e:\n",
    "            print(f\"  - Error processing assists: {e}\")\n",
    "            df_fwd['Ast_per90'] = 0\n",
    "    else:\n",
    "        df_fwd['Ast_per90'] = 0\n",
    "        \n",
    "    if sh_col is not None:\n",
    "        try:\n",
    "            sh_values = pd.to_numeric(df_fwd[sh_col], errors='coerce').fillna(0).values\n",
    "            sh_values = np.array(sh_values).flatten()\n",
    "            if len(sh_values) == len(min_values):\n",
    "                df_fwd['Shots_per90'] = np.where(min_values > 0, sh_values / min_values * 90, 0)\n",
    "            else:\n",
    "                df_fwd['Shots_per90'] = 0\n",
    "        except Exception as e:\n",
    "            print(f\"  - Error processing shots: {e}\")\n",
    "            df_fwd['Shots_per90'] = 0\n",
    "    else:\n",
    "        df_fwd['Shots_per90'] = 0\n",
    "        \n",
    "    if sot_col is not None:\n",
    "        try:\n",
    "            sot_values = pd.to_numeric(df_fwd[sot_col], errors='coerce').fillna(0).values\n",
    "            sot_values = np.array(sot_values).flatten()\n",
    "            if len(sot_values) == len(min_values):\n",
    "                df_fwd['SoT_per90'] = np.where(min_values > 0, sot_values / min_values * 90, 0)\n",
    "            else:\n",
    "                df_fwd['SoT_per90'] = 0\n",
    "        except Exception as e:\n",
    "            print(f\"  - Error processing shots on target: {e}\")\n",
    "            df_fwd['SoT_per90'] = 0\n",
    "    else:\n",
    "        df_fwd['SoT_per90'] = 0\n",
    "        \n",
    "    if xg_col is not None:\n",
    "        try:\n",
    "            xg_values = pd.to_numeric(df_fwd[xg_col], errors='coerce').fillna(0).values\n",
    "            xg_values = np.array(xg_values).flatten()\n",
    "            if len(xg_values) == len(min_values):\n",
    "                df_fwd['xG_per90'] = np.where(min_values > 0, xg_values / min_values * 90, 0)\n",
    "            else:\n",
    "                df_fwd['xG_per90'] = 0\n",
    "        except Exception as e:\n",
    "            print(f\"  - Error processing xG: {e}\")\n",
    "            df_fwd['xG_per90'] = 0\n",
    "    else:\n",
    "        df_fwd['xG_per90'] = 0\n",
    "    \n",
    "    # Scale to 0-100\n",
    "    max_goals = df_fwd['Gls_per90'].max() if df_fwd['Gls_per90'].max() > 0 else 1\n",
    "    max_shots = df_fwd['Shots_per90'].max() if df_fwd['Shots_per90'].max() > 0 else 1\n",
    "    max_sot = df_fwd['SoT_per90'].max() if df_fwd['SoT_per90'].max() > 0 else 1\n",
    "    max_xg = df_fwd['xG_per90'].max() if df_fwd['xG_per90'].max() > 0 else 1\n",
    "    \n",
    "    df_fwd['FWD_Goals'] = (df_fwd['Gls_per90'] / max_goals * 100)\n",
    "    df_fwd['FWD_Assists'] = (df_fwd['Ast_per90'] * 50)  # Assists bonus\n",
    "    df_fwd['FWD_Shots'] = (df_fwd['Shots_per90'] / max_shots * 100)\n",
    "    df_fwd['FWD_ShotsOnTarget'] = (df_fwd['SoT_per90'] / max_sot * 100)\n",
    "    df_fwd['FWD_ExpectedGoals'] = (df_fwd['xG_per90'] / max_xg * 100)\n",
    "    df_fwd['FWD_TakeOnSuccess'] = df_fwd['Take-Ons Succ%'] if 'Take-Ons Succ%' in df_fwd.columns else 0\n",
    "    \n",
    "    # Weighted score\n",
    "    df_fwd['Performance_Score'] = (\n",
    "        df_fwd['FWD_Goals'] * 0.35 +           # 35% - Goals\n",
    "        df_fwd['FWD_Assists'] * 0.20 +         # 20% - Assists\n",
    "        df_fwd['FWD_ShotsOnTarget'] * 0.15 +   # 15% - Shots on target\n",
    "        df_fwd['FWD_ExpectedGoals'] * 0.15 +   # 15% - Expected goals\n",
    "        df_fwd['FWD_TakeOnSuccess'] * 0.10 +   # 10% - Take-on success\n",
    "        df_fwd['FWD_Shots'] * 0.05             # 5% - Shot volume\n",
    "    )\n",
    "    \n",
    "    print(f\"  - Completed forward scoring. Score range: {df_fwd['Performance_Score'].min():.1f} - {df_fwd['Performance_Score'].max():.1f}\")\n",
    "    \n",
    "    return df_fwd\n",
    "\n",
    "# Apply scoring by position group\n",
    "df['Performance_Score'] = 0\n",
    "\n",
    "# Process each position group separately to avoid index conflicts\n",
    "for position_group in df['Position_Group'].unique():\n",
    "    if pd.isna(position_group):\n",
    "        continue\n",
    "        \n",
    "    print(f\"\\nProcessing {position_group} players...\")\n",
    "    \n",
    "    # Create a clean subset with proper filtering\n",
    "    mask = df['Position_Group'] == position_group\n",
    "    subset = df[mask].copy()\n",
    "    original_length = len(subset)\n",
    "    \n",
    "    # Reset index completely\n",
    "    subset = subset.reset_index(drop=True)\n",
    "    \n",
    "    print(f\"Found {len(subset)} {position_group} records\")\n",
    "    \n",
    "    try:\n",
    "        if position_group == 'Goalkeeper':\n",
    "            subset = calculate_gk_score(subset)\n",
    "        elif position_group == 'Defense':\n",
    "            subset = calculate_def_score(subset)\n",
    "        elif position_group == 'Midfield':\n",
    "            subset = calculate_mid_score(subset)\n",
    "        elif position_group == 'Forward':\n",
    "            subset = calculate_fwd_score(subset)\n",
    "        \n",
    "        # Verify lengths match before updating\n",
    "        if len(subset) == original_length:\n",
    "            # Update the main dataframe with the calculated scores using loc indexing\n",
    "            original_indices = df[mask].index\n",
    "            df.loc[original_indices, 'Performance_Score'] = subset['Performance_Score'].values\n",
    "            print(f\"âœ“ Successfully calculated scores for {position_group}\")\n",
    "        else:\n",
    "            print(f\"âœ— Length mismatch for {position_group}: {len(subset)} vs {original_length}\")\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"âœ— Error processing {position_group}: {e}\")\n",
    "        # Set default scores for this position group\n",
    "        df.loc[mask, 'Performance_Score'] = 50  # Default middle score\n",
    "\n",
    "# Cap scores at 100\n",
    "df['Performance_Score'] = df['Performance_Score'].clip(0, 100)\n",
    "print(f\"\\nCompleted performance score calculation. Score range: {df['Performance_Score'].min():.1f} - {df['Performance_Score'].max():.1f}\")\n",
    "\n",
    "# Create the combined dataset with all new columns\n",
    "combined_df = df.copy()\n",
    "\n",
    "# Create summary table by Season and Position\n",
    "try:\n",
    "    season_position_summary = combined_df.groupby(['Season', 'Position_Group']).agg({\n",
    "        'Performance_Score': ['mean', 'max', 'min', 'std', 'count'],\n",
    "        'Player': 'nunique',\n",
    "        'Min': 'sum',\n",
    "        'Gls': 'sum',\n",
    "        'Ast': 'sum'\n",
    "    }).round(2)\n",
    "\n",
    "    season_position_summary.columns = ['Avg_Performance', 'Max_Performance', 'Min_Performance', \n",
    "                                      'Std_Performance', 'Total_Matches', 'Unique_Players', \n",
    "                                      'Total_Minutes', 'Total_Goals', 'Total_Assists']\n",
    "    season_position_summary = season_position_summary.reset_index()\n",
    "except Exception as e:\n",
    "    print(f\"Error creating season position summary: {e}\")\n",
    "    # Create a simple summary instead\n",
    "    season_position_summary = combined_df.groupby(['Season', 'Position_Group'])['Performance_Score'].mean().reset_index()\n",
    "    season_position_summary.columns = ['Season', 'Position_Group', 'Avg_Performance']\n",
    "\n",
    "# Create summary table by Player, Season, and Position\n",
    "try:\n",
    "    player_season_summary = combined_df.groupby(['Player', 'Position_Group', 'Season']).agg({\n",
    "        'Performance_Score': ['mean', 'max', 'min', 'count'],\n",
    "        'Min': 'sum',\n",
    "        'Gls': 'sum',\n",
    "        'Ast': 'sum',\n",
    "        'Date': ['min', 'max']\n",
    "    }).round(2)\n",
    "\n",
    "    player_season_summary.columns = ['Avg_Performance_Score', 'Max_Performance_Score', \n",
    "                                    'Min_Performance_Score', 'Games_Played', 'Total_Minutes', \n",
    "                                    'Total_Goals', 'Total_Assists', 'First_Game', 'Last_Game']\n",
    "    player_season_summary = player_season_summary.reset_index()\n",
    "except Exception as e:\n",
    "    print(f\"Error creating player season summary: {e}\")\n",
    "    # Create a simple summary instead\n",
    "    player_season_summary = combined_df.groupby(['Player', 'Position_Group', 'Season']).agg({\n",
    "        'Performance_Score': 'mean',\n",
    "        'Min': 'sum'\n",
    "    }).reset_index()\n",
    "    player_season_summary.columns = ['Player', 'Position_Group', 'Season', 'Avg_Performance_Score', 'Total_Minutes']\n",
    "\n",
    "# Display comprehensive summary\n",
    "print(\"\\n=== REAL MADRID PERFORMANCE SCORING SYSTEM ===\")\n",
    "if len(player_season_summary) > 0:\n",
    "    print(\"Top 10 Players by Average Performance Score:\")\n",
    "    if 'Avg_Performance_Score' in player_season_summary.columns:\n",
    "        top_players = player_season_summary.nlargest(10, 'Avg_Performance_Score')\n",
    "        display_cols = [col for col in ['Player', 'Position_Group', 'Season', 'Avg_Performance_Score', 'Games_Played'] \n",
    "                       if col in top_players.columns]\n",
    "        print(top_players[display_cols].to_string(index=False))\n",
    "\n",
    "print(\"\\n\\n=== SUMMARY BY SEASON AND POSITION ===\")\n",
    "if len(season_position_summary) > 0:\n",
    "    print(season_position_summary.to_string(index=False))\n",
    "\n",
    "print(\"\\n\\n=== TOP PERFORMERS BY SEASON ===\")\n",
    "if len(player_season_summary) > 0 and 'Avg_Performance_Score' in player_season_summary.columns:\n",
    "    for season in sorted(combined_df['Season'].unique()):\n",
    "        if pd.notna(season):\n",
    "            season_data = player_season_summary[player_season_summary['Season'] == season]\n",
    "            if len(season_data) > 0:\n",
    "                top_performers = season_data.nlargest(5, 'Avg_Performance_Score')\n",
    "                print(f\"\\n{season} Season - Top 5 Performers:\")\n",
    "                display_cols = [col for col in ['Player', 'Position_Group', 'Avg_Performance_Score', 'Games_Played'] \n",
    "                               if col in top_performers.columns]\n",
    "                print(top_performers[display_cols].to_string(index=False))\n",
    "\n",
    "print(\"\\n\\n=== POSITION ANALYSIS ACROSS SEASONS ===\")\n",
    "try:\n",
    "    position_across_seasons = combined_df.groupby(['Position_Group', 'Season'])['Performance_Score'].mean().unstack(fill_value=0).round(2)\n",
    "    print(position_across_seasons.to_string())\n",
    "except Exception as e:\n",
    "    print(f\"Could not create position analysis: {e}\")\n",
    "    # Simple alternative\n",
    "    print(combined_df.groupby(['Position_Group', 'Season'])['Performance_Score'].mean().round(2).to_string())\n",
    "\n",
    "# Save all files with error handling\n",
    "try:\n",
    "    # 1. Enhanced combined dataset with all columns\n",
    "    enhanced_path = '/Users/mariamoramora/Documents/GitHub/ADS599_Capstone/Soccer_Performance_Score/data/real_madrid_combined/real_madrid_enhanced_complete.csv'\n",
    "    combined_df.to_csv(enhanced_path, index=False)\n",
    "    print(f\"âœ“ Enhanced dataset saved: {enhanced_path}\")\n",
    "except Exception as e:\n",
    "    print(f\"âœ— Error saving enhanced dataset: {e}\")\n",
    "\n",
    "try:\n",
    "    # 2. Season-Position summary\n",
    "    season_pos_path = '/Users/mariamoramora/Documents/GitHub/ADS599_Capstone/Soccer_Performance_Score/data/real_madrid_combined/summary_by_season_position.csv'\n",
    "    season_position_summary.to_csv(season_pos_path, index=False)\n",
    "    print(f\"âœ“ Season-Position summary saved: {season_pos_path}\")\n",
    "except Exception as e:\n",
    "    print(f\"âœ— Error saving season-position summary: {e}\")\n",
    "\n",
    "try:\n",
    "    # 3. Player-Season summary\n",
    "    player_season_path = '/Users/mariamoramora/Documents/GitHub/ADS599_Capstone/Soccer_Performance_Score/data/real_madrid_combined/player_summary_by_season.csv'\n",
    "    player_season_summary.to_csv(player_season_path, index=False)\n",
    "    print(f\"âœ“ Player summary saved: {player_season_path}\")\n",
    "except Exception as e:\n",
    "    print(f\"âœ— Error saving player summary: {e}\")\n",
    "\n",
    "try:\n",
    "    # 4. Position performance across seasons\n",
    "    position_seasons_path = '/Users/mariamoramora/Documents/GitHub/ADS599_Capstone/Soccer_Performance_Score/data/real_madrid_combined/position_performance_across_seasons.csv'\n",
    "    if 'position_across_seasons' in locals():\n",
    "        position_across_seasons.to_csv(position_seasons_path)\n",
    "        print(f\"âœ“ Position analysis saved: {position_seasons_path}\")\n",
    "    else:\n",
    "        # Create simple version\n",
    "        simple_position_analysis = combined_df.groupby(['Position_Group', 'Season'])['Performance_Score'].mean().reset_index()\n",
    "        simple_position_analysis.to_csv(position_seasons_path, index=False)\n",
    "        print(f\"âœ“ Simple position analysis saved: {position_seasons_path}\")\n",
    "except Exception as e:\n",
    "    print(f\"âœ— Error saving position analysis: {e}\")\n",
    "\n",
    "print(f\"\\n=== DATASET INFO ===\")\n",
    "print(f\"Total records in enhanced dataset: {len(combined_df)}\")\n",
    "print(f\"Seasons covered: {sorted(combined_df['Season'].unique())}\")\n",
    "print(f\"Position groups: {combined_df['Position_Group'].value_counts().to_dict()}\")\n",
    "print(f\"Unique players: {combined_df['Player'].nunique()}\")\n",
    "\n",
    "# Show sample of enhanced dataset\n",
    "print(f\"\\n=== SAMPLE OF ENHANCED DATASET ===\")\n",
    "sample_cols = ['Date', 'Season', 'Player', 'Position_Group', 'Performance_Score', 'Min', 'Gls', 'Ast']\n",
    "available_cols = [col for col in sample_cols if col in combined_df.columns]\n",
    "print(combined_df[available_cols].head(15).to_string(index=False))\n",
    "\n",
    "print(\"\\nðŸ† REAL MADRID PERFORMANCE ANALYSIS COMPLETE! ðŸ†\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Second code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== REAL MADRID DATA PREPROCESSING & PERFORMANCE ANALYSIS ===\n",
      "âœ“ Loaded dataset: (1550, 73)\n",
      "Original columns: 73\n",
      "\n",
      "ðŸ§¹ PHASE 1: DATA CLEANING & PREPROCESSING\n",
      "âœ“ Removed columns: ['Match URL', 'Challenges Tkl%', 'number']\n",
      "âœ“ Cleaning Age column...\n",
      "  Age range: 17 - 39\n",
      "âœ“ Cleaning Nation column...\n",
      "  Sample nations: ['BRA', 'CRO', 'ESP', 'ENG', 'FRA', 'GER', 'URU', 'AUT', 'UKR', 'MAR']\n",
      "âœ“ Column names cleaned\n",
      "âœ“ Basic setup complete\n",
      "Cleaned dataset shape: (1550, 72)\n",
      "Position distribution: {'Defense': 483, 'Midfield': 410, 'Forward': 211, 'Goalkeeper': 104}\n",
      "\n",
      "Cleaning statistical columns...\n",
      "  Processing Min\n",
      "    âœ“ Range: 1 - 120\n",
      "  Processing Gls\n",
      "    âœ“ Range: 0 - 3\n",
      "  Processing Ast\n",
      "    âš ï¸ Could not calculate range, but column processed\n",
      "  Processing Sh\n",
      "    âœ“ Range: 0 - 11\n",
      "  Processing SoT\n",
      "    âœ“ Range: 0 - 5\n",
      "  Processing Tkl\n",
      "    âœ“ Range: 0 - 10\n",
      "  Processing Int\n",
      "    âš ï¸ Could not calculate range, but column processed\n",
      "  Processing Blocks\n",
      "    âœ“ Range: 0 - 7\n",
      "  Processing Clr\n",
      "    âœ“ Range: 0 - 14\n",
      "  Processing SCA\n",
      "    âœ“ Range: 0 - 13\n",
      "  Processing KP\n",
      "    âœ“ Range: 0 - 8\n",
      "  Processing Expected xG\n",
      "    âœ“ Range: 0.0 - 2.1\n",
      "  Processing Total Cmp%\n",
      "    âœ“ Range: 0.0 - 100.0\n",
      "  Processing Long Cmp%\n",
      "    âœ“ Range: 0.0 - 100.0\n",
      "  Processing Total Att\n",
      "    âœ“ Range: 0 - 135\n",
      "  Processing Passes PrgP\n",
      "    âœ“ Range: 0 - 23\n",
      "âœ“ Take-on statistics calculated\n",
      "âœ“ Data preprocessing completed\n",
      "\n",
      "âš½ PHASE 2: CALCULATING PERFORMANCE SCORES\n",
      "\n",
      "Goalkeepers: 104 records\n",
      "  âœ“ Score range: 44.0 - 100.0\n",
      "\n",
      "Forwards: 211 records\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "cannot reindex on an axis with duplicate labels",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[30], line 168\u001b[0m\n\u001b[1;32m    166\u001b[0m \u001b[38;5;66;03m# Calculate per-90 stats\u001b[39;00m\n\u001b[1;32m    167\u001b[0m fw_data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mGls_90\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m per_90(fw_data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mGls\u001b[39m\u001b[38;5;124m'\u001b[39m], fw_data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMin\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m--> 168\u001b[0m fw_data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAst_90\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m per_90(fw_data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAst\u001b[39m\u001b[38;5;124m'\u001b[39m], fw_data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMin\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m    169\u001b[0m fw_data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSh_90\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m per_90(fw_data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSh\u001b[39m\u001b[38;5;124m'\u001b[39m], fw_data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMin\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m    170\u001b[0m fw_data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSoT_90\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m per_90(fw_data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSoT\u001b[39m\u001b[38;5;124m'\u001b[39m], fw_data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMin\u001b[39m\u001b[38;5;124m'\u001b[39m])\n",
      "Cell \u001b[0;32mIn[30], line 137\u001b[0m, in \u001b[0;36mper_90\u001b[0;34m(stat, minutes)\u001b[0m\n\u001b[1;32m    136\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mper_90\u001b[39m(stat, minutes):\n\u001b[0;32m--> 137\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m np\u001b[38;5;241m.\u001b[39mwhere(minutes \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m, stat \u001b[38;5;241m/\u001b[39m minutes \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m90\u001b[39m, \u001b[38;5;241m0\u001b[39m)\n",
      "File \u001b[0;32m/opt/miniconda3/lib/python3.12/site-packages/pandas/core/ops/common.py:76\u001b[0m, in \u001b[0;36m_unpack_zerodim_and_defer.<locals>.new_method\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m     72\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mNotImplemented\u001b[39m\n\u001b[1;32m     74\u001b[0m other \u001b[38;5;241m=\u001b[39m item_from_zerodim(other)\n\u001b[0;32m---> 76\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m method(\u001b[38;5;28mself\u001b[39m, other)\n",
      "File \u001b[0;32m/opt/miniconda3/lib/python3.12/site-packages/pandas/core/arraylike.py:210\u001b[0m, in \u001b[0;36mOpsMixin.__truediv__\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m    208\u001b[0m \u001b[38;5;129m@unpack_zerodim_and_defer\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__truediv__\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    209\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__truediv__\u001b[39m(\u001b[38;5;28mself\u001b[39m, other):\n\u001b[0;32m--> 210\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_arith_method(other, operator\u001b[38;5;241m.\u001b[39mtruediv)\n",
      "File \u001b[0;32m/opt/miniconda3/lib/python3.12/site-packages/pandas/core/frame.py:7910\u001b[0m, in \u001b[0;36mDataFrame._arith_method\u001b[0;34m(self, other, op)\u001b[0m\n\u001b[1;32m   7907\u001b[0m axis: Literal[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m  \u001b[38;5;66;03m# only relevant for Series other case\u001b[39;00m\n\u001b[1;32m   7908\u001b[0m other \u001b[38;5;241m=\u001b[39m ops\u001b[38;5;241m.\u001b[39mmaybe_prepare_scalar_for_op(other, (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mshape[axis],))\n\u001b[0;32m-> 7910\u001b[0m \u001b[38;5;28mself\u001b[39m, other \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_align_for_op(other, axis, flex\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, level\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m   7912\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m np\u001b[38;5;241m.\u001b[39merrstate(\u001b[38;5;28mall\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m   7913\u001b[0m     new_data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dispatch_frame_op(other, op, axis\u001b[38;5;241m=\u001b[39maxis)\n",
      "File \u001b[0;32m/opt/miniconda3/lib/python3.12/site-packages/pandas/core/frame.py:8211\u001b[0m, in \u001b[0;36mDataFrame._align_for_op\u001b[0;34m(self, other, axis, flex, level)\u001b[0m\n\u001b[1;32m   8204\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m left\u001b[38;5;241m.\u001b[39maxes[axis]\u001b[38;5;241m.\u001b[39mequals(right\u001b[38;5;241m.\u001b[39mindex):\n\u001b[1;32m   8205\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   8206\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOperands are not aligned. Do \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   8207\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`left, right = left.align(right, axis=1, copy=False)` \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   8208\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbefore operating.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   8209\u001b[0m             )\n\u001b[0;32m-> 8211\u001b[0m     left, right \u001b[38;5;241m=\u001b[39m left\u001b[38;5;241m.\u001b[39malign(\n\u001b[1;32m   8212\u001b[0m         right,\n\u001b[1;32m   8213\u001b[0m         join\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mouter\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   8214\u001b[0m         axis\u001b[38;5;241m=\u001b[39maxis,\n\u001b[1;32m   8215\u001b[0m         level\u001b[38;5;241m=\u001b[39mlevel,\n\u001b[1;32m   8216\u001b[0m         copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m   8217\u001b[0m     )\n\u001b[1;32m   8218\u001b[0m     right \u001b[38;5;241m=\u001b[39m left\u001b[38;5;241m.\u001b[39m_maybe_align_series_as_frame(right, axis)\n\u001b[1;32m   8220\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m left, right\n",
      "File \u001b[0;32m/opt/miniconda3/lib/python3.12/site-packages/pandas/core/generic.py:10447\u001b[0m, in \u001b[0;36mNDFrame.align\u001b[0;34m(self, other, join, axis, level, copy, fill_value, method, limit, fill_axis, broadcast_axis)\u001b[0m\n\u001b[1;32m  10434\u001b[0m     left, _right, join_index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_align_frame(\n\u001b[1;32m  10435\u001b[0m         other,\n\u001b[1;32m  10436\u001b[0m         join\u001b[38;5;241m=\u001b[39mjoin,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m  10443\u001b[0m         fill_axis\u001b[38;5;241m=\u001b[39mfill_axis,\n\u001b[1;32m  10444\u001b[0m     )\n\u001b[1;32m  10446\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(other, ABCSeries):\n\u001b[0;32m> 10447\u001b[0m     left, _right, join_index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_align_series(\n\u001b[1;32m  10448\u001b[0m         other,\n\u001b[1;32m  10449\u001b[0m         join\u001b[38;5;241m=\u001b[39mjoin,\n\u001b[1;32m  10450\u001b[0m         axis\u001b[38;5;241m=\u001b[39maxis,\n\u001b[1;32m  10451\u001b[0m         level\u001b[38;5;241m=\u001b[39mlevel,\n\u001b[1;32m  10452\u001b[0m         copy\u001b[38;5;241m=\u001b[39mcopy,\n\u001b[1;32m  10453\u001b[0m         fill_value\u001b[38;5;241m=\u001b[39mfill_value,\n\u001b[1;32m  10454\u001b[0m         method\u001b[38;5;241m=\u001b[39mmethod,\n\u001b[1;32m  10455\u001b[0m         limit\u001b[38;5;241m=\u001b[39mlimit,\n\u001b[1;32m  10456\u001b[0m         fill_axis\u001b[38;5;241m=\u001b[39mfill_axis,\n\u001b[1;32m  10457\u001b[0m     )\n\u001b[1;32m  10458\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:  \u001b[38;5;66;03m# pragma: no cover\u001b[39;00m\n\u001b[1;32m  10459\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124munsupported type: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(other)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/opt/miniconda3/lib/python3.12/site-packages/pandas/core/generic.py:10590\u001b[0m, in \u001b[0;36mNDFrame._align_series\u001b[0;34m(self, other, join, axis, level, copy, fill_value, method, limit, fill_axis)\u001b[0m\n\u001b[1;32m  10588\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m lidx \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m  10589\u001b[0m     bm_axis \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_block_manager_axis(\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m> 10590\u001b[0m     fdata \u001b[38;5;241m=\u001b[39m fdata\u001b[38;5;241m.\u001b[39mreindex_indexer(join_index, lidx, axis\u001b[38;5;241m=\u001b[39mbm_axis)\n\u001b[1;32m  10592\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m copy \u001b[38;5;129;01mand\u001b[39;00m fdata \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_mgr:\n\u001b[1;32m  10593\u001b[0m     fdata \u001b[38;5;241m=\u001b[39m fdata\u001b[38;5;241m.\u001b[39mcopy()\n",
      "File \u001b[0;32m/opt/miniconda3/lib/python3.12/site-packages/pandas/core/internals/managers.py:674\u001b[0m, in \u001b[0;36mBaseBlockManager.reindex_indexer\u001b[0;34m(self, new_axis, indexer, axis, fill_value, allow_dups, copy, only_slice, use_na_proxy)\u001b[0m\n\u001b[1;32m    672\u001b[0m \u001b[38;5;66;03m# some axes don't allow reindexing with dups\u001b[39;00m\n\u001b[1;32m    673\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m allow_dups:\n\u001b[0;32m--> 674\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maxes[axis]\u001b[38;5;241m.\u001b[39m_validate_can_reindex(indexer)\n\u001b[1;32m    676\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m axis \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mndim:\n\u001b[1;32m    677\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mIndexError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRequested axis not found in manager\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/opt/miniconda3/lib/python3.12/site-packages/pandas/core/indexes/base.py:4321\u001b[0m, in \u001b[0;36mIndex._validate_can_reindex\u001b[0;34m(self, indexer)\u001b[0m\n\u001b[1;32m   4319\u001b[0m \u001b[38;5;66;03m# trying to reindex on an axis with duplicates\u001b[39;00m\n\u001b[1;32m   4320\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_index_as_unique \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(indexer):\n\u001b[0;32m-> 4321\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcannot reindex on an axis with duplicate labels\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mValueError\u001b[0m: cannot reindex on an axis with duplicate labels"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "print(\"=== REAL MADRID DATA PREPROCESSING & PERFORMANCE ANALYSIS ===\")\n",
    "\n",
    "# Load the data\n",
    "original_path = '/Users/mariamoramora/Documents/GitHub/ADS599_Capstone/Soccer_Performance_Score/data/real_madrid_combined/combined_real_madrid.csv'\n",
    "\n",
    "try:\n",
    "    df = pd.read_csv(original_path)\n",
    "    print(\"âœ“ Loaded dataset:\", df.shape)\n",
    "except FileNotFoundError:\n",
    "    print(\"âŒ File not found:\", original_path)\n",
    "    exit()\n",
    "\n",
    "print(\"Original columns:\", len(df.columns))\n",
    "\n",
    "# ==========================================\n",
    "# PHASE 1: DATA CLEANING & PREPROCESSING\n",
    "# ==========================================\n",
    "\n",
    "print(\"\\nðŸ§¹ PHASE 1: DATA CLEANING & PREPROCESSING\")\n",
    "\n",
    "# 1. Remove problematic columns\n",
    "columns_to_remove = ['Match URL', 'Challenges Tkl%', 'number']\n",
    "existing_cols_to_remove = [col for col in columns_to_remove if col in df.columns]\n",
    "if existing_cols_to_remove:\n",
    "    df = df.drop(columns=existing_cols_to_remove)\n",
    "    print(\"âœ“ Removed columns:\", existing_cols_to_remove)\n",
    "\n",
    "# 2. Clean Age column (remove everything after the dash)\n",
    "if 'Age' in df.columns:\n",
    "    print(\"âœ“ Cleaning Age column...\")\n",
    "    df['Age'] = df['Age'].astype(str).str.split('-').str[0]\n",
    "    df['Age'] = pd.to_numeric(df['Age'], errors='coerce').fillna(0).astype(int)\n",
    "    print(\"  Age range:\", df['Age'].min(), \"-\", df['Age'].max())\n",
    "\n",
    "# 3. Clean Nation column (keep only last 3 characters)\n",
    "if 'Nation' in df.columns:\n",
    "    print(\"âœ“ Cleaning Nation column...\")\n",
    "    df['Nation'] = df['Nation'].astype(str).str[-3:]\n",
    "    print(\"  Sample nations:\", df['Nation'].unique()[:10].tolist())\n",
    "\n",
    "# 4. Clean column names\n",
    "df.columns = df.columns.str.strip()\n",
    "print(\"âœ“ Column names cleaned\")\n",
    "\n",
    "# 5. Setup Date and Season\n",
    "df['Date'] = pd.to_datetime(df['Date'], format='%m/%d/%y', errors='coerce')\n",
    "df['Season'] = df['Date'].apply(lambda x: \n",
    "    str(x.year) + \"-\" + str(x.year + 1)[-2:] if pd.notna(x) and x.month >= 8 \n",
    "    else str(x.year - 1) + \"-\" + str(x.year)[-2:] if pd.notna(x) else \"Unknown\"\n",
    ")\n",
    "\n",
    "# 6. Position mapping\n",
    "position_mapping = {\n",
    "    'GK': 'Goalkeeper', 'CB': 'Defense', 'LB': 'Defense', 'RB': 'Defense',\n",
    "    'DM': 'Midfield', 'CM': 'Midfield', 'LM': 'Midfield', 'RM': 'Midfield', 'AM': 'Midfield',\n",
    "    'FW': 'Forward'\n",
    "}\n",
    "df['Position_Group'] = df['Pos'].map(position_mapping)\n",
    "\n",
    "print(\"âœ“ Basic setup complete\")\n",
    "print(\"Cleaned dataset shape:\", df.shape)\n",
    "print(\"Position distribution:\", df['Position_Group'].value_counts().to_dict())\n",
    "\n",
    "# 7. Clean key statistical columns\n",
    "def safe_numeric_conversion(series, default_value=0):\n",
    "    \"\"\"Convert series to numeric safely\"\"\"\n",
    "    try:\n",
    "        # Convert to string first, handle empty/null values\n",
    "        series_str = series.astype(str).replace(['nan', 'NaN', '', ' ', 'None'], '0')\n",
    "        # Convert to numeric\n",
    "        result = pd.to_numeric(series_str, errors='coerce').fillna(default_value)\n",
    "        return result\n",
    "    except:\n",
    "        # If anything fails, return default values\n",
    "        return pd.Series([default_value] * len(series))\n",
    "\n",
    "# Key columns we need for analysis\n",
    "key_stats = {\n",
    "    'Min': 0, 'Gls': 0, 'Ast': 0, 'Sh': 0, 'SoT': 0, 'Tkl': 0, 'Int': 0, \n",
    "    'Blocks': 0, 'Clr': 0, 'SCA': 0, 'KP': 0, 'Expected xG': 0,\n",
    "    'Total Cmp%': 0, 'Long Cmp%': 0, 'Total Att': 0, 'Passes PrgP': 0\n",
    "}\n",
    "\n",
    "print(\"\\nCleaning statistical columns...\")\n",
    "for col, default in key_stats.items():\n",
    "    if col in df.columns:\n",
    "        print(\"  Processing\", col)\n",
    "        df[col] = safe_numeric_conversion(df[col], default)\n",
    "        \n",
    "        # Safe min/max calculation with error handling\n",
    "        try:\n",
    "            col_values = df[col]\n",
    "            if len(col_values) > 0:\n",
    "                # Ensure all values are numeric\n",
    "                numeric_values = pd.to_numeric(col_values, errors='coerce')\n",
    "                if not numeric_values.isnull().all():\n",
    "                    min_val = numeric_values.min()\n",
    "                    max_val = numeric_values.max()\n",
    "                    print(\"    âœ“ Range:\", round(min_val, 1), \"-\", round(max_val, 1))\n",
    "                else:\n",
    "                    print(\"    âœ“ All values set to default:\", default)\n",
    "            else:\n",
    "                print(\"    âœ“ Empty column, set to default:\", default)\n",
    "        except Exception as e:\n",
    "            print(\"    âš ï¸ Could not calculate range, but column processed\")\n",
    "    else:\n",
    "        df[col] = default\n",
    "        print(\"  + Created\", col, \"=\", default)\n",
    "\n",
    "# 8. Handle Take-ons\n",
    "if 'Take-Ons Att' in df.columns and 'Take-Ons Succ' in df.columns:\n",
    "    df['Take-Ons Att'] = safe_numeric_conversion(df['Take-Ons Att'], 0)\n",
    "    df['Take-Ons Succ'] = safe_numeric_conversion(df['Take-Ons Succ'], 0)\n",
    "    df['Take-Ons Succ%'] = np.where(df['Take-Ons Att'] > 0, \n",
    "                                   (df['Take-Ons Succ'] / df['Take-Ons Att'] * 100), 0)\n",
    "    print(\"âœ“ Take-on statistics calculated\")\n",
    "else:\n",
    "    df['Take-Ons Succ%'] = 0\n",
    "    print(\"âœ“ Take-on columns not found, set to 0\")\n",
    "\n",
    "print(\"âœ“ Data preprocessing completed\")\n",
    "\n",
    "# ==========================================\n",
    "# PHASE 2: PERFORMANCE SCORING\n",
    "# ==========================================\n",
    "\n",
    "print(\"\\nâš½ PHASE 2: CALCULATING PERFORMANCE SCORES\")\n",
    "\n",
    "df['Performance_Score'] = 0.0\n",
    "\n",
    "# Helper function for per-90 calculations\n",
    "def per_90(stat, minutes):\n",
    "    return np.where(minutes > 0, stat / minutes * 90, 0)\n",
    "\n",
    "# Safe function to get numeric min/max\n",
    "def safe_min_max(series):\n",
    "    try:\n",
    "        numeric_series = pd.to_numeric(series, errors='coerce')\n",
    "        if not numeric_series.isnull().all():\n",
    "            return numeric_series.min(), numeric_series.max()\n",
    "        else:\n",
    "            return 0.0, 0.0\n",
    "    except:\n",
    "        return 0.0, 0.0\n",
    "\n",
    "# GOALKEEPERS\n",
    "gk_mask = df['Position_Group'] == 'Goalkeeper'\n",
    "if gk_mask.sum() > 0:\n",
    "    print(\"\\nGoalkeepers:\", gk_mask.sum(), \"records\")\n",
    "    gk_score = df.loc[gk_mask, 'Total Cmp%'] * 0.6 + df.loc[gk_mask, 'Long Cmp%'] * 0.4\n",
    "    df.loc[gk_mask, 'Performance_Score'] = gk_score\n",
    "    min_score, max_score = safe_min_max(gk_score)\n",
    "    print(\"  âœ“ Score range:\", round(min_score, 1), \"-\", round(max_score, 1))\n",
    "\n",
    "# FORWARDS\n",
    "fw_mask = df['Position_Group'] == 'Forward'\n",
    "if fw_mask.sum() > 0:\n",
    "    print(\"\\nForwards:\", fw_mask.sum(), \"records\")\n",
    "    \n",
    "    fw_data = df[fw_mask].copy()\n",
    "    \n",
    "    # Calculate per-90 stats\n",
    "    fw_data['Gls_90'] = per_90(fw_data['Gls'], fw_data['Min'])\n",
    "    fw_data['Ast_90'] = per_90(fw_data['Ast'], fw_data['Min'])\n",
    "    fw_data['Sh_90'] = per_90(fw_data['Sh'], fw_data['Min'])\n",
    "    fw_data['SoT_90'] = per_90(fw_data['SoT'], fw_data['Min'])\n",
    "    fw_data['xG_90'] = per_90(fw_data['Expected xG'], fw_data['Min'])\n",
    "    \n",
    "    # Get max values for normalization (avoid division by zero)\n",
    "    _, max_g = safe_min_max(fw_data['Gls_90'])\n",
    "    _, max_s = safe_min_max(fw_data['Sh_90'])\n",
    "    _, max_sot = safe_min_max(fw_data['SoT_90'])\n",
    "    _, max_xg = safe_min_max(fw_data['xG_90'])\n",
    "    \n",
    "    max_g = max(max_g, 0.1)\n",
    "    max_s = max(max_s, 0.1)\n",
    "    max_sot = max(max_sot, 0.1)\n",
    "    max_xg = max(max_xg, 0.1)\n",
    "    \n",
    "    # Calculate weighted score\n",
    "    fw_score = (\n",
    "        (fw_data['Gls_90'] / max_g * 100) * 0.35 +      # Goals 35%\n",
    "        (fw_data['Ast_90'] * 25) * 0.20 +               # Assists 20%\n",
    "        (fw_data['Sh_90'] / max_s * 100) * 0.05 +       # Shots 5%\n",
    "        (fw_data['SoT_90'] / max_sot * 100) * 0.15 +    # SoT 15%\n",
    "        (fw_data['xG_90'] / max_xg * 100) * 0.15 +      # xG 15%\n",
    "        fw_data['Take-Ons Succ%'] * 0.10                # Take-ons 10%\n",
    "    )\n",
    "    \n",
    "    df.loc[fw_mask, 'Performance_Score'] = fw_score\n",
    "    min_score, max_score = safe_min_max(fw_score)\n",
    "    print(\"  âœ“ Score range:\", round(min_score, 1), \"-\", round(max_score, 1))\n",
    "\n",
    "# MIDFIELDERS\n",
    "mid_mask = df['Position_Group'] == 'Midfield'\n",
    "if mid_mask.sum() > 0:\n",
    "    print(\"\\nMidfielders:\", mid_mask.sum(), \"records\")\n",
    "    \n",
    "    mid_data = df[mid_mask].copy()\n",
    "    \n",
    "    # Calculate per-90 stats\n",
    "    mid_data['Pass_90'] = per_90(mid_data['Total Att'], mid_data['Min'])\n",
    "    mid_data['Prog_90'] = per_90(mid_data['Passes PrgP'], mid_data['Min'])\n",
    "    mid_data['SCA_90'] = per_90(mid_data['SCA'], mid_data['Min'])\n",
    "    mid_data['KP_90'] = per_90(mid_data['KP'], mid_data['Min'])\n",
    "    mid_data['Ast_90'] = per_90(mid_data['Ast'], mid_data['Min'])\n",
    "    \n",
    "    # Get max values for normalization\n",
    "    _, max_pass = safe_min_max(mid_data['Pass_90'])\n",
    "    _, max_prog = safe_min_max(mid_data['Prog_90'])\n",
    "    _, max_sca = safe_min_max(mid_data['SCA_90'])\n",
    "    _, max_kp = safe_min_max(mid_data['KP_90'])\n",
    "    \n",
    "    max_pass = max(max_pass, 0.1)\n",
    "    max_prog = max(max_prog, 0.1)\n",
    "    max_sca = max(max_sca, 0.1)\n",
    "    max_kp = max(max_kp, 0.1)\n",
    "    \n",
    "    # Calculate weighted score\n",
    "    mid_score = (\n",
    "        mid_data['Total Cmp%'] * 0.20 +                         # Pass accuracy 20%\n",
    "        (mid_data['Pass_90'] / max_pass * 100) * 0.15 +         # Pass volume 15%\n",
    "        (mid_data['Prog_90'] / max_prog * 100) * 0.20 +         # Progressive 20%\n",
    "        (mid_data['SCA_90'] / max_sca * 100) * 0.20 +           # Creativity 20%\n",
    "        (mid_data['KP_90'] / max_kp * 100) * 0.15 +             # Key passes 15%\n",
    "        (mid_data['Ast_90'] * 25) * 0.10                        # Assists 10%\n",
    "    )\n",
    "    \n",
    "    df.loc[mid_mask, 'Performance_Score'] = mid_score\n",
    "    min_score, max_score = safe_min_max(mid_score)\n",
    "    print(\"  âœ“ Score range:\", round(min_score, 1), \"-\", round(max_score, 1))\n",
    "\n",
    "# DEFENDERS\n",
    "def_mask = df['Position_Group'] == 'Defense'\n",
    "if def_mask.sum() > 0:\n",
    "    print(\"\\nDefenders:\", def_mask.sum(), \"records\")\n",
    "    \n",
    "    def_data = df[def_mask].copy()\n",
    "    \n",
    "    # Calculate per-90 stats\n",
    "    def_data['Tkl_90'] = per_90(def_data['Tkl'], def_data['Min'])\n",
    "    def_data['Int_90'] = per_90(def_data['Int'], def_data['Min'])\n",
    "    def_data['Blk_90'] = per_90(def_data['Blocks'], def_data['Min'])\n",
    "    def_data['Clr_90'] = per_90(def_data['Clr'], def_data['Min'])\n",
    "    \n",
    "    # Get max values for normalization\n",
    "    _, max_tkl = safe_min_max(def_data['Tkl_90'])\n",
    "    _, max_int = safe_min_max(def_data['Int_90'])\n",
    "    _, max_blk = safe_min_max(def_data['Blk_90'])\n",
    "    _, max_clr = safe_min_max(def_data['Clr_90'])\n",
    "    \n",
    "    max_tkl = max(max_tkl, 0.1)\n",
    "    max_int = max(max_int, 0.1)\n",
    "    max_blk = max(max_blk, 0.1)\n",
    "    max_clr = max(max_clr, 0.1)\n",
    "    \n",
    "    # Calculate weighted score\n",
    "    def_score = (\n",
    "        (def_data['Tkl_90'] / max_tkl * 100) * 0.25 +           # Tackles 25%\n",
    "        (def_data['Int_90'] / max_int * 100) * 0.25 +           # Interceptions 25%\n",
    "        (def_data['Blk_90'] / max_blk * 100) * 0.20 +           # Blocks 20%\n",
    "        (def_data['Clr_90'] / max_clr * 100) * 0.15 +           # Clearances 15%\n",
    "        def_data['Total Cmp%'] * 0.15                           # Pass accuracy 15%\n",
    "    )\n",
    "    \n",
    "    df.loc[def_mask, 'Performance_Score'] = def_score\n",
    "    min_score, max_score = safe_min_max(def_score)\n",
    "    print(\"  âœ“ Score range:\", round(min_score, 1), \"-\", round(max_score, 1))\n",
    "\n",
    "# Cap all scores at 100\n",
    "df['Performance_Score'] = df['Performance_Score'].clip(0, 100)\n",
    "\n",
    "print(\"\\nâœ… SCORING COMPLETED\")\n",
    "overall_min = float(df['Performance_Score'].min())\n",
    "overall_max = float(df['Performance_Score'].max())\n",
    "print(\"Overall range:\", round(overall_min, 1), \"-\", round(overall_max, 1))\n",
    "\n",
    "# ==========================================\n",
    "# PHASE 3: ANALYSIS & RESULTS\n",
    "# ==========================================\n",
    "\n",
    "print(\"\\nðŸ“Š PHASE 3: ANALYSIS & RESULTS\")\n",
    "\n",
    "# Check Antonio RÃ¼diger specifically\n",
    "print(\"\\n=== VALIDATION CHECK ===\")\n",
    "rudiger = df[df['Player'].str.contains('RÃ¼diger', na=False, case=False)]\n",
    "if len(rudiger) > 0:\n",
    "    rudiger_avg = rudiger['Performance_Score'].mean()\n",
    "    print(\"âœ“ RÃ¼diger average score:\", round(rudiger_avg, 1), \"(should not be 50.0)\")\n",
    "    rudiger_best = rudiger.nlargest(3, 'Performance_Score')[\n",
    "        ['Date', 'Performance_Score', 'Min', 'Tkl', 'Int', 'Blocks', 'Total Cmp%']\n",
    "    ]\n",
    "    print(\"âœ“ RÃ¼diger's top performances:\")\n",
    "    print(rudiger_best.to_string(index=False))\n",
    "\n",
    "# Top performances\n",
    "print(\"\\n=== TOP 15 INDIVIDUAL PERFORMANCES ===\")\n",
    "top_individual = df.nlargest(15, 'Performance_Score')[\n",
    "    ['Date', 'Player', 'Position_Group', 'Performance_Score', 'Min', 'Gls', 'Ast', 'Opponent']\n",
    "]\n",
    "print(top_individual.to_string(index=False))\n",
    "\n",
    "# Player averages\n",
    "print(\"\\n=== BEST SEASON AVERAGES (500+ minutes) ===\")\n",
    "player_avg = df.groupby(['Player', 'Position_Group', 'Season']).agg({\n",
    "    'Performance_Score': 'mean',\n",
    "    'Min': 'sum',\n",
    "    'Gls': 'sum',\n",
    "    'Ast': 'sum',\n",
    "    'Age': 'first',\n",
    "    'Nation': 'first'\n",
    "}).round(2).reset_index()\n",
    "\n",
    "significant_players = player_avg[player_avg['Min'] >= 500]\n",
    "top_averages = significant_players.nlargest(15, 'Performance_Score')\n",
    "print(top_averages.to_string(index=False))\n",
    "\n",
    "# ==========================================\n",
    "# PHASE 4: SAVE RESULTS\n",
    "# ==========================================\n",
    "\n",
    "print(\"\\nðŸ’¾ PHASE 4: SAVING RESULTS\")\n",
    "\n",
    "output_dir = '/Users/mariamoramora/Documents/GitHub/ADS599_Capstone/Soccer_Performance_Score/data/real_madrid_combined'\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Save complete cleaned dataset\n",
    "final_path = output_dir + '/real_madrid_cleaned_with_scores.csv'\n",
    "df.to_csv(final_path, index=False)\n",
    "\n",
    "# Save player averages\n",
    "averages_path = output_dir + '/player_season_averages_clean.csv'\n",
    "player_avg.to_csv(averages_path, index=False)\n",
    "\n",
    "print(\"âœ… SAVED:\")\n",
    "print(\"ðŸ“Š Complete cleaned data:\", final_path)\n",
    "print(\"ðŸ† Player averages:\", averages_path)\n",
    "\n",
    "print(\"\\nðŸŽ¯ FINAL SUMMARY:\")\n",
    "print(\"â€¢ Processed\", len(df), \"match records\")\n",
    "print(\"â€¢ Unique players:\", df['Player'].nunique())\n",
    "print(\"â€¢ Age range:\", df['Age'].min(), \"-\", df['Age'].max(), \"years\")\n",
    "print(\"â€¢ Nations:\", df['Nation'].nunique(), \"different countries\")\n",
    "print(\"â€¢ Players with 500+ minutes:\", len(significant_players))\n",
    "best_performer = df.loc[df['Performance_Score'].idxmax(), 'Player']\n",
    "best_score = float(df['Performance_Score'].max())\n",
    "print(\"â€¢ Best performer:\", best_performer, \"(\" + str(round(best_score, 1)) + \")\")\n",
    "\n",
    "print(\"\\nðŸ† REAL MADRID ANALYSIS COMPLETE! ðŸ†\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== REAL MADRID DATA PREPROCESSING & PERFORMANCE ANALYSIS ===\n",
      "âœ“ Loaded dataset: (1550, 73)\n",
      "Original columns: 73\n",
      "\n",
      "ðŸ§¹ PHASE 1: DATA CLEANING & PREPROCESSING\n",
      "âœ“ Removed columns: ['Match URL', 'Challenges Tkl%', 'number']\n",
      "âœ“ Cleaning Age column...\n",
      "  Age range: 17 - 39\n",
      "âœ“ Cleaning Nation column...\n",
      "  Sample nations: ['BRA', 'CRO', 'ESP', 'ENG', 'FRA', 'GER', 'URU', 'AUT', 'UKR', 'MAR']\n",
      "âœ“ Column names cleaned\n",
      "âœ“ Basic setup complete\n",
      "Cleaned dataset shape: (1550, 72)\n",
      "Position distribution: {'Defense': 483, 'Midfield': 410, 'Forward': 211, 'Goalkeeper': 104}\n",
      "\n",
      "Cleaning statistical columns...\n",
      "  Processing Min\n",
      "    âœ“ Range: 1 - 120\n",
      "  Processing Gls\n",
      "    âœ“ Range: 0 - 3\n",
      "  Processing Ast\n",
      "    âš ï¸ Could not calculate range, but column processed\n",
      "  Processing Sh\n",
      "    âœ“ Range: 0 - 11\n",
      "  Processing SoT\n",
      "    âœ“ Range: 0 - 5\n",
      "  Processing Tkl\n",
      "    âœ“ Range: 0 - 10\n",
      "  Processing Int\n",
      "    âš ï¸ Could not calculate range, but column processed\n",
      "  Processing Blocks\n",
      "    âœ“ Range: 0 - 7\n",
      "  Processing Clr\n",
      "    âœ“ Range: 0 - 14\n",
      "  Processing SCA\n",
      "    âœ“ Range: 0 - 13\n",
      "  Processing KP\n",
      "    âœ“ Range: 0 - 8\n",
      "  Processing Expected xG\n",
      "    âœ“ Range: 0.0 - 2.1\n",
      "  Processing Total Cmp%\n",
      "    âœ“ Range: 0.0 - 100.0\n",
      "  Processing Long Cmp%\n",
      "    âœ“ Range: 0.0 - 100.0\n",
      "  Processing Total Att\n",
      "    âœ“ Range: 0 - 135\n",
      "  Processing Passes PrgP\n",
      "    âœ“ Range: 0 - 23\n",
      "âœ“ Take-on statistics calculated\n",
      "âœ“ Data preprocessing completed\n",
      "\n",
      "âš½ PHASE 2: CALCULATING PERFORMANCE SCORES\n",
      "\n",
      "Goalkeepers: 104 records\n",
      "  âœ“ Score range: 44.0 - 100.0\n",
      "\n",
      "Forwards: 211 records\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "operands could not be broadcast together with shapes (211,2) (211,) ",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[31], line 178\u001b[0m\n\u001b[1;32m    176\u001b[0m \u001b[38;5;66;03m# Calculate per-90 stats using numpy operations\u001b[39;00m\n\u001b[1;32m    177\u001b[0m fw_data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mGls_90\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mwhere(min_values \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m, gls_values \u001b[38;5;241m/\u001b[39m min_values \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m90\u001b[39m, \u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m--> 178\u001b[0m fw_data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAst_90\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mwhere(min_values \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m, ast_values \u001b[38;5;241m/\u001b[39m min_values \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m90\u001b[39m, \u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m    179\u001b[0m fw_data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSh_90\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mwhere(min_values \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m, sh_values \u001b[38;5;241m/\u001b[39m min_values \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m90\u001b[39m, \u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m    180\u001b[0m fw_data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSoT_90\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mwhere(min_values \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m, sot_values \u001b[38;5;241m/\u001b[39m min_values \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m90\u001b[39m, \u001b[38;5;241m0\u001b[39m)\n",
      "\u001b[0;31mValueError\u001b[0m: operands could not be broadcast together with shapes (211,2) (211,) "
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "print(\"=== REAL MADRID DATA PREPROCESSING & PERFORMANCE ANALYSIS ===\")\n",
    "\n",
    "# Load the data\n",
    "original_path = '/Users/mariamoramora/Documents/GitHub/ADS599_Capstone/Soccer_Performance_Score/data/real_madrid_combined/combined_real_madrid.csv'\n",
    "\n",
    "try:\n",
    "    df = pd.read_csv(original_path)\n",
    "    print(\"âœ“ Loaded dataset:\", df.shape)\n",
    "except FileNotFoundError:\n",
    "    print(\"âŒ File not found:\", original_path)\n",
    "    exit()\n",
    "\n",
    "print(\"Original columns:\", len(df.columns))\n",
    "\n",
    "# ==========================================\n",
    "# PHASE 1: DATA CLEANING & PREPROCESSING\n",
    "# ==========================================\n",
    "\n",
    "print(\"\\nðŸ§¹ PHASE 1: DATA CLEANING & PREPROCESSING\")\n",
    "\n",
    "# 1. Remove problematic columns\n",
    "columns_to_remove = ['Match URL', 'Challenges Tkl%', 'number']\n",
    "existing_cols_to_remove = [col for col in columns_to_remove if col in df.columns]\n",
    "if existing_cols_to_remove:\n",
    "    df = df.drop(columns=existing_cols_to_remove)\n",
    "    print(\"âœ“ Removed columns:\", existing_cols_to_remove)\n",
    "\n",
    "# 2. Clean Age column (remove everything after the dash)\n",
    "if 'Age' in df.columns:\n",
    "    print(\"âœ“ Cleaning Age column...\")\n",
    "    df['Age'] = df['Age'].astype(str).str.split('-').str[0]\n",
    "    df['Age'] = pd.to_numeric(df['Age'], errors='coerce').fillna(0).astype(int)\n",
    "    print(\"  Age range:\", df['Age'].min(), \"-\", df['Age'].max())\n",
    "\n",
    "# 3. Clean Nation column (keep only last 3 characters)\n",
    "if 'Nation' in df.columns:\n",
    "    print(\"âœ“ Cleaning Nation column...\")\n",
    "    df['Nation'] = df['Nation'].astype(str).str[-3:]\n",
    "    print(\"  Sample nations:\", df['Nation'].unique()[:10].tolist())\n",
    "\n",
    "# 4. Clean column names\n",
    "df.columns = df.columns.str.strip()\n",
    "print(\"âœ“ Column names cleaned\")\n",
    "\n",
    "# 5. Setup Date and Season\n",
    "df['Date'] = pd.to_datetime(df['Date'], format='%m/%d/%y', errors='coerce')\n",
    "df['Season'] = df['Date'].apply(lambda x: \n",
    "    str(x.year) + \"-\" + str(x.year + 1)[-2:] if pd.notna(x) and x.month >= 8 \n",
    "    else str(x.year - 1) + \"-\" + str(x.year)[-2:] if pd.notna(x) else \"Unknown\"\n",
    ")\n",
    "\n",
    "# 6. Position mapping\n",
    "position_mapping = {\n",
    "    'GK': 'Goalkeeper', 'CB': 'Defense', 'LB': 'Defense', 'RB': 'Defense',\n",
    "    'DM': 'Midfield', 'CM': 'Midfield', 'LM': 'Midfield', 'RM': 'Midfield', 'AM': 'Midfield',\n",
    "    'FW': 'Forward'\n",
    "}\n",
    "df['Position_Group'] = df['Pos'].map(position_mapping)\n",
    "\n",
    "print(\"âœ“ Basic setup complete\")\n",
    "print(\"Cleaned dataset shape:\", df.shape)\n",
    "print(\"Position distribution:\", df['Position_Group'].value_counts().to_dict())\n",
    "\n",
    "# 7. Clean key statistical columns\n",
    "def safe_numeric_conversion(series, default_value=0):\n",
    "    \"\"\"Convert series to numeric safely\"\"\"\n",
    "    try:\n",
    "        # Convert to string first, handle empty/null values\n",
    "        series_str = series.astype(str).replace(['nan', 'NaN', '', ' ', 'None'], '0')\n",
    "        # Convert to numeric\n",
    "        result = pd.to_numeric(series_str, errors='coerce').fillna(default_value)\n",
    "        return result\n",
    "    except:\n",
    "        # If anything fails, return default values\n",
    "        return pd.Series([default_value] * len(series))\n",
    "\n",
    "# Key columns we need for analysis\n",
    "key_stats = {\n",
    "    'Min': 0, 'Gls': 0, 'Ast': 0, 'Sh': 0, 'SoT': 0, 'Tkl': 0, 'Int': 0, \n",
    "    'Blocks': 0, 'Clr': 0, 'SCA': 0, 'KP': 0, 'Expected xG': 0,\n",
    "    'Total Cmp%': 0, 'Long Cmp%': 0, 'Total Att': 0, 'Passes PrgP': 0\n",
    "}\n",
    "\n",
    "print(\"\\nCleaning statistical columns...\")\n",
    "for col, default in key_stats.items():\n",
    "    if col in df.columns:\n",
    "        print(\"  Processing\", col)\n",
    "        df[col] = safe_numeric_conversion(df[col], default)\n",
    "        \n",
    "        # Safe min/max calculation with error handling\n",
    "        try:\n",
    "            col_values = df[col]\n",
    "            if len(col_values) > 0:\n",
    "                # Ensure all values are numeric\n",
    "                numeric_values = pd.to_numeric(col_values, errors='coerce')\n",
    "                if not numeric_values.isnull().all():\n",
    "                    min_val = numeric_values.min()\n",
    "                    max_val = numeric_values.max()\n",
    "                    print(\"    âœ“ Range:\", round(min_val, 1), \"-\", round(max_val, 1))\n",
    "                else:\n",
    "                    print(\"    âœ“ All values set to default:\", default)\n",
    "            else:\n",
    "                print(\"    âœ“ Empty column, set to default:\", default)\n",
    "        except Exception as e:\n",
    "            print(\"    âš ï¸ Could not calculate range, but column processed\")\n",
    "    else:\n",
    "        df[col] = default\n",
    "        print(\"  + Created\", col, \"=\", default)\n",
    "\n",
    "# 8. Handle Take-ons\n",
    "if 'Take-Ons Att' in df.columns and 'Take-Ons Succ' in df.columns:\n",
    "    df['Take-Ons Att'] = safe_numeric_conversion(df['Take-Ons Att'], 0)\n",
    "    df['Take-Ons Succ'] = safe_numeric_conversion(df['Take-Ons Succ'], 0)\n",
    "    df['Take-Ons Succ%'] = np.where(df['Take-Ons Att'] > 0, \n",
    "                                   (df['Take-Ons Succ'] / df['Take-Ons Att'] * 100), 0)\n",
    "    print(\"âœ“ Take-on statistics calculated\")\n",
    "else:\n",
    "    df['Take-Ons Succ%'] = 0\n",
    "    print(\"âœ“ Take-on columns not found, set to 0\")\n",
    "\n",
    "print(\"âœ“ Data preprocessing completed\")\n",
    "\n",
    "# ==========================================\n",
    "# PHASE 2: PERFORMANCE SCORING\n",
    "# ==========================================\n",
    "\n",
    "print(\"\\nâš½ PHASE 2: CALCULATING PERFORMANCE SCORES\")\n",
    "\n",
    "df['Performance_Score'] = 0.0\n",
    "\n",
    "# Helper function for per-90 calculations\n",
    "def per_90(stat, minutes):\n",
    "    return np.where(minutes > 0, stat / minutes * 90, 0)\n",
    "\n",
    "# Safe function to get numeric min/max\n",
    "def safe_min_max(series):\n",
    "    try:\n",
    "        numeric_series = pd.to_numeric(series, errors='coerce')\n",
    "        if not numeric_series.isnull().all():\n",
    "            return numeric_series.min(), numeric_series.max()\n",
    "        else:\n",
    "            return 0.0, 0.0\n",
    "    except:\n",
    "        return 0.0, 0.0\n",
    "\n",
    "# GOALKEEPERS\n",
    "gk_mask = df['Position_Group'] == 'Goalkeeper'\n",
    "if gk_mask.sum() > 0:\n",
    "    print(\"\\nGoalkeepers:\", gk_mask.sum(), \"records\")\n",
    "    gk_score = df.loc[gk_mask, 'Total Cmp%'] * 0.6 + df.loc[gk_mask, 'Long Cmp%'] * 0.4\n",
    "    df.loc[gk_mask, 'Performance_Score'] = gk_score\n",
    "    min_score, max_score = safe_min_max(gk_score)\n",
    "    print(\"  âœ“ Score range:\", round(min_score, 1), \"-\", round(max_score, 1))\n",
    "\n",
    "# FORWARDS\n",
    "fw_mask = df['Position_Group'] == 'Forward'\n",
    "if fw_mask.sum() > 0:\n",
    "    print(\"\\nForwards:\", fw_mask.sum(), \"records\")\n",
    "    \n",
    "    # Create clean copy with reset index to avoid duplicate index issues\n",
    "    fw_data = df[fw_mask].copy().reset_index(drop=True)\n",
    "    \n",
    "    # Calculate per-90 stats using numpy arrays to avoid pandas alignment issues\n",
    "    min_values = fw_data['Min'].values\n",
    "    gls_values = fw_data['Gls'].values\n",
    "    ast_values = fw_data['Ast'].values\n",
    "    sh_values = fw_data['Sh'].values\n",
    "    sot_values = fw_data['SoT'].values\n",
    "    xg_values = fw_data['Expected xG'].values\n",
    "    takeon_values = fw_data['Take-Ons Succ%'].values\n",
    "    \n",
    "    # Calculate per-90 stats using numpy operations\n",
    "    fw_data['Gls_90'] = np.where(min_values > 0, gls_values / min_values * 90, 0)\n",
    "    fw_data['Ast_90'] = np.where(min_values > 0, ast_values / min_values * 90, 0)\n",
    "    fw_data['Sh_90'] = np.where(min_values > 0, sh_values / min_values * 90, 0)\n",
    "    fw_data['SoT_90'] = np.where(min_values > 0, sot_values / min_values * 90, 0)\n",
    "    fw_data['xG_90'] = np.where(min_values > 0, xg_values / min_values * 90, 0)\n",
    "    \n",
    "    # Get max values for normalization\n",
    "    _, max_g = safe_min_max(fw_data['Gls_90'])\n",
    "    _, max_s = safe_min_max(fw_data['Sh_90'])\n",
    "    _, max_sot = safe_min_max(fw_data['SoT_90'])\n",
    "    _, max_xg = safe_min_max(fw_data['xG_90'])\n",
    "    \n",
    "    max_g = max(max_g, 0.1)\n",
    "    max_s = max(max_s, 0.1)\n",
    "    max_sot = max(max_sot, 0.1)\n",
    "    max_xg = max(max_xg, 0.1)\n",
    "    \n",
    "    # Calculate weighted score\n",
    "    fw_score = (\n",
    "        (fw_data['Gls_90'] / max_g * 100) * 0.35 +      # Goals 35%\n",
    "        (fw_data['Ast_90'] * 25) * 0.20 +               # Assists 20%\n",
    "        (fw_data['Sh_90'] / max_s * 100) * 0.05 +       # Shots 5%\n",
    "        (fw_data['SoT_90'] / max_sot * 100) * 0.15 +    # SoT 15%\n",
    "        (fw_data['xG_90'] / max_xg * 100) * 0.15 +      # xG 15%\n",
    "        takeon_values * 0.10                            # Take-ons 10%\n",
    "    )\n",
    "    \n",
    "    # Update main dataframe using the original indices\n",
    "    original_indices = df[fw_mask].index\n",
    "    df.loc[original_indices, 'Performance_Score'] = fw_score.values\n",
    "    \n",
    "    min_score, max_score = safe_min_max(fw_score)\n",
    "    print(\"  âœ“ Score range:\", round(min_score, 1), \"-\", round(max_score, 1))\n",
    "\n",
    "# MIDFIELDERS\n",
    "mid_mask = df['Position_Group'] == 'Midfield'\n",
    "if mid_mask.sum() > 0:\n",
    "    print(\"\\nMidfielders:\", mid_mask.sum(), \"records\")\n",
    "    \n",
    "    # Create clean copy with reset index\n",
    "    mid_data = df[mid_mask].copy().reset_index(drop=True)\n",
    "    \n",
    "    # Calculate per-90 stats using numpy arrays\n",
    "    min_values = mid_data['Min'].values\n",
    "    att_values = mid_data['Total Att'].values\n",
    "    prog_values = mid_data['Passes PrgP'].values\n",
    "    sca_values = mid_data['SCA'].values\n",
    "    kp_values = mid_data['KP'].values\n",
    "    ast_values = mid_data['Ast'].values\n",
    "    cmp_pct_values = mid_data['Total Cmp%'].values\n",
    "    \n",
    "    # Calculate per-90 stats\n",
    "    mid_data['Pass_90'] = np.where(min_values > 0, att_values / min_values * 90, 0)\n",
    "    mid_data['Prog_90'] = np.where(min_values > 0, prog_values / min_values * 90, 0)\n",
    "    mid_data['SCA_90'] = np.where(min_values > 0, sca_values / min_values * 90, 0)\n",
    "    mid_data['KP_90'] = np.where(min_values > 0, kp_values / min_values * 90, 0)\n",
    "    mid_data['Ast_90'] = np.where(min_values > 0, ast_values / min_values * 90, 0)\n",
    "    \n",
    "    # Get max values for normalization\n",
    "    _, max_pass = safe_min_max(mid_data['Pass_90'])\n",
    "    _, max_prog = safe_min_max(mid_data['Prog_90'])\n",
    "    _, max_sca = safe_min_max(mid_data['SCA_90'])\n",
    "    _, max_kp = safe_min_max(mid_data['KP_90'])\n",
    "    \n",
    "    max_pass = max(max_pass, 0.1)\n",
    "    max_prog = max(max_prog, 0.1)\n",
    "    max_sca = max(max_sca, 0.1)\n",
    "    max_kp = max(max_kp, 0.1)\n",
    "    \n",
    "    # Calculate weighted score\n",
    "    mid_score = (\n",
    "        cmp_pct_values * 0.20 +                                 # Pass accuracy 20%\n",
    "        (mid_data['Pass_90'] / max_pass * 100) * 0.15 +         # Pass volume 15%\n",
    "        (mid_data['Prog_90'] / max_prog * 100) * 0.20 +         # Progressive 20%\n",
    "        (mid_data['SCA_90'] / max_sca * 100) * 0.20 +           # Creativity 20%\n",
    "        (mid_data['KP_90'] / max_kp * 100) * 0.15 +             # Key passes 15%\n",
    "        (mid_data['Ast_90'] * 25) * 0.10                        # Assists 10%\n",
    "    )\n",
    "    \n",
    "    # Update main dataframe\n",
    "    original_indices = df[mid_mask].index\n",
    "    df.loc[original_indices, 'Performance_Score'] = mid_score.values\n",
    "    \n",
    "    min_score, max_score = safe_min_max(mid_score)\n",
    "    print(\"  âœ“ Score range:\", round(min_score, 1), \"-\", round(max_score, 1))\n",
    "\n",
    "# DEFENDERS\n",
    "def_mask = df['Position_Group'] == 'Defense'\n",
    "if def_mask.sum() > 0:\n",
    "    print(\"\\nDefenders:\", def_mask.sum(), \"records\")\n",
    "    \n",
    "    # Create clean copy with reset index\n",
    "    def_data = df[def_mask].copy().reset_index(drop=True)\n",
    "    \n",
    "    # Calculate per-90 stats using numpy arrays\n",
    "    min_values = def_data['Min'].values\n",
    "    tkl_values = def_data['Tkl'].values\n",
    "    int_values = def_data['Int'].values\n",
    "    blk_values = def_data['Blocks'].values\n",
    "    clr_values = def_data['Clr'].values\n",
    "    cmp_pct_values = def_data['Total Cmp%'].values\n",
    "    \n",
    "    # Calculate per-90 stats\n",
    "    def_data['Tkl_90'] = np.where(min_values > 0, tkl_values / min_values * 90, 0)\n",
    "    def_data['Int_90'] = np.where(min_values > 0, int_values / min_values * 90, 0)\n",
    "    def_data['Blk_90'] = np.where(min_values > 0, blk_values / min_values * 90, 0)\n",
    "    def_data['Clr_90'] = np.where(min_values > 0, clr_values / min_values * 90, 0)\n",
    "    \n",
    "    # Get max values for normalization\n",
    "    _, max_tkl = safe_min_max(def_data['Tkl_90'])\n",
    "    _, max_int = safe_min_max(def_data['Int_90'])\n",
    "    _, max_blk = safe_min_max(def_data['Blk_90'])\n",
    "    _, max_clr = safe_min_max(def_data['Clr_90'])\n",
    "    \n",
    "    max_tkl = max(max_tkl, 0.1)\n",
    "    max_int = max(max_int, 0.1)\n",
    "    max_blk = max(max_blk, 0.1)\n",
    "    max_clr = max(max_clr, 0.1)\n",
    "    \n",
    "    # Calculate weighted score\n",
    "    def_score = (\n",
    "        (def_data['Tkl_90'] / max_tkl * 100) * 0.25 +           # Tackles 25%\n",
    "        (def_data['Int_90'] / max_int * 100) * 0.25 +           # Interceptions 25%\n",
    "        (def_data['Blk_90'] / max_blk * 100) * 0.20 +           # Blocks 20%\n",
    "        (def_data['Clr_90'] / max_clr * 100) * 0.15 +           # Clearances 15%\n",
    "        cmp_pct_values * 0.15                                   # Pass accuracy 15%\n",
    "    )\n",
    "    \n",
    "    # Update main dataframe\n",
    "    original_indices = df[def_mask].index\n",
    "    df.loc[original_indices, 'Performance_Score'] = def_score.values\n",
    "    \n",
    "    min_score, max_score = safe_min_max(def_score)\n",
    "    print(\"  âœ“ Score range:\", round(min_score, 1), \"-\", round(max_score, 1))\n",
    "\n",
    "# Cap all scores at 100\n",
    "df['Performance_Score'] = df['Performance_Score'].clip(0, 100)\n",
    "\n",
    "print(\"\\nâœ… SCORING COMPLETED\")\n",
    "overall_min = float(df['Performance_Score'].min())\n",
    "overall_max = float(df['Performance_Score'].max())\n",
    "print(\"Overall range:\", round(overall_min, 1), \"-\", round(overall_max, 1))\n",
    "\n",
    "# ==========================================\n",
    "# PHASE 3: ANALYSIS & RESULTS\n",
    "# ==========================================\n",
    "\n",
    "print(\"\\nðŸ“Š PHASE 3: ANALYSIS & RESULTS\")\n",
    "\n",
    "# Check Antonio RÃ¼diger specifically\n",
    "print(\"\\n=== VALIDATION CHECK ===\")\n",
    "rudiger = df[df['Player'].str.contains('RÃ¼diger', na=False, case=False)]\n",
    "if len(rudiger) > 0:\n",
    "    rudiger_avg = rudiger['Performance_Score'].mean()\n",
    "    print(\"âœ“ RÃ¼diger average score:\", round(rudiger_avg, 1), \"(should not be 50.0)\")\n",
    "    rudiger_best = rudiger.nlargest(3, 'Performance_Score')[\n",
    "        ['Date', 'Performance_Score', 'Min', 'Tkl', 'Int', 'Blocks', 'Total Cmp%']\n",
    "    ]\n",
    "    print(\"âœ“ RÃ¼diger's top performances:\")\n",
    "    print(rudiger_best.to_string(index=False))\n",
    "\n",
    "# Top performances\n",
    "print(\"\\n=== TOP 15 INDIVIDUAL PERFORMANCES ===\")\n",
    "top_individual = df.nlargest(15, 'Performance_Score')[\n",
    "    ['Date', 'Player', 'Position_Group', 'Performance_Score', 'Min', 'Gls', 'Ast', 'Opponent']\n",
    "]\n",
    "print(top_individual.to_string(index=False))\n",
    "\n",
    "# Player averages\n",
    "print(\"\\n=== BEST SEASON AVERAGES (500+ minutes) ===\")\n",
    "player_avg = df.groupby(['Player', 'Position_Group', 'Season']).agg({\n",
    "    'Performance_Score': 'mean',\n",
    "    'Min': 'sum',\n",
    "    'Gls': 'sum',\n",
    "    'Ast': 'sum',\n",
    "    'Age': 'first',\n",
    "    'Nation': 'first'\n",
    "}).round(2).reset_index()\n",
    "\n",
    "significant_players = player_avg[player_avg['Min'] >= 500]\n",
    "top_averages = significant_players.nlargest(15, 'Performance_Score')\n",
    "print(top_averages.to_string(index=False))\n",
    "\n",
    "# ==========================================\n",
    "# PHASE 4: SAVE RESULTS\n",
    "# ==========================================\n",
    "\n",
    "print(\"\\nðŸ’¾ PHASE 4: SAVING RESULTS\")\n",
    "\n",
    "output_dir = '/Users/mariamoramora/Documents/GitHub/ADS599_Capstone/Soccer_Performance_Score/data/real_madrid_combined'\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Save complete cleaned dataset\n",
    "final_path = output_dir + '/real_madrid_cleaned_with_scores.csv'\n",
    "df.to_csv(final_path, index=False)\n",
    "\n",
    "# Save player averages\n",
    "averages_path = output_dir + '/player_season_averages_clean.csv'\n",
    "player_avg.to_csv(averages_path, index=False)\n",
    "\n",
    "print(\"âœ… SAVED:\")\n",
    "print(\"ðŸ“Š Complete cleaned data:\", final_path)\n",
    "print(\"ðŸ† Player averages:\", averages_path)\n",
    "\n",
    "print(\"\\nðŸŽ¯ FINAL SUMMARY:\")\n",
    "print(\"â€¢ Processed\", len(df), \"match records\")\n",
    "print(\"â€¢ Unique players:\", df['Player'].nunique())\n",
    "print(\"â€¢ Age range:\", df['Age'].min(), \"-\", df['Age'].max(), \"years\")\n",
    "print(\"â€¢ Nations:\", df['Nation'].nunique(), \"different countries\")\n",
    "print(\"â€¢ Players with 500+ minutes:\", len(significant_players))\n",
    "best_performer = df.loc[df['Performance_Score'].idxmax(), 'Player']\n",
    "best_score = float(df['Performance_Score'].max())\n",
    "print(\"â€¢ Best performer:\", best_performer, \"(\" + str(round(best_score, 1)) + \")\")\n",
    "\n",
    "print(\"\\nðŸ† REAL MADRID ANALYSIS COMPLETE! ðŸ†\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
