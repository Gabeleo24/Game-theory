{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Soccer_Performance_Score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 | Combine 2 seasons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found CSV files: ['/Users/mariamoramora/Documents/GitHub/ADS599_Capstone/Soccer_Performance_Score/data/real_madrid/real_madrid_23_24.csv', '/Users/mariamoramora/Documents/GitHub/ADS599_Capstone/Soccer_Performance_Score/data/real_madrid/real_madrid_24_25.csv']\n",
      "\n",
      "File: /Users/mariamoramora/Documents/GitHub/ADS599_Capstone/Soccer_Performance_Score/data/real_madrid/real_madrid_23_24.csv\n",
      "Shape: (774, 73)\n",
      "Columns: ['Date', 'Competition', 'Opponent', 'Player', '#', 'Nation', 'Pos', 'Age', 'Min', ' Gls', ' Ast', ' PK', ' PKatt', ' Sh', ' SoT', ' CrdY', ' CrdR', ' Touches', ' Tkl', ' Int', ' Blocks', 'Expected xG', 'Expected npxG', 'Expected xAG', 'SCA', 'GCA', 'Passes Cmp', 'Passes Att', 'Passes Cmp%', 'Passes PrgP', 'Carries Carries', 'Carries PrgC', 'Take-Ons Att', 'Take-Ons Succ', 'Tackles Tkl', 'Tackles TklW', 'Tackles Def 3rd', 'Tackles Mid 3rd', 'Tackles Att 3rd', 'Challenges Tkl', 'Challenges Att', 'Challenges Tkl%', 'Challenges Lost', 'Blocks Blocks', 'Blocks Sh', 'Blocks Pass', 'Int', 'Tkl+Int', 'Clr', 'Err', 'Total Cmp', 'Total Att', 'Total Cmp%', 'Total TotDist', 'Total PrgDist', 'Short Cmp', 'Short Att', 'Short Cmp%', 'Medium Cmp', 'Medium Att', 'Medium Cmp%', 'Long Cmp', 'Long Att', 'Long Cmp%', 'Ast', 'xAG', 'xA', 'KP', ' 1/3', 'PPA', 'CrsPA', 'PrgP', 'Match URL']\n",
      "\n",
      "File: /Users/mariamoramora/Documents/GitHub/ADS599_Capstone/Soccer_Performance_Score/data/real_madrid/real_madrid_24_25.csv\n",
      "Shape: (776, 73)\n",
      "Columns: ['Date', 'Competition', 'Opponent', 'Player', '#', 'Nation', 'Pos', 'Age', 'Min', ' Gls', ' Ast', ' PK', ' PKatt', ' Sh', ' SoT', ' CrdY', ' CrdR', ' Int', ' Touches', ' Tkl', ' Blocks', 'Expected xG', 'Expected npxG', 'Expected xAG', 'SCA', 'GCA', 'Passes Cmp', 'Passes Att', 'Passes Cmp%', 'Passes PrgP', 'Carries Carries', 'Carries PrgC', 'Take-Ons Att', 'Take-Ons Succ', 'Tackles Tkl', 'Tackles TklW', 'Tackles Def 3rd', 'Tackles Mid 3rd', 'Tackles Att 3rd', 'Challenges Tkl', 'Challenges Att', 'Challenges Tkl%', 'Challenges Lost', 'Blocks Blocks', 'Blocks Sh', 'Blocks Pass', 'Int', 'Tkl+Int', 'Clr', 'Err', 'Total Cmp', 'Total Att', 'Total Cmp%', 'Total TotDist', 'Total PrgDist', 'Short Cmp', 'Short Att', 'Short Cmp%', 'Medium Cmp', 'Medium Att', 'Medium Cmp%', 'Long Cmp', 'Long Att', 'Long Cmp%', 'Ast', 'xAG', 'xA', 'KP', ' 1/3', 'PPA', 'CrsPA', 'PrgP', 'Match URL']\n",
      "\n",
      "Combined DataFrame Shape (before removing duplicates): (1550, 73)\n",
      "Removed 0 duplicate rows\n",
      "Final DataFrame Shape: (1550, 73)\n",
      "Combined DataFrame Columns: ['Date', 'Competition', 'Opponent', 'Player', '#', 'Nation', 'Pos', 'Age', 'Min', ' Gls', ' Ast', ' PK', ' PKatt', ' Sh', ' SoT', ' CrdY', ' CrdR', ' Touches', ' Tkl', ' Int', ' Blocks', 'Expected xG', 'Expected npxG', 'Expected xAG', 'SCA', 'GCA', 'Passes Cmp', 'Passes Att', 'Passes Cmp%', 'Passes PrgP', 'Carries Carries', 'Carries PrgC', 'Take-Ons Att', 'Take-Ons Succ', 'Tackles Tkl', 'Tackles TklW', 'Tackles Def 3rd', 'Tackles Mid 3rd', 'Tackles Att 3rd', 'Challenges Tkl', 'Challenges Att', 'Challenges Tkl%', 'Challenges Lost', 'Blocks Blocks', 'Blocks Sh', 'Blocks Pass', 'Int', 'Tkl+Int', 'Clr', 'Err', 'Total Cmp', 'Total Att', 'Total Cmp%', 'Total TotDist', 'Total PrgDist', 'Short Cmp', 'Short Att', 'Short Cmp%', 'Medium Cmp', 'Medium Att', 'Medium Cmp%', 'Long Cmp', 'Long Att', 'Long Cmp%', 'Ast', 'xAG', 'xA', 'KP', ' 1/3', 'PPA', 'CrsPA', 'PrgP', 'Match URL']\n",
      "\n",
      "Head of combined DataFrame:\n",
      "      Date Competition       Opponent           Player   #   Nation Pos  \\\n",
      "0  8/12/23     La Liga  Athletic Club  Vinicius Júnior   7   br BRA  FW   \n",
      "1  8/12/23     La Liga  Athletic Club      Luka Modrić  10   hr CRO  FW   \n",
      "2  8/12/23     La Liga  Athletic Club          Rodrygo  11   br BRA  FW   \n",
      "3  8/12/23     La Liga  Athletic Club           Joselu  14   es ESP  FW   \n",
      "4  8/12/23     La Liga  Athletic Club  Jude Bellingham   5  eng ENG  AM   \n",
      "\n",
      "      Age  Min   Gls  ...  Long Cmp%  Ast  xAG   xA  KP   1/3  PPA  CrsPA  \\\n",
      "0  23-031   79     0  ...      100.0    0  0.0  0.1   0     1    1      0   \n",
      "1  37-337   11     0  ...      100.0    0  0.0  0.2   0     4    1      0   \n",
      "2  22-215   79     1  ...        NaN    0  0.1  0.1   2     2    4      0   \n",
      "3  33-138   11     0  ...        NaN    0  0.1  0.1   1     0    0      0   \n",
      "4  20-044   90     1  ...        0.0    0  0.1  0.0   1     4    2      0   \n",
      "\n",
      "   PrgP                                          Match URL  \n",
      "0     2  https://fbref.com/en/matches/c31f0a31/Athletic...  \n",
      "1     3  https://fbref.com/en/matches/c31f0a31/Athletic...  \n",
      "2     5  https://fbref.com/en/matches/c31f0a31/Athletic...  \n",
      "3     0  https://fbref.com/en/matches/c31f0a31/Athletic...  \n",
      "4     6  https://fbref.com/en/matches/c31f0a31/Athletic...  \n",
      "\n",
      "[5 rows x 73 columns]\n",
      "\n",
      "Combined CSV saved to: /Users/mariamoramora/Documents/GitHub/ADS599_Capstone/Soccer_Performance_Score/data/real_madrid_combined/combined_real_madrid.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "# Set the directory path\n",
    "data_dir = \"/Users/mariamoramora/Documents/GitHub/ADS599_Capstone/Soccer_Performance_Score/data/real_madrid\"\n",
    "\n",
    "# Get all CSV files in the directory\n",
    "csv_files = []\n",
    "for file in os.listdir(data_dir):\n",
    "    if file.endswith('.csv'):\n",
    "        csv_files.append(os.path.join(data_dir, file))\n",
    "\n",
    "print(f\"Found CSV files: {csv_files}\")\n",
    "\n",
    "# Read and combine all CSV files\n",
    "dataframes = []\n",
    "for file in csv_files:\n",
    "    df = pd.read_csv(file)\n",
    "    print(f\"\\nFile: {file}\")\n",
    "    print(f\"Shape: {df.shape}\")\n",
    "    print(f\"Columns: {list(df.columns)}\")\n",
    "    dataframes.append(df)\n",
    "\n",
    "# Combine all dataframes\n",
    "if len(dataframes) == 2:\n",
    "    # If the CSV files have the same structure, use concat\n",
    "    combined_df = pd.concat(dataframes, ignore_index=True)\n",
    "    \n",
    "    # Alternative: if you want to merge on a common column instead\n",
    "    # combined_df = pd.merge(dataframes[0], dataframes[1], on='common_column', how='outer')\n",
    "    \n",
    "elif len(dataframes) > 2:\n",
    "    # For more than 2 files\n",
    "    combined_df = pd.concat(dataframes, ignore_index=True)\n",
    "else:\n",
    "    combined_df = dataframes[0] if dataframes else pd.DataFrame()\n",
    "\n",
    "print(f\"\\nCombined DataFrame Shape (before removing duplicates): {combined_df.shape}\")\n",
    "\n",
    "# Remove duplicates\n",
    "initial_shape = combined_df.shape[0]\n",
    "combined_df = combined_df.drop_duplicates()\n",
    "final_shape = combined_df.shape[0]\n",
    "\n",
    "print(f\"Removed {initial_shape - final_shape} duplicate rows\")\n",
    "print(f\"Final DataFrame Shape: {combined_df.shape}\")\n",
    "print(f\"Combined DataFrame Columns: {list(combined_df.columns)}\")\n",
    "\n",
    "# Display the head of the combined dataframe\n",
    "print(\"\\nHead of combined DataFrame:\")\n",
    "print(combined_df.head())\n",
    "\n",
    "# Create output directory and save the combined dataframe\n",
    "output_dir = \"/Users/mariamoramora/Documents/GitHub/ADS599_Capstone/Soccer_Performance_Score/data/real_madrid_combined\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Save the combined dataframe to the new folder\n",
    "output_file = os.path.join(output_dir, 'combined_real_madrid.csv')\n",
    "combined_df.to_csv(output_file, index=False)\n",
    "\n",
    "print(f\"\\nCombined CSV saved to: {output_file}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create weighted metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== HANDLING DUPLICATES ===\n",
      "Initial dataset shape: (1550, 73)\n",
      "Removed 0 exact duplicate rows\n",
      "Final dataset shape: (1550, 73)\n",
      "=== DATASET COLUMN ANALYSIS ===\n",
      "Total columns: 75\n",
      "Column names: ['Date', 'Competition', 'Opponent', 'Player', 'number', 'Nation', 'Pos', 'Age', 'Min', ' Gls', ' Ast', ' PK', ' PKatt', ' Sh', ' SoT', ' CrdY', ' CrdR', ' Touches', ' Tkl', ' Int', ' Blocks', 'Expected xG', 'Expected npxG', 'Expected xAG', 'SCA', 'GCA', 'Passes Cmp', 'Passes Att', 'Passes Cmp%', 'Passes PrgP', 'Carries Carries', 'Carries PrgC', 'Take-Ons Att', 'Take-Ons Succ', 'Tackles Tkl', 'Tackles TklW', 'Tackles Def 3rd', 'Tackles Mid 3rd', 'Tackles Att 3rd', 'Challenges Tkl', 'Challenges Att', 'Challenges Tkl%', 'Challenges Lost', 'Blocks Blocks', 'Blocks Sh', 'Blocks Pass', 'Int', 'Tkl+Int', 'Clr', 'Err', 'Total Cmp', 'Total Att', 'Total Cmp%', 'Total TotDist', 'Total PrgDist', 'Short Cmp', 'Short Att', 'Short Cmp%', 'Medium Cmp', 'Medium Att', 'Medium Cmp%', 'Long Cmp', 'Long Att', 'Long Cmp%', 'Ast', 'xAG', 'xA', 'KP', ' 1/3', 'PPA', 'CrsPA', 'PrgP', 'Match URL', 'Season', 'Position_Group']\n",
      "\n",
      "Found these numeric columns: ['Int', 'Clr', 'Total Cmp%', 'Long Cmp%', 'Passes PrgP', 'Carries PrgC', 'SCA', 'KP', 'Ast', ' Gls', ' Sh', ' SoT', 'Take-Ons Att', 'Take-Ons Succ', 'Expected xG', 'Total Att', 'Min', 'Total Cmp', 'Total TotDist', 'Total PrgDist']\n",
      "Renamed columns: {' Gls': 'Gls', ' Ast': 'Ast', ' PK': 'PK', ' PKatt': 'PKatt', ' Sh': 'Sh', ' SoT': 'SoT', ' CrdY': 'CrdY', ' CrdR': 'CrdR', ' Touches': 'Touches', ' Tkl': 'Tkl', ' Int': 'Int', ' Blocks': 'Blocks', ' 1/3': '1/3'}\n",
      "\n",
      "Final check - Key columns available:\n",
      "✓ Gls\n",
      "✓ Ast\n",
      "✓ Sh\n",
      "✓ SoT\n",
      "✓ Min\n",
      "✓ Tkl\n",
      "✓ Int\n",
      "\n",
      "Processing Forward players...\n",
      "Found 211 Forward records\n",
      "  - Processing 211 forward records\n",
      "  - Available columns: Gls=True, Ast=True, Sh=True\n",
      "  - Min values shape: (211,)\n",
      "  - Goals values shape: (211,)\n",
      "  - Error processing assists: arg must be a list, tuple, 1-d array, or Series\n",
      "  - Completed forward scoring. Score range: 0.0 - 42.0\n",
      "✓ Successfully calculated scores for Forward\n",
      "\n",
      "Processing Midfield players...\n",
      "Found 410 Midfield records\n",
      "✗ Error processing Midfield: operands could not be broadcast together with shapes (820,) (410,) \n",
      "\n",
      "Processing Defense players...\n",
      "Found 483 Defense records\n",
      "✗ Error processing Defense: operands could not be broadcast together with shapes (966,) (483,) \n",
      "\n",
      "Processing Goalkeeper players...\n",
      "Found 104 Goalkeeper records\n",
      "✓ Successfully calculated scores for Goalkeeper\n",
      "\n",
      "Completed performance score calculation. Score range: 0.0 - 100.0\n",
      "Error creating season position summary: 'DataFrame' object has no attribute 'name'\n",
      "Error creating player season summary: 'DataFrame' object has no attribute 'name'\n",
      "\n",
      "=== REAL MADRID PERFORMANCE SCORING SYSTEM ===\n",
      "Top 10 Players by Average Performance Score:\n",
      "           Player Position_Group  Season  Avg_Performance_Score\n",
      "             Fran     Goalkeeper 2024-25              89.000000\n",
      "     Andriy Lunin     Goalkeeper 2024-25              81.517778\n",
      " Thibaut Courtois     Goalkeeper 2023-24              79.888000\n",
      "Kepa Arrizabalaga     Goalkeeper 2023-24              74.402222\n",
      "     Andriy Lunin     Goalkeeper 2023-24              73.327586\n",
      " Thibaut Courtois     Goalkeeper 2024-25              68.973810\n",
      "  Antonio Rüdiger        Defense 2023-24              50.000000\n",
      "  Antonio Rüdiger        Defense 2024-25              50.000000\n",
      "       Arda Güler       Midfield 2023-24              50.000000\n",
      "       Arda Güler       Midfield 2024-25              50.000000\n",
      "\n",
      "\n",
      "=== SUMMARY BY SEASON AND POSITION ===\n",
      " Season Position_Group  Avg_Performance\n",
      "2023-24        Defense        50.000000\n",
      "2023-24        Forward         4.701409\n",
      "2023-24     Goalkeeper        74.330385\n",
      "2023-24       Midfield        50.000000\n",
      "2024-25        Defense        50.000000\n",
      "2024-25        Forward         6.879834\n",
      "2024-25     Goalkeeper        71.530000\n",
      "2024-25       Midfield        50.000000\n",
      "\n",
      "\n",
      "=== TOP PERFORMERS BY SEASON ===\n",
      "\n",
      "2023-24 Season - Top 5 Performers:\n",
      "           Player Position_Group  Avg_Performance_Score\n",
      " Thibaut Courtois     Goalkeeper              79.888000\n",
      "Kepa Arrizabalaga     Goalkeeper              74.402222\n",
      "     Andriy Lunin     Goalkeeper              73.327586\n",
      "  Antonio Rüdiger        Defense              50.000000\n",
      "       Arda Güler       Midfield              50.000000\n",
      "\n",
      "2024-25 Season - Top 5 Performers:\n",
      "          Player Position_Group  Avg_Performance_Score\n",
      "            Fran     Goalkeeper              89.000000\n",
      "    Andriy Lunin     Goalkeeper              81.517778\n",
      "Thibaut Courtois     Goalkeeper              68.973810\n",
      " Antonio Rüdiger        Defense              50.000000\n",
      "      Arda Güler       Midfield              50.000000\n",
      "\n",
      "\n",
      "=== POSITION ANALYSIS ACROSS SEASONS ===\n",
      "Season          2023-24  2024-25\n",
      "Position_Group                  \n",
      "Defense           50.00    50.00\n",
      "Forward            4.70     6.88\n",
      "Goalkeeper        74.33    71.53\n",
      "Midfield          50.00    50.00\n",
      "✓ Enhanced dataset saved: /Users/mariamoramora/Documents/GitHub/ADS599_Capstone/Soccer_Performance_Score/data/real_madrid_combined/real_madrid_enhanced_complete.csv\n",
      "✓ Season-Position summary saved: /Users/mariamoramora/Documents/GitHub/ADS599_Capstone/Soccer_Performance_Score/data/real_madrid_combined/summary_by_season_position.csv\n",
      "✓ Player summary saved: /Users/mariamoramora/Documents/GitHub/ADS599_Capstone/Soccer_Performance_Score/data/real_madrid_combined/player_summary_by_season.csv\n",
      "✓ Position analysis saved: /Users/mariamoramora/Documents/GitHub/ADS599_Capstone/Soccer_Performance_Score/data/real_madrid_combined/position_performance_across_seasons.csv\n",
      "\n",
      "=== DATASET INFO ===\n",
      "Total records in enhanced dataset: 1550\n",
      "Seasons covered: ['2023-24', '2024-25']\n",
      "Position groups: {'Defense': 483, 'Midfield': 410, 'Forward': 211, 'Goalkeeper': 104}\n",
      "Unique players: 37\n",
      "\n",
      "=== SAMPLE OF ENHANCED DATASET ===\n",
      "      Date  Season              Player Position_Group  Performance_Score  Min  Gls  Ast  Ast\n",
      "2023-08-12 2023-24     Vinicius Júnior        Forward           4.329114   79    0    0    0\n",
      "2023-08-12 2023-24         Luka Modrić        Forward          14.545455   11    0    0    0\n",
      "2023-08-12 2023-24             Rodrygo        Forward           3.291139   79    1    0    0\n",
      "2023-08-12 2023-24              Joselu        Forward           0.000000   11    0    0    0\n",
      "2023-08-12 2023-24     Jude Bellingham       Midfield          50.000000   90    1    0    0\n",
      "2023-08-12 2023-24   Eduardo Camavinga       Midfield          50.000000   70    0    0    0\n",
      "2023-08-12 2023-24          Toni Kroos       Midfield          50.000000   20    0    0    0\n",
      "2023-08-12 2023-24   Federico Valverde       Midfield          50.000000   90    0    0    0\n",
      "2023-08-12 2023-24 Aurélien Tchouaméni       Midfield          50.000000   90    0    0    0\n",
      "2023-08-12 2023-24         Fran Garcia        Defense          50.000000   90    0    0    0\n",
      "2023-08-12 2023-24         David Alaba        Defense          50.000000   90    0    1    1\n",
      "2023-08-12 2023-24        Éder Militão        Defense          50.000000   49    0    0    0\n",
      "2023-08-12 2023-24     Antonio Rüdiger        Defense          50.000000   41    0    0    0\n",
      "2023-08-12 2023-24       Dani Carvajal        Defense          50.000000   90    0    1    1\n",
      "2023-08-12 2023-24        Andriy Lunin     Goalkeeper          87.620000   90    0    0    0\n",
      "\n",
      "🏆 REAL MADRID PERFORMANCE ANALYSIS COMPLETE! 🏆\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/qw/jyz61sns2534v_vwqrk2t1nc0000gn/T/ipykernel_54811/1318013363.py:446: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '[ 4.32911392 14.54545455  3.29113924  0.          6.61516854  6.66666667\n",
      "  7.26760563  3.5        10.          0.          8.88383838  4.\n",
      "  5.22222222  1.97674419  0.         16.39344262 10.11111111  3.61111111\n",
      "  3.55555556  0.44444444  4.16666667  8.83928571  3.92156863  9.12790698\n",
      " 10.          0.         10.86956522  8.20137694  0.          1.14864865\n",
      "  0.          7.21126761  4.47368421  4.22222222  3.70689655  0.\n",
      "  1.53846154  0.          4.61111111  3.92857143  0.          0.28089888\n",
      "  0.         10.56451613  5.17857143  6.66666667  4.88888889 15.98684211\n",
      "  0.         12.42165242  0.          9.96969697 12.88311688  0.38888889\n",
      "  0.         10.93023256 15.29411765  9.58333333  0.          0.07246377\n",
      "  6.47222222  6.64556962  0.          6.22222222  8.27777778 11.00401606\n",
      "  0.          2.84019975  0.          6.4         0.          6.31961259\n",
      "  0.          6.22222222  5.11111111  2.66666667  0.          5.04054054\n",
      "  8.75        6.7816092   0.          1.26666667 11.21428571  7.\n",
      "  0.          9.30555556  0.          3.76811594  6.66666667  0.96385542\n",
      "  2.85714286 13.94444444  5.17977528 10.          0.          3.33333333\n",
      "  4.9086758   3.82352941  9.70833333  0.          3.55633803  0.\n",
      "  2.54901961  0.          0.61111111  5.          8.85802469  0.\n",
      "  0.          0.          6.66666667  0.          4.83333333  2.77777778\n",
      "  7.11111111  7.125       2.44444444  8.88888889 12.66666667  2.83333333\n",
      "  2.94444444  5.22222222  0.          7.38888889 11.05882353 42.\n",
      "  8.         13.4939759  35.          6.43258427  0.         10.83333333\n",
      "  9.22222222 11.79746835  2.24806202  1.25        7.55555556 12.32142857\n",
      " 10.          8.01282051  2.92857143  5.33950617  4.13483146 10.\n",
      "  2.03968254  4.66666667  7.3015873  12.61111111  6.11111111  2.5\n",
      "  9.18292683  6.47222222  0.          6.38888889  0.          6.3030303\n",
      "  5.77777778  4.63218391  0.          4.125       0.         16.85714286\n",
      "  2.91666667  7.05555556  3.33333333 12.66666667 11.80952381  0.25\n",
      "  0.          3.05555556  7.66666667  7.27777778  5.66666667  8.10861423\n",
      " 11.86507937  4.84269663  0.         21.75324675  0.          6.95238095\n",
      "  5.          2.5         2.66666667  3.72222222 11.83333333 11.19230769\n",
      "  0.          3.23934837  0.          1.42857143  8.88888889  0.\n",
      " 12.28571429  6.25        8.5         0.33333333  8.          0.\n",
      "  3.33333333 10.34246575  0.          8.53174603 10.          1.58730159\n",
      " 12.44444444 10.61111111  7.05479452  4.70588235  8.44444444  0.87719298\n",
      " 12.44444444]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  df.loc[original_indices, 'Performance_Score'] = subset['Performance_Score'].values\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "\n",
    "# Load your combined Real Madrid data\n",
    "df = pd.read_csv('/Users/mariamoramora/Documents/GitHub/ADS599_Capstone/Soccer_Performance_Score/data/real_madrid_combined/combined_real_madrid.csv')\n",
    "\n",
    "# Check for and handle duplicates\n",
    "print(\"=== HANDLING DUPLICATES ===\")\n",
    "print(f\"Initial dataset shape: {df.shape}\")\n",
    "initial_count = len(df)\n",
    "\n",
    "# Remove exact duplicate rows\n",
    "df_no_duplicates = df.drop_duplicates()\n",
    "duplicates_removed = initial_count - len(df_no_duplicates)\n",
    "print(f\"Removed {duplicates_removed} exact duplicate rows\")\n",
    "\n",
    "# Reset index to avoid duplicate index issues\n",
    "df = df_no_duplicates.reset_index(drop=True)\n",
    "print(f\"Final dataset shape: {df.shape}\")\n",
    "\n",
    "# Convert Date to datetime and add Season\n",
    "df['Date'] = pd.to_datetime(df['Date'], format='%m/%d/%y')\n",
    "df['Season'] = df['Date'].apply(lambda x: \n",
    "    f\"{x.year}-{str(x.year + 1)[-2:]}\" if x.month >= 8 \n",
    "    else f\"{x.year - 1}-{str(x.year)[-2:]}\"\n",
    ")\n",
    "\n",
    "# Position grouping\n",
    "position_mapping = {\n",
    "    'GK': 'Goalkeeper',\n",
    "    'CB': 'Defense', 'LB': 'Defense', 'RB': 'Defense',\n",
    "    'DM': 'Midfield', 'CM': 'Midfield', 'LM': 'Midfield', 'RM': 'Midfield', 'AM': 'Midfield',\n",
    "    'FW': 'Forward'\n",
    "}\n",
    "df['Position_Group'] = df['Pos'].map(position_mapping)\n",
    "\n",
    "# First, let's check what columns we actually have\n",
    "print(\"=== DATASET COLUMN ANALYSIS ===\")\n",
    "print(f\"Total columns: {len(df.columns)}\")\n",
    "print(f\"Column names: {list(df.columns)}\")\n",
    "\n",
    "# Handle missing values and convert to numeric - check if columns exist first\n",
    "potential_numeric_columns = ['Tkl', 'Int', 'Blocks', 'Clr', 'Total Cmp%', 'Long Cmp%', 'Passes PrgP', \n",
    "                            'Carries PrgC', 'SCA', 'KP', 'Ast', 'Gls', ' Gls', 'Sh', ' Sh', 'SoT', ' SoT',\n",
    "                            'Take-Ons Att', 'Take-Ons Succ', 'Expected xG', 'Total Att', 'Min', ' Min',\n",
    "                            'Total Cmp', 'Total TotDist', 'Total PrgDist']\n",
    "\n",
    "# Find which columns actually exist (handle spaces in column names)\n",
    "existing_numeric_columns = []\n",
    "for col in potential_numeric_columns:\n",
    "    if col in df.columns:\n",
    "        existing_numeric_columns.append(col)\n",
    "\n",
    "print(f\"\\nFound these numeric columns: {existing_numeric_columns}\")\n",
    "\n",
    "# Convert existing columns to numeric\n",
    "for col in existing_numeric_columns:\n",
    "    df[col] = pd.to_numeric(df[col], errors='coerce').fillna(0)\n",
    "\n",
    "# Create standardized column names (remove leading spaces)\n",
    "column_mapping = {}\n",
    "for col in df.columns:\n",
    "    clean_col = col.strip()\n",
    "    if col != clean_col:\n",
    "        column_mapping[col] = clean_col\n",
    "\n",
    "if column_mapping:\n",
    "    df.rename(columns=column_mapping, inplace=True)\n",
    "    print(f\"Renamed columns: {column_mapping}\")\n",
    "\n",
    "# Now check for the key columns we need\n",
    "required_columns = ['Gls', 'Ast', 'Tkl', 'Int', 'Blocks', 'SCA', 'KP', 'Sh', 'SoT', 'Min']\n",
    "missing_columns = []\n",
    "for col in required_columns:\n",
    "    if col not in df.columns:\n",
    "        missing_columns.append(col)\n",
    "        df[col] = 0  # Create missing columns with zeros\n",
    "\n",
    "if missing_columns:\n",
    "    print(f\"Created missing columns with zeros: {missing_columns}\")\n",
    "\n",
    "# Calculate Take-on Success Rate - check if columns exist\n",
    "if 'Take-Ons Att' in df.columns and 'Take-Ons Succ' in df.columns:\n",
    "    df['Take-Ons Succ%'] = np.where(df['Take-Ons Att'] > 0, \n",
    "                                    (df['Take-Ons Succ'] / df['Take-Ons Att'] * 100), 0)\n",
    "else:\n",
    "    df['Take-Ons Succ%'] = 0\n",
    "    print(\"Take-on columns not found, setting Take-Ons Succ% to 0\")\n",
    "\n",
    "# Check for alternate column names that might exist\n",
    "alternate_names = {\n",
    "    'Gls': [' Gls', 'Goals', 'G'],\n",
    "    'Ast': [' Ast', 'Assists', 'A'], \n",
    "    'Sh': [' Sh', 'Shots', 'Shot'],\n",
    "    'SoT': [' SoT', 'Shots on Target', 'ShotsonTarget'],\n",
    "    'Min': [' Min', 'Minutes', 'Playing Time'],\n",
    "    'Tkl': [' Tkl', 'Tackles'],\n",
    "    'Int': [' Int', 'Interceptions'],\n",
    "    'SCA': [' SCA', 'Shot Creating Actions'],\n",
    "    'KP': [' KP', 'Key Passes']\n",
    "}\n",
    "\n",
    "# Map alternate column names\n",
    "for standard_name, alternates in alternate_names.items():\n",
    "    if standard_name not in df.columns:\n",
    "        for alt_name in alternates:\n",
    "            if alt_name in df.columns:\n",
    "                df[standard_name] = df[alt_name]\n",
    "                print(f\"Mapped {alt_name} to {standard_name}\")\n",
    "                break\n",
    "\n",
    "print(f\"\\nFinal check - Key columns available:\")\n",
    "for col in ['Gls', 'Ast', 'Sh', 'SoT', 'Min', 'Tkl', 'Int']:\n",
    "    status = \"✓\" if col in df.columns else \"✗\"\n",
    "    print(f\"{status} {col}\")\n",
    "\n",
    "# GOALKEEPER PERFORMANCE SCORE\n",
    "def calculate_gk_score(df_gk):\n",
    "    if df_gk.empty:\n",
    "        return df_gk\n",
    "    \n",
    "    # Reset index to ensure no duplicates\n",
    "    df_gk = df_gk.reset_index(drop=True).copy()\n",
    "    \n",
    "    # Normalize metrics (0-100 scale)\n",
    "    df_gk['GK_Distribution'] = np.where(df_gk['Total Cmp%'] > 0, df_gk['Total Cmp%'], 0)\n",
    "    df_gk['GK_LongBall'] = np.where(df_gk['Long Cmp%'] > 0, df_gk['Long Cmp%'], 0)\n",
    "    \n",
    "    # Weighted score\n",
    "    df_gk['Performance_Score'] = (\n",
    "        df_gk['GK_Distribution'] * 0.6 +  # 60% - Distribution accuracy\n",
    "        df_gk['GK_LongBall'] * 0.4       # 40% - Long ball accuracy\n",
    "    )\n",
    "    \n",
    "    return df_gk\n",
    "\n",
    "# DEFENSE PERFORMANCE SCORE\n",
    "def calculate_def_score(df_def):\n",
    "    if df_def.empty:\n",
    "        return df_def\n",
    "    \n",
    "    # Reset index to ensure no duplicates\n",
    "    df_def = df_def.reset_index(drop=True).copy()\n",
    "    \n",
    "    # Check if required columns exist, use 0 if not\n",
    "    tkl_col = 'Tkl' if 'Tkl' in df_def.columns else None\n",
    "    int_col = 'Int' if 'Int' in df_def.columns else None\n",
    "    blocks_col = 'Blocks' if 'Blocks' in df_def.columns else None\n",
    "    clr_col = 'Clr' if 'Clr' in df_def.columns else None\n",
    "    pass_acc_col = 'Total Cmp%' if 'Total Cmp%' in df_def.columns else None\n",
    "    \n",
    "    # Convert to numpy arrays and ensure they're 1D\n",
    "    min_values = np.array(df_def['Min']).flatten()\n",
    "    \n",
    "    # Normalize per 90 minutes using numpy operations\n",
    "    if tkl_col is not None:\n",
    "        tkl_values = np.array(df_def[tkl_col]).flatten()\n",
    "        df_def['Tkl_per90'] = np.where(min_values > 0, tkl_values / min_values * 90, 0)\n",
    "    else:\n",
    "        df_def['Tkl_per90'] = 0\n",
    "        \n",
    "    if int_col is not None:\n",
    "        int_values = np.array(df_def[int_col]).flatten()\n",
    "        df_def['Int_per90'] = np.where(min_values > 0, int_values / min_values * 90, 0)\n",
    "    else:\n",
    "        df_def['Int_per90'] = 0\n",
    "        \n",
    "    if blocks_col is not None:\n",
    "        blocks_values = np.array(df_def[blocks_col]).flatten()\n",
    "        df_def['Blocks_per90'] = np.where(min_values > 0, blocks_values / min_values * 90, 0)\n",
    "    else:\n",
    "        df_def['Blocks_per90'] = 0\n",
    "        \n",
    "    if clr_col is not None:\n",
    "        clr_values = np.array(df_def[clr_col]).flatten()\n",
    "        df_def['Clr_per90'] = np.where(min_values > 0, clr_values / min_values * 90, 0)\n",
    "    else:\n",
    "        df_def['Clr_per90'] = 0\n",
    "    \n",
    "    # Scale to 0-100\n",
    "    max_tkl = df_def['Tkl_per90'].max() if df_def['Tkl_per90'].max() > 0 else 1\n",
    "    max_int = df_def['Int_per90'].max() if df_def['Int_per90'].max() > 0 else 1\n",
    "    max_blocks = df_def['Blocks_per90'].max() if df_def['Blocks_per90'].max() > 0 else 1\n",
    "    max_clr = df_def['Clr_per90'].max() if df_def['Clr_per90'].max() > 0 else 1\n",
    "    \n",
    "    df_def['DEF_Tackles'] = (df_def['Tkl_per90'] / max_tkl * 100)\n",
    "    df_def['DEF_Interceptions'] = (df_def['Int_per90'] / max_int * 100)\n",
    "    df_def['DEF_Blocks'] = (df_def['Blocks_per90'] / max_blocks * 100)\n",
    "    df_def['DEF_Clearances'] = (df_def['Clr_per90'] / max_clr * 100)\n",
    "    df_def['DEF_PassAccuracy'] = df_def[pass_acc_col] if pass_acc_col else 0\n",
    "    \n",
    "    # Weighted score\n",
    "    df_def['Performance_Score'] = (\n",
    "        df_def['DEF_Tackles'] * 0.25 +       # 25% - Tackles\n",
    "        df_def['DEF_Interceptions'] * 0.25 + # 25% - Interceptions\n",
    "        df_def['DEF_Blocks'] * 0.20 +        # 20% - Blocks\n",
    "        df_def['DEF_Clearances'] * 0.15 +    # 15% - Clearances\n",
    "        df_def['DEF_PassAccuracy'] * 0.15    # 15% - Pass accuracy\n",
    "    )\n",
    "    \n",
    "    return df_def\n",
    "\n",
    "# MIDFIELD PERFORMANCE SCORE\n",
    "def calculate_mid_score(df_mid):\n",
    "    if df_mid.empty:\n",
    "        return df_mid\n",
    "    \n",
    "    # Reset index to ensure no duplicates\n",
    "    df_mid = df_mid.reset_index(drop=True).copy()\n",
    "    \n",
    "    # Check if required columns exist\n",
    "    total_att_col = 'Total Att' if 'Total Att' in df_mid.columns else None\n",
    "    prog_passes_col = 'Passes PrgP' if 'Passes PrgP' in df_mid.columns else None\n",
    "    sca_col = 'SCA' if 'SCA' in df_mid.columns else None\n",
    "    kp_col = 'KP' if 'KP' in df_mid.columns else None\n",
    "    ast_col = 'Ast' if 'Ast' in df_mid.columns else None\n",
    "    pass_acc_col = 'Total Cmp%' if 'Total Cmp%' in df_mid.columns else None\n",
    "    \n",
    "    # Convert to numpy arrays and ensure they're 1D\n",
    "    min_values = np.array(df_mid['Min']).flatten()\n",
    "    \n",
    "    # Normalize per 90 minutes using numpy operations\n",
    "    if total_att_col is not None:\n",
    "        passes_values = np.array(df_mid[total_att_col]).flatten()\n",
    "        df_mid['Passes_per90'] = np.where(min_values > 0, passes_values / min_values * 90, 0)\n",
    "    else:\n",
    "        df_mid['Passes_per90'] = 0\n",
    "        \n",
    "    if prog_passes_col is not None:\n",
    "        prog_values = np.array(df_mid[prog_passes_col]).flatten()\n",
    "        df_mid['ProgPasses_per90'] = np.where(min_values > 0, prog_values / min_values * 90, 0)\n",
    "    else:\n",
    "        df_mid['ProgPasses_per90'] = 0\n",
    "        \n",
    "    if sca_col is not None:\n",
    "        sca_values = np.array(df_mid[sca_col]).flatten()\n",
    "        df_mid['SCA_per90'] = np.where(min_values > 0, sca_values / min_values * 90, 0)\n",
    "    else:\n",
    "        df_mid['SCA_per90'] = 0\n",
    "        \n",
    "    if kp_col is not None:\n",
    "        kp_values = np.array(df_mid[kp_col]).flatten()\n",
    "        df_mid['KP_per90'] = np.where(min_values > 0, kp_values / min_values * 90, 0)\n",
    "    else:\n",
    "        df_mid['KP_per90'] = 0\n",
    "        \n",
    "    if ast_col is not None:\n",
    "        ast_values = np.array(df_mid[ast_col]).flatten()\n",
    "        df_mid['Ast_per90'] = np.where(min_values > 0, ast_values / min_values * 90, 0)\n",
    "    else:\n",
    "        df_mid['Ast_per90'] = 0\n",
    "    \n",
    "    # Scale to 0-100\n",
    "    max_passes = df_mid['Passes_per90'].max() if df_mid['Passes_per90'].max() > 0 else 1\n",
    "    max_prog = df_mid['ProgPasses_per90'].max() if df_mid['ProgPasses_per90'].max() > 0 else 1\n",
    "    max_sca = df_mid['SCA_per90'].max() if df_mid['SCA_per90'].max() > 0 else 1\n",
    "    max_kp = df_mid['KP_per90'].max() if df_mid['KP_per90'].max() > 0 else 1\n",
    "    \n",
    "    df_mid['MID_PassVolume'] = (df_mid['Passes_per90'] / max_passes * 100)\n",
    "    df_mid['MID_Progressive'] = (df_mid['ProgPasses_per90'] / max_prog * 100)\n",
    "    df_mid['MID_Creativity'] = (df_mid['SCA_per90'] / max_sca * 100)\n",
    "    df_mid['MID_KeyPasses'] = (df_mid['KP_per90'] / max_kp * 100)\n",
    "    df_mid['MID_PassAccuracy'] = df_mid[pass_acc_col] if pass_acc_col else 80  # Default decent accuracy\n",
    "    df_mid['MID_Assists'] = (df_mid['Ast_per90'] * 50)  # Assists bonus\n",
    "    \n",
    "    # Weighted score\n",
    "    df_mid['Performance_Score'] = (\n",
    "        df_mid['MID_PassAccuracy'] * 0.20 +   # 20% - Pass accuracy\n",
    "        df_mid['MID_Progressive'] * 0.20 +    # 20% - Progressive passes\n",
    "        df_mid['MID_Creativity'] * 0.20 +     # 20% - Shot creating actions\n",
    "        df_mid['MID_KeyPasses'] * 0.15 +      # 15% - Key passes\n",
    "        df_mid['MID_PassVolume'] * 0.15 +     # 15% - Pass volume\n",
    "        df_mid['MID_Assists'] * 0.10          # 10% - Assists\n",
    "    )\n",
    "    \n",
    "    return df_mid\n",
    "\n",
    "# FORWARD PERFORMANCE SCORE\n",
    "def calculate_fwd_score(df_fwd):\n",
    "    if df_fwd.empty:\n",
    "        print(\"  - Forward subset is empty\")\n",
    "        return df_fwd\n",
    "    \n",
    "    print(f\"  - Processing {len(df_fwd)} forward records\")\n",
    "    \n",
    "    # Ensure we have a clean copy with reset index\n",
    "    df_fwd = df_fwd.copy().reset_index(drop=True)\n",
    "    \n",
    "    # Check if required columns exist\n",
    "    gls_col = 'Gls' if 'Gls' in df_fwd.columns else None\n",
    "    ast_col = 'Ast' if 'Ast' in df_fwd.columns else None\n",
    "    sh_col = 'Sh' if 'Sh' in df_fwd.columns else None\n",
    "    sot_col = 'SoT' if 'SoT' in df_fwd.columns else None\n",
    "    xg_col = 'Expected xG' if 'Expected xG' in df_fwd.columns else None\n",
    "    \n",
    "    print(f\"  - Available columns: Gls={gls_col is not None}, Ast={ast_col is not None}, Sh={sh_col is not None}\")\n",
    "    \n",
    "    # Safely extract minutes as 1D array\n",
    "    try:\n",
    "        min_values = pd.to_numeric(df_fwd['Min'], errors='coerce').fillna(0).values\n",
    "        min_values = np.array(min_values).flatten()\n",
    "        print(f\"  - Min values shape: {min_values.shape}\")\n",
    "    except Exception as e:\n",
    "        print(f\"  - Error extracting minutes: {e}\")\n",
    "        min_values = np.zeros(len(df_fwd))\n",
    "    \n",
    "    # Normalize per 90 minutes using safe operations\n",
    "    if gls_col is not None:\n",
    "        try:\n",
    "            gls_values = pd.to_numeric(df_fwd[gls_col], errors='coerce').fillna(0).values\n",
    "            gls_values = np.array(gls_values).flatten()\n",
    "            print(f\"  - Goals values shape: {gls_values.shape}\")\n",
    "            \n",
    "            if len(gls_values) == len(min_values):\n",
    "                df_fwd['Gls_per90'] = np.where(min_values > 0, gls_values / min_values * 90, 0)\n",
    "            else:\n",
    "                print(f\"  - Shape mismatch for goals: {len(gls_values)} vs {len(min_values)}\")\n",
    "                df_fwd['Gls_per90'] = 0\n",
    "        except Exception as e:\n",
    "            print(f\"  - Error processing goals: {e}\")\n",
    "            df_fwd['Gls_per90'] = 0\n",
    "    else:\n",
    "        df_fwd['Gls_per90'] = 0\n",
    "        \n",
    "    if ast_col is not None:\n",
    "        try:\n",
    "            ast_values = pd.to_numeric(df_fwd[ast_col], errors='coerce').fillna(0).values\n",
    "            ast_values = np.array(ast_values).flatten()\n",
    "            print(f\"  - Assists values shape: {ast_values.shape}\")\n",
    "            \n",
    "            if len(ast_values) == len(min_values):\n",
    "                df_fwd['Ast_per90'] = np.where(min_values > 0, ast_values / min_values * 90, 0)\n",
    "            else:\n",
    "                print(f\"  - Shape mismatch for assists: {len(ast_values)} vs {len(min_values)}\")\n",
    "                df_fwd['Ast_per90'] = 0\n",
    "        except Exception as e:\n",
    "            print(f\"  - Error processing assists: {e}\")\n",
    "            df_fwd['Ast_per90'] = 0\n",
    "    else:\n",
    "        df_fwd['Ast_per90'] = 0\n",
    "        \n",
    "    if sh_col is not None:\n",
    "        try:\n",
    "            sh_values = pd.to_numeric(df_fwd[sh_col], errors='coerce').fillna(0).values\n",
    "            sh_values = np.array(sh_values).flatten()\n",
    "            if len(sh_values) == len(min_values):\n",
    "                df_fwd['Shots_per90'] = np.where(min_values > 0, sh_values / min_values * 90, 0)\n",
    "            else:\n",
    "                df_fwd['Shots_per90'] = 0\n",
    "        except Exception as e:\n",
    "            print(f\"  - Error processing shots: {e}\")\n",
    "            df_fwd['Shots_per90'] = 0\n",
    "    else:\n",
    "        df_fwd['Shots_per90'] = 0\n",
    "        \n",
    "    if sot_col is not None:\n",
    "        try:\n",
    "            sot_values = pd.to_numeric(df_fwd[sot_col], errors='coerce').fillna(0).values\n",
    "            sot_values = np.array(sot_values).flatten()\n",
    "            if len(sot_values) == len(min_values):\n",
    "                df_fwd['SoT_per90'] = np.where(min_values > 0, sot_values / min_values * 90, 0)\n",
    "            else:\n",
    "                df_fwd['SoT_per90'] = 0\n",
    "        except Exception as e:\n",
    "            print(f\"  - Error processing shots on target: {e}\")\n",
    "            df_fwd['SoT_per90'] = 0\n",
    "    else:\n",
    "        df_fwd['SoT_per90'] = 0\n",
    "        \n",
    "    if xg_col is not None:\n",
    "        try:\n",
    "            xg_values = pd.to_numeric(df_fwd[xg_col], errors='coerce').fillna(0).values\n",
    "            xg_values = np.array(xg_values).flatten()\n",
    "            if len(xg_values) == len(min_values):\n",
    "                df_fwd['xG_per90'] = np.where(min_values > 0, xg_values / min_values * 90, 0)\n",
    "            else:\n",
    "                df_fwd['xG_per90'] = 0\n",
    "        except Exception as e:\n",
    "            print(f\"  - Error processing xG: {e}\")\n",
    "            df_fwd['xG_per90'] = 0\n",
    "    else:\n",
    "        df_fwd['xG_per90'] = 0\n",
    "    \n",
    "    # Scale to 0-100\n",
    "    max_goals = df_fwd['Gls_per90'].max() if df_fwd['Gls_per90'].max() > 0 else 1\n",
    "    max_shots = df_fwd['Shots_per90'].max() if df_fwd['Shots_per90'].max() > 0 else 1\n",
    "    max_sot = df_fwd['SoT_per90'].max() if df_fwd['SoT_per90'].max() > 0 else 1\n",
    "    max_xg = df_fwd['xG_per90'].max() if df_fwd['xG_per90'].max() > 0 else 1\n",
    "    \n",
    "    df_fwd['FWD_Goals'] = (df_fwd['Gls_per90'] / max_goals * 100)\n",
    "    df_fwd['FWD_Assists'] = (df_fwd['Ast_per90'] * 50)  # Assists bonus\n",
    "    df_fwd['FWD_Shots'] = (df_fwd['Shots_per90'] / max_shots * 100)\n",
    "    df_fwd['FWD_ShotsOnTarget'] = (df_fwd['SoT_per90'] / max_sot * 100)\n",
    "    df_fwd['FWD_ExpectedGoals'] = (df_fwd['xG_per90'] / max_xg * 100)\n",
    "    df_fwd['FWD_TakeOnSuccess'] = df_fwd['Take-Ons Succ%'] if 'Take-Ons Succ%' in df_fwd.columns else 0\n",
    "    \n",
    "    # Weighted score\n",
    "    df_fwd['Performance_Score'] = (\n",
    "        df_fwd['FWD_Goals'] * 0.35 +           # 35% - Goals\n",
    "        df_fwd['FWD_Assists'] * 0.20 +         # 20% - Assists\n",
    "        df_fwd['FWD_ShotsOnTarget'] * 0.15 +   # 15% - Shots on target\n",
    "        df_fwd['FWD_ExpectedGoals'] * 0.15 +   # 15% - Expected goals\n",
    "        df_fwd['FWD_TakeOnSuccess'] * 0.10 +   # 10% - Take-on success\n",
    "        df_fwd['FWD_Shots'] * 0.05             # 5% - Shot volume\n",
    "    )\n",
    "    \n",
    "    print(f\"  - Completed forward scoring. Score range: {df_fwd['Performance_Score'].min():.1f} - {df_fwd['Performance_Score'].max():.1f}\")\n",
    "    \n",
    "    return df_fwd\n",
    "\n",
    "# Apply scoring by position group\n",
    "df['Performance_Score'] = 0\n",
    "\n",
    "# Process each position group separately to avoid index conflicts\n",
    "for position_group in df['Position_Group'].unique():\n",
    "    if pd.isna(position_group):\n",
    "        continue\n",
    "        \n",
    "    print(f\"\\nProcessing {position_group} players...\")\n",
    "    \n",
    "    # Create a clean subset with proper filtering\n",
    "    mask = df['Position_Group'] == position_group\n",
    "    subset = df[mask].copy()\n",
    "    original_length = len(subset)\n",
    "    \n",
    "    # Reset index completely\n",
    "    subset = subset.reset_index(drop=True)\n",
    "    \n",
    "    print(f\"Found {len(subset)} {position_group} records\")\n",
    "    \n",
    "    try:\n",
    "        if position_group == 'Goalkeeper':\n",
    "            subset = calculate_gk_score(subset)\n",
    "        elif position_group == 'Defense':\n",
    "            subset = calculate_def_score(subset)\n",
    "        elif position_group == 'Midfield':\n",
    "            subset = calculate_mid_score(subset)\n",
    "        elif position_group == 'Forward':\n",
    "            subset = calculate_fwd_score(subset)\n",
    "        \n",
    "        # Verify lengths match before updating\n",
    "        if len(subset) == original_length:\n",
    "            # Update the main dataframe with the calculated scores using loc indexing\n",
    "            original_indices = df[mask].index\n",
    "            df.loc[original_indices, 'Performance_Score'] = subset['Performance_Score'].values\n",
    "            print(f\"✓ Successfully calculated scores for {position_group}\")\n",
    "        else:\n",
    "            print(f\"✗ Length mismatch for {position_group}: {len(subset)} vs {original_length}\")\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"✗ Error processing {position_group}: {e}\")\n",
    "        # Set default scores for this position group\n",
    "        df.loc[mask, 'Performance_Score'] = 50  # Default middle score\n",
    "\n",
    "# Cap scores at 100\n",
    "df['Performance_Score'] = df['Performance_Score'].clip(0, 100)\n",
    "print(f\"\\nCompleted performance score calculation. Score range: {df['Performance_Score'].min():.1f} - {df['Performance_Score'].max():.1f}\")\n",
    "\n",
    "# Create the combined dataset with all new columns\n",
    "combined_df = df.copy()\n",
    "\n",
    "# Create summary table by Season and Position\n",
    "try:\n",
    "    season_position_summary = combined_df.groupby(['Season', 'Position_Group']).agg({\n",
    "        'Performance_Score': ['mean', 'max', 'min', 'std', 'count'],\n",
    "        'Player': 'nunique',\n",
    "        'Min': 'sum',\n",
    "        'Gls': 'sum',\n",
    "        'Ast': 'sum'\n",
    "    }).round(2)\n",
    "\n",
    "    season_position_summary.columns = ['Avg_Performance', 'Max_Performance', 'Min_Performance', \n",
    "                                      'Std_Performance', 'Total_Matches', 'Unique_Players', \n",
    "                                      'Total_Minutes', 'Total_Goals', 'Total_Assists']\n",
    "    season_position_summary = season_position_summary.reset_index()\n",
    "except Exception as e:\n",
    "    print(f\"Error creating season position summary: {e}\")\n",
    "    # Create a simple summary instead\n",
    "    season_position_summary = combined_df.groupby(['Season', 'Position_Group'])['Performance_Score'].mean().reset_index()\n",
    "    season_position_summary.columns = ['Season', 'Position_Group', 'Avg_Performance']\n",
    "\n",
    "# Create summary table by Player, Season, and Position\n",
    "try:\n",
    "    player_season_summary = combined_df.groupby(['Player', 'Position_Group', 'Season']).agg({\n",
    "        'Performance_Score': ['mean', 'max', 'min', 'count'],\n",
    "        'Min': 'sum',\n",
    "        'Gls': 'sum',\n",
    "        'Ast': 'sum',\n",
    "        'Date': ['min', 'max']\n",
    "    }).round(2)\n",
    "\n",
    "    player_season_summary.columns = ['Avg_Performance_Score', 'Max_Performance_Score', \n",
    "                                    'Min_Performance_Score', 'Games_Played', 'Total_Minutes', \n",
    "                                    'Total_Goals', 'Total_Assists', 'First_Game', 'Last_Game']\n",
    "    player_season_summary = player_season_summary.reset_index()\n",
    "except Exception as e:\n",
    "    print(f\"Error creating player season summary: {e}\")\n",
    "    # Create a simple summary instead\n",
    "    player_season_summary = combined_df.groupby(['Player', 'Position_Group', 'Season']).agg({\n",
    "        'Performance_Score': 'mean',\n",
    "        'Min': 'sum'\n",
    "    }).reset_index()\n",
    "    player_season_summary.columns = ['Player', 'Position_Group', 'Season', 'Avg_Performance_Score', 'Total_Minutes']\n",
    "\n",
    "# Display comprehensive summary\n",
    "print(\"\\n=== REAL MADRID PERFORMANCE SCORING SYSTEM ===\")\n",
    "if len(player_season_summary) > 0:\n",
    "    print(\"Top 10 Players by Average Performance Score:\")\n",
    "    if 'Avg_Performance_Score' in player_season_summary.columns:\n",
    "        top_players = player_season_summary.nlargest(10, 'Avg_Performance_Score')\n",
    "        display_cols = [col for col in ['Player', 'Position_Group', 'Season', 'Avg_Performance_Score', 'Games_Played'] \n",
    "                       if col in top_players.columns]\n",
    "        print(top_players[display_cols].to_string(index=False))\n",
    "\n",
    "print(\"\\n\\n=== SUMMARY BY SEASON AND POSITION ===\")\n",
    "if len(season_position_summary) > 0:\n",
    "    print(season_position_summary.to_string(index=False))\n",
    "\n",
    "print(\"\\n\\n=== TOP PERFORMERS BY SEASON ===\")\n",
    "if len(player_season_summary) > 0 and 'Avg_Performance_Score' in player_season_summary.columns:\n",
    "    for season in sorted(combined_df['Season'].unique()):\n",
    "        if pd.notna(season):\n",
    "            season_data = player_season_summary[player_season_summary['Season'] == season]\n",
    "            if len(season_data) > 0:\n",
    "                top_performers = season_data.nlargest(5, 'Avg_Performance_Score')\n",
    "                print(f\"\\n{season} Season - Top 5 Performers:\")\n",
    "                display_cols = [col for col in ['Player', 'Position_Group', 'Avg_Performance_Score', 'Games_Played'] \n",
    "                               if col in top_performers.columns]\n",
    "                print(top_performers[display_cols].to_string(index=False))\n",
    "\n",
    "print(\"\\n\\n=== POSITION ANALYSIS ACROSS SEASONS ===\")\n",
    "try:\n",
    "    position_across_seasons = combined_df.groupby(['Position_Group', 'Season'])['Performance_Score'].mean().unstack(fill_value=0).round(2)\n",
    "    print(position_across_seasons.to_string())\n",
    "except Exception as e:\n",
    "    print(f\"Could not create position analysis: {e}\")\n",
    "    # Simple alternative\n",
    "    print(combined_df.groupby(['Position_Group', 'Season'])['Performance_Score'].mean().round(2).to_string())\n",
    "\n",
    "# Save all files with error handling\n",
    "try:\n",
    "    # 1. Enhanced combined dataset with all columns\n",
    "    enhanced_path = '/Users/mariamoramora/Documents/GitHub/ADS599_Capstone/Soccer_Performance_Score/data/real_madrid_combined/real_madrid_enhanced_complete.csv'\n",
    "    combined_df.to_csv(enhanced_path, index=False)\n",
    "    print(f\"✓ Enhanced dataset saved: {enhanced_path}\")\n",
    "except Exception as e:\n",
    "    print(f\"✗ Error saving enhanced dataset: {e}\")\n",
    "\n",
    "try:\n",
    "    # 2. Season-Position summary\n",
    "    season_pos_path = '/Users/mariamoramora/Documents/GitHub/ADS599_Capstone/Soccer_Performance_Score/data/real_madrid_combined/summary_by_season_position.csv'\n",
    "    season_position_summary.to_csv(season_pos_path, index=False)\n",
    "    print(f\"✓ Season-Position summary saved: {season_pos_path}\")\n",
    "except Exception as e:\n",
    "    print(f\"✗ Error saving season-position summary: {e}\")\n",
    "\n",
    "try:\n",
    "    # 3. Player-Season summary\n",
    "    player_season_path = '/Users/mariamoramora/Documents/GitHub/ADS599_Capstone/Soccer_Performance_Score/data/real_madrid_combined/player_summary_by_season.csv'\n",
    "    player_season_summary.to_csv(player_season_path, index=False)\n",
    "    print(f\"✓ Player summary saved: {player_season_path}\")\n",
    "except Exception as e:\n",
    "    print(f\"✗ Error saving player summary: {e}\")\n",
    "\n",
    "try:\n",
    "    # 4. Position performance across seasons\n",
    "    position_seasons_path = '/Users/mariamoramora/Documents/GitHub/ADS599_Capstone/Soccer_Performance_Score/data/real_madrid_combined/position_performance_across_seasons.csv'\n",
    "    if 'position_across_seasons' in locals():\n",
    "        position_across_seasons.to_csv(position_seasons_path)\n",
    "        print(f\"✓ Position analysis saved: {position_seasons_path}\")\n",
    "    else:\n",
    "        # Create simple version\n",
    "        simple_position_analysis = combined_df.groupby(['Position_Group', 'Season'])['Performance_Score'].mean().reset_index()\n",
    "        simple_position_analysis.to_csv(position_seasons_path, index=False)\n",
    "        print(f\"✓ Simple position analysis saved: {position_seasons_path}\")\n",
    "except Exception as e:\n",
    "    print(f\"✗ Error saving position analysis: {e}\")\n",
    "\n",
    "print(f\"\\n=== DATASET INFO ===\")\n",
    "print(f\"Total records in enhanced dataset: {len(combined_df)}\")\n",
    "print(f\"Seasons covered: {sorted(combined_df['Season'].unique())}\")\n",
    "print(f\"Position groups: {combined_df['Position_Group'].value_counts().to_dict()}\")\n",
    "print(f\"Unique players: {combined_df['Player'].nunique()}\")\n",
    "\n",
    "# Show sample of enhanced dataset\n",
    "print(f\"\\n=== SAMPLE OF ENHANCED DATASET ===\")\n",
    "sample_cols = ['Date', 'Season', 'Player', 'Position_Group', 'Performance_Score', 'Min', 'Gls', 'Ast']\n",
    "available_cols = [col for col in sample_cols if col in combined_df.columns]\n",
    "print(combined_df[available_cols].head(15).to_string(index=False))\n",
    "\n",
    "print(\"\\n🏆 REAL MADRID PERFORMANCE ANALYSIS COMPLETE! 🏆\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Second code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== REAL MADRID DATA PREPROCESSING & PERFORMANCE ANALYSIS ===\n",
      "✓ Loaded dataset: (1550, 73)\n",
      "Original columns: 73\n",
      "\n",
      "🧹 PHASE 1: DATA CLEANING & PREPROCESSING\n",
      "✓ Removed columns: ['Match URL', 'Challenges Tkl%', 'number']\n",
      "✓ Cleaning Age column...\n",
      "  Age range: 17 - 39\n",
      "✓ Cleaning Nation column...\n",
      "  Sample nations: ['BRA', 'CRO', 'ESP', 'ENG', 'FRA', 'GER', 'URU', 'AUT', 'UKR', 'MAR']\n",
      "✓ Column names cleaned\n",
      "✓ Basic setup complete\n",
      "Cleaned dataset shape: (1550, 72)\n",
      "Position distribution: {'Defense': 483, 'Midfield': 410, 'Forward': 211, 'Goalkeeper': 104}\n",
      "\n",
      "Cleaning statistical columns...\n",
      "  Processing Min\n",
      "    ✓ Range: 1 - 120\n",
      "  Processing Gls\n",
      "    ✓ Range: 0 - 3\n",
      "  Processing Ast\n",
      "    ⚠️ Could not calculate range, but column processed\n",
      "  Processing Sh\n",
      "    ✓ Range: 0 - 11\n",
      "  Processing SoT\n",
      "    ✓ Range: 0 - 5\n",
      "  Processing Tkl\n",
      "    ✓ Range: 0 - 10\n",
      "  Processing Int\n",
      "    ⚠️ Could not calculate range, but column processed\n",
      "  Processing Blocks\n",
      "    ✓ Range: 0 - 7\n",
      "  Processing Clr\n",
      "    ✓ Range: 0 - 14\n",
      "  Processing SCA\n",
      "    ✓ Range: 0 - 13\n",
      "  Processing KP\n",
      "    ✓ Range: 0 - 8\n",
      "  Processing Expected xG\n",
      "    ✓ Range: 0.0 - 2.1\n",
      "  Processing Total Cmp%\n",
      "    ✓ Range: 0.0 - 100.0\n",
      "  Processing Long Cmp%\n",
      "    ✓ Range: 0.0 - 100.0\n",
      "  Processing Total Att\n",
      "    ✓ Range: 0 - 135\n",
      "  Processing Passes PrgP\n",
      "    ✓ Range: 0 - 23\n",
      "✓ Take-on statistics calculated\n",
      "✓ Data preprocessing completed\n",
      "\n",
      "⚽ PHASE 2: CALCULATING PERFORMANCE SCORES\n",
      "\n",
      "Goalkeepers: 104 records\n",
      "  ✓ Score range: 44.0 - 100.0\n",
      "\n",
      "Forwards: 211 records\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "cannot reindex on an axis with duplicate labels",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[30], line 168\u001b[0m\n\u001b[1;32m    166\u001b[0m \u001b[38;5;66;03m# Calculate per-90 stats\u001b[39;00m\n\u001b[1;32m    167\u001b[0m fw_data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mGls_90\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m per_90(fw_data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mGls\u001b[39m\u001b[38;5;124m'\u001b[39m], fw_data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMin\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m--> 168\u001b[0m fw_data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAst_90\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m per_90(fw_data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAst\u001b[39m\u001b[38;5;124m'\u001b[39m], fw_data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMin\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m    169\u001b[0m fw_data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSh_90\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m per_90(fw_data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSh\u001b[39m\u001b[38;5;124m'\u001b[39m], fw_data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMin\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m    170\u001b[0m fw_data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSoT_90\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m per_90(fw_data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSoT\u001b[39m\u001b[38;5;124m'\u001b[39m], fw_data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMin\u001b[39m\u001b[38;5;124m'\u001b[39m])\n",
      "Cell \u001b[0;32mIn[30], line 137\u001b[0m, in \u001b[0;36mper_90\u001b[0;34m(stat, minutes)\u001b[0m\n\u001b[1;32m    136\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mper_90\u001b[39m(stat, minutes):\n\u001b[0;32m--> 137\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m np\u001b[38;5;241m.\u001b[39mwhere(minutes \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m, stat \u001b[38;5;241m/\u001b[39m minutes \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m90\u001b[39m, \u001b[38;5;241m0\u001b[39m)\n",
      "File \u001b[0;32m/opt/miniconda3/lib/python3.12/site-packages/pandas/core/ops/common.py:76\u001b[0m, in \u001b[0;36m_unpack_zerodim_and_defer.<locals>.new_method\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m     72\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mNotImplemented\u001b[39m\n\u001b[1;32m     74\u001b[0m other \u001b[38;5;241m=\u001b[39m item_from_zerodim(other)\n\u001b[0;32m---> 76\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m method(\u001b[38;5;28mself\u001b[39m, other)\n",
      "File \u001b[0;32m/opt/miniconda3/lib/python3.12/site-packages/pandas/core/arraylike.py:210\u001b[0m, in \u001b[0;36mOpsMixin.__truediv__\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m    208\u001b[0m \u001b[38;5;129m@unpack_zerodim_and_defer\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__truediv__\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    209\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__truediv__\u001b[39m(\u001b[38;5;28mself\u001b[39m, other):\n\u001b[0;32m--> 210\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_arith_method(other, operator\u001b[38;5;241m.\u001b[39mtruediv)\n",
      "File \u001b[0;32m/opt/miniconda3/lib/python3.12/site-packages/pandas/core/frame.py:7910\u001b[0m, in \u001b[0;36mDataFrame._arith_method\u001b[0;34m(self, other, op)\u001b[0m\n\u001b[1;32m   7907\u001b[0m axis: Literal[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m  \u001b[38;5;66;03m# only relevant for Series other case\u001b[39;00m\n\u001b[1;32m   7908\u001b[0m other \u001b[38;5;241m=\u001b[39m ops\u001b[38;5;241m.\u001b[39mmaybe_prepare_scalar_for_op(other, (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mshape[axis],))\n\u001b[0;32m-> 7910\u001b[0m \u001b[38;5;28mself\u001b[39m, other \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_align_for_op(other, axis, flex\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, level\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m   7912\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m np\u001b[38;5;241m.\u001b[39merrstate(\u001b[38;5;28mall\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m   7913\u001b[0m     new_data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dispatch_frame_op(other, op, axis\u001b[38;5;241m=\u001b[39maxis)\n",
      "File \u001b[0;32m/opt/miniconda3/lib/python3.12/site-packages/pandas/core/frame.py:8211\u001b[0m, in \u001b[0;36mDataFrame._align_for_op\u001b[0;34m(self, other, axis, flex, level)\u001b[0m\n\u001b[1;32m   8204\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m left\u001b[38;5;241m.\u001b[39maxes[axis]\u001b[38;5;241m.\u001b[39mequals(right\u001b[38;5;241m.\u001b[39mindex):\n\u001b[1;32m   8205\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   8206\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOperands are not aligned. Do \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   8207\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`left, right = left.align(right, axis=1, copy=False)` \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   8208\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbefore operating.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   8209\u001b[0m             )\n\u001b[0;32m-> 8211\u001b[0m     left, right \u001b[38;5;241m=\u001b[39m left\u001b[38;5;241m.\u001b[39malign(\n\u001b[1;32m   8212\u001b[0m         right,\n\u001b[1;32m   8213\u001b[0m         join\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mouter\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   8214\u001b[0m         axis\u001b[38;5;241m=\u001b[39maxis,\n\u001b[1;32m   8215\u001b[0m         level\u001b[38;5;241m=\u001b[39mlevel,\n\u001b[1;32m   8216\u001b[0m         copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m   8217\u001b[0m     )\n\u001b[1;32m   8218\u001b[0m     right \u001b[38;5;241m=\u001b[39m left\u001b[38;5;241m.\u001b[39m_maybe_align_series_as_frame(right, axis)\n\u001b[1;32m   8220\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m left, right\n",
      "File \u001b[0;32m/opt/miniconda3/lib/python3.12/site-packages/pandas/core/generic.py:10447\u001b[0m, in \u001b[0;36mNDFrame.align\u001b[0;34m(self, other, join, axis, level, copy, fill_value, method, limit, fill_axis, broadcast_axis)\u001b[0m\n\u001b[1;32m  10434\u001b[0m     left, _right, join_index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_align_frame(\n\u001b[1;32m  10435\u001b[0m         other,\n\u001b[1;32m  10436\u001b[0m         join\u001b[38;5;241m=\u001b[39mjoin,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m  10443\u001b[0m         fill_axis\u001b[38;5;241m=\u001b[39mfill_axis,\n\u001b[1;32m  10444\u001b[0m     )\n\u001b[1;32m  10446\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(other, ABCSeries):\n\u001b[0;32m> 10447\u001b[0m     left, _right, join_index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_align_series(\n\u001b[1;32m  10448\u001b[0m         other,\n\u001b[1;32m  10449\u001b[0m         join\u001b[38;5;241m=\u001b[39mjoin,\n\u001b[1;32m  10450\u001b[0m         axis\u001b[38;5;241m=\u001b[39maxis,\n\u001b[1;32m  10451\u001b[0m         level\u001b[38;5;241m=\u001b[39mlevel,\n\u001b[1;32m  10452\u001b[0m         copy\u001b[38;5;241m=\u001b[39mcopy,\n\u001b[1;32m  10453\u001b[0m         fill_value\u001b[38;5;241m=\u001b[39mfill_value,\n\u001b[1;32m  10454\u001b[0m         method\u001b[38;5;241m=\u001b[39mmethod,\n\u001b[1;32m  10455\u001b[0m         limit\u001b[38;5;241m=\u001b[39mlimit,\n\u001b[1;32m  10456\u001b[0m         fill_axis\u001b[38;5;241m=\u001b[39mfill_axis,\n\u001b[1;32m  10457\u001b[0m     )\n\u001b[1;32m  10458\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:  \u001b[38;5;66;03m# pragma: no cover\u001b[39;00m\n\u001b[1;32m  10459\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124munsupported type: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(other)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/opt/miniconda3/lib/python3.12/site-packages/pandas/core/generic.py:10590\u001b[0m, in \u001b[0;36mNDFrame._align_series\u001b[0;34m(self, other, join, axis, level, copy, fill_value, method, limit, fill_axis)\u001b[0m\n\u001b[1;32m  10588\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m lidx \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m  10589\u001b[0m     bm_axis \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_block_manager_axis(\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m> 10590\u001b[0m     fdata \u001b[38;5;241m=\u001b[39m fdata\u001b[38;5;241m.\u001b[39mreindex_indexer(join_index, lidx, axis\u001b[38;5;241m=\u001b[39mbm_axis)\n\u001b[1;32m  10592\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m copy \u001b[38;5;129;01mand\u001b[39;00m fdata \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_mgr:\n\u001b[1;32m  10593\u001b[0m     fdata \u001b[38;5;241m=\u001b[39m fdata\u001b[38;5;241m.\u001b[39mcopy()\n",
      "File \u001b[0;32m/opt/miniconda3/lib/python3.12/site-packages/pandas/core/internals/managers.py:674\u001b[0m, in \u001b[0;36mBaseBlockManager.reindex_indexer\u001b[0;34m(self, new_axis, indexer, axis, fill_value, allow_dups, copy, only_slice, use_na_proxy)\u001b[0m\n\u001b[1;32m    672\u001b[0m \u001b[38;5;66;03m# some axes don't allow reindexing with dups\u001b[39;00m\n\u001b[1;32m    673\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m allow_dups:\n\u001b[0;32m--> 674\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maxes[axis]\u001b[38;5;241m.\u001b[39m_validate_can_reindex(indexer)\n\u001b[1;32m    676\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m axis \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mndim:\n\u001b[1;32m    677\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mIndexError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRequested axis not found in manager\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/opt/miniconda3/lib/python3.12/site-packages/pandas/core/indexes/base.py:4321\u001b[0m, in \u001b[0;36mIndex._validate_can_reindex\u001b[0;34m(self, indexer)\u001b[0m\n\u001b[1;32m   4319\u001b[0m \u001b[38;5;66;03m# trying to reindex on an axis with duplicates\u001b[39;00m\n\u001b[1;32m   4320\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_index_as_unique \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(indexer):\n\u001b[0;32m-> 4321\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcannot reindex on an axis with duplicate labels\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mValueError\u001b[0m: cannot reindex on an axis with duplicate labels"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "print(\"=== REAL MADRID DATA PREPROCESSING & PERFORMANCE ANALYSIS ===\")\n",
    "\n",
    "# Load the data\n",
    "original_path = '/Users/mariamoramora/Documents/GitHub/ADS599_Capstone/Soccer_Performance_Score/data/real_madrid_combined/combined_real_madrid.csv'\n",
    "\n",
    "try:\n",
    "    df = pd.read_csv(original_path)\n",
    "    print(\"✓ Loaded dataset:\", df.shape)\n",
    "except FileNotFoundError:\n",
    "    print(\"❌ File not found:\", original_path)\n",
    "    exit()\n",
    "\n",
    "print(\"Original columns:\", len(df.columns))\n",
    "\n",
    "# ==========================================\n",
    "# PHASE 1: DATA CLEANING & PREPROCESSING\n",
    "# ==========================================\n",
    "\n",
    "print(\"\\n🧹 PHASE 1: DATA CLEANING & PREPROCESSING\")\n",
    "\n",
    "# 1. Remove problematic columns\n",
    "columns_to_remove = ['Match URL', 'Challenges Tkl%', 'number']\n",
    "existing_cols_to_remove = [col for col in columns_to_remove if col in df.columns]\n",
    "if existing_cols_to_remove:\n",
    "    df = df.drop(columns=existing_cols_to_remove)\n",
    "    print(\"✓ Removed columns:\", existing_cols_to_remove)\n",
    "\n",
    "# 2. Clean Age column (remove everything after the dash)\n",
    "if 'Age' in df.columns:\n",
    "    print(\"✓ Cleaning Age column...\")\n",
    "    df['Age'] = df['Age'].astype(str).str.split('-').str[0]\n",
    "    df['Age'] = pd.to_numeric(df['Age'], errors='coerce').fillna(0).astype(int)\n",
    "    print(\"  Age range:\", df['Age'].min(), \"-\", df['Age'].max())\n",
    "\n",
    "# 3. Clean Nation column (keep only last 3 characters)\n",
    "if 'Nation' in df.columns:\n",
    "    print(\"✓ Cleaning Nation column...\")\n",
    "    df['Nation'] = df['Nation'].astype(str).str[-3:]\n",
    "    print(\"  Sample nations:\", df['Nation'].unique()[:10].tolist())\n",
    "\n",
    "# 4. Clean column names\n",
    "df.columns = df.columns.str.strip()\n",
    "print(\"✓ Column names cleaned\")\n",
    "\n",
    "# 5. Setup Date and Season\n",
    "df['Date'] = pd.to_datetime(df['Date'], format='%m/%d/%y', errors='coerce')\n",
    "df['Season'] = df['Date'].apply(lambda x: \n",
    "    str(x.year) + \"-\" + str(x.year + 1)[-2:] if pd.notna(x) and x.month >= 8 \n",
    "    else str(x.year - 1) + \"-\" + str(x.year)[-2:] if pd.notna(x) else \"Unknown\"\n",
    ")\n",
    "\n",
    "# 6. Position mapping\n",
    "position_mapping = {\n",
    "    'GK': 'Goalkeeper', 'CB': 'Defense', 'LB': 'Defense', 'RB': 'Defense',\n",
    "    'DM': 'Midfield', 'CM': 'Midfield', 'LM': 'Midfield', 'RM': 'Midfield', 'AM': 'Midfield',\n",
    "    'FW': 'Forward'\n",
    "}\n",
    "df['Position_Group'] = df['Pos'].map(position_mapping)\n",
    "\n",
    "print(\"✓ Basic setup complete\")\n",
    "print(\"Cleaned dataset shape:\", df.shape)\n",
    "print(\"Position distribution:\", df['Position_Group'].value_counts().to_dict())\n",
    "\n",
    "# 7. Clean key statistical columns\n",
    "def safe_numeric_conversion(series, default_value=0):\n",
    "    \"\"\"Convert series to numeric safely\"\"\"\n",
    "    try:\n",
    "        # Convert to string first, handle empty/null values\n",
    "        series_str = series.astype(str).replace(['nan', 'NaN', '', ' ', 'None'], '0')\n",
    "        # Convert to numeric\n",
    "        result = pd.to_numeric(series_str, errors='coerce').fillna(default_value)\n",
    "        return result\n",
    "    except:\n",
    "        # If anything fails, return default values\n",
    "        return pd.Series([default_value] * len(series))\n",
    "\n",
    "# Key columns we need for analysis\n",
    "key_stats = {\n",
    "    'Min': 0, 'Gls': 0, 'Ast': 0, 'Sh': 0, 'SoT': 0, 'Tkl': 0, 'Int': 0, \n",
    "    'Blocks': 0, 'Clr': 0, 'SCA': 0, 'KP': 0, 'Expected xG': 0,\n",
    "    'Total Cmp%': 0, 'Long Cmp%': 0, 'Total Att': 0, 'Passes PrgP': 0\n",
    "}\n",
    "\n",
    "print(\"\\nCleaning statistical columns...\")\n",
    "for col, default in key_stats.items():\n",
    "    if col in df.columns:\n",
    "        print(\"  Processing\", col)\n",
    "        df[col] = safe_numeric_conversion(df[col], default)\n",
    "        \n",
    "        # Safe min/max calculation with error handling\n",
    "        try:\n",
    "            col_values = df[col]\n",
    "            if len(col_values) > 0:\n",
    "                # Ensure all values are numeric\n",
    "                numeric_values = pd.to_numeric(col_values, errors='coerce')\n",
    "                if not numeric_values.isnull().all():\n",
    "                    min_val = numeric_values.min()\n",
    "                    max_val = numeric_values.max()\n",
    "                    print(\"    ✓ Range:\", round(min_val, 1), \"-\", round(max_val, 1))\n",
    "                else:\n",
    "                    print(\"    ✓ All values set to default:\", default)\n",
    "            else:\n",
    "                print(\"    ✓ Empty column, set to default:\", default)\n",
    "        except Exception as e:\n",
    "            print(\"    ⚠️ Could not calculate range, but column processed\")\n",
    "    else:\n",
    "        df[col] = default\n",
    "        print(\"  + Created\", col, \"=\", default)\n",
    "\n",
    "# 8. Handle Take-ons\n",
    "if 'Take-Ons Att' in df.columns and 'Take-Ons Succ' in df.columns:\n",
    "    df['Take-Ons Att'] = safe_numeric_conversion(df['Take-Ons Att'], 0)\n",
    "    df['Take-Ons Succ'] = safe_numeric_conversion(df['Take-Ons Succ'], 0)\n",
    "    df['Take-Ons Succ%'] = np.where(df['Take-Ons Att'] > 0, \n",
    "                                   (df['Take-Ons Succ'] / df['Take-Ons Att'] * 100), 0)\n",
    "    print(\"✓ Take-on statistics calculated\")\n",
    "else:\n",
    "    df['Take-Ons Succ%'] = 0\n",
    "    print(\"✓ Take-on columns not found, set to 0\")\n",
    "\n",
    "print(\"✓ Data preprocessing completed\")\n",
    "\n",
    "# ==========================================\n",
    "# PHASE 2: PERFORMANCE SCORING\n",
    "# ==========================================\n",
    "\n",
    "print(\"\\n⚽ PHASE 2: CALCULATING PERFORMANCE SCORES\")\n",
    "\n",
    "df['Performance_Score'] = 0.0\n",
    "\n",
    "# Helper function for per-90 calculations\n",
    "def per_90(stat, minutes):\n",
    "    return np.where(minutes > 0, stat / minutes * 90, 0)\n",
    "\n",
    "# Safe function to get numeric min/max\n",
    "def safe_min_max(series):\n",
    "    try:\n",
    "        numeric_series = pd.to_numeric(series, errors='coerce')\n",
    "        if not numeric_series.isnull().all():\n",
    "            return numeric_series.min(), numeric_series.max()\n",
    "        else:\n",
    "            return 0.0, 0.0\n",
    "    except:\n",
    "        return 0.0, 0.0\n",
    "\n",
    "# GOALKEEPERS\n",
    "gk_mask = df['Position_Group'] == 'Goalkeeper'\n",
    "if gk_mask.sum() > 0:\n",
    "    print(\"\\nGoalkeepers:\", gk_mask.sum(), \"records\")\n",
    "    gk_score = df.loc[gk_mask, 'Total Cmp%'] * 0.6 + df.loc[gk_mask, 'Long Cmp%'] * 0.4\n",
    "    df.loc[gk_mask, 'Performance_Score'] = gk_score\n",
    "    min_score, max_score = safe_min_max(gk_score)\n",
    "    print(\"  ✓ Score range:\", round(min_score, 1), \"-\", round(max_score, 1))\n",
    "\n",
    "# FORWARDS\n",
    "fw_mask = df['Position_Group'] == 'Forward'\n",
    "if fw_mask.sum() > 0:\n",
    "    print(\"\\nForwards:\", fw_mask.sum(), \"records\")\n",
    "    \n",
    "    fw_data = df[fw_mask].copy()\n",
    "    \n",
    "    # Calculate per-90 stats\n",
    "    fw_data['Gls_90'] = per_90(fw_data['Gls'], fw_data['Min'])\n",
    "    fw_data['Ast_90'] = per_90(fw_data['Ast'], fw_data['Min'])\n",
    "    fw_data['Sh_90'] = per_90(fw_data['Sh'], fw_data['Min'])\n",
    "    fw_data['SoT_90'] = per_90(fw_data['SoT'], fw_data['Min'])\n",
    "    fw_data['xG_90'] = per_90(fw_data['Expected xG'], fw_data['Min'])\n",
    "    \n",
    "    # Get max values for normalization (avoid division by zero)\n",
    "    _, max_g = safe_min_max(fw_data['Gls_90'])\n",
    "    _, max_s = safe_min_max(fw_data['Sh_90'])\n",
    "    _, max_sot = safe_min_max(fw_data['SoT_90'])\n",
    "    _, max_xg = safe_min_max(fw_data['xG_90'])\n",
    "    \n",
    "    max_g = max(max_g, 0.1)\n",
    "    max_s = max(max_s, 0.1)\n",
    "    max_sot = max(max_sot, 0.1)\n",
    "    max_xg = max(max_xg, 0.1)\n",
    "    \n",
    "    # Calculate weighted score\n",
    "    fw_score = (\n",
    "        (fw_data['Gls_90'] / max_g * 100) * 0.35 +      # Goals 35%\n",
    "        (fw_data['Ast_90'] * 25) * 0.20 +               # Assists 20%\n",
    "        (fw_data['Sh_90'] / max_s * 100) * 0.05 +       # Shots 5%\n",
    "        (fw_data['SoT_90'] / max_sot * 100) * 0.15 +    # SoT 15%\n",
    "        (fw_data['xG_90'] / max_xg * 100) * 0.15 +      # xG 15%\n",
    "        fw_data['Take-Ons Succ%'] * 0.10                # Take-ons 10%\n",
    "    )\n",
    "    \n",
    "    df.loc[fw_mask, 'Performance_Score'] = fw_score\n",
    "    min_score, max_score = safe_min_max(fw_score)\n",
    "    print(\"  ✓ Score range:\", round(min_score, 1), \"-\", round(max_score, 1))\n",
    "\n",
    "# MIDFIELDERS\n",
    "mid_mask = df['Position_Group'] == 'Midfield'\n",
    "if mid_mask.sum() > 0:\n",
    "    print(\"\\nMidfielders:\", mid_mask.sum(), \"records\")\n",
    "    \n",
    "    mid_data = df[mid_mask].copy()\n",
    "    \n",
    "    # Calculate per-90 stats\n",
    "    mid_data['Pass_90'] = per_90(mid_data['Total Att'], mid_data['Min'])\n",
    "    mid_data['Prog_90'] = per_90(mid_data['Passes PrgP'], mid_data['Min'])\n",
    "    mid_data['SCA_90'] = per_90(mid_data['SCA'], mid_data['Min'])\n",
    "    mid_data['KP_90'] = per_90(mid_data['KP'], mid_data['Min'])\n",
    "    mid_data['Ast_90'] = per_90(mid_data['Ast'], mid_data['Min'])\n",
    "    \n",
    "    # Get max values for normalization\n",
    "    _, max_pass = safe_min_max(mid_data['Pass_90'])\n",
    "    _, max_prog = safe_min_max(mid_data['Prog_90'])\n",
    "    _, max_sca = safe_min_max(mid_data['SCA_90'])\n",
    "    _, max_kp = safe_min_max(mid_data['KP_90'])\n",
    "    \n",
    "    max_pass = max(max_pass, 0.1)\n",
    "    max_prog = max(max_prog, 0.1)\n",
    "    max_sca = max(max_sca, 0.1)\n",
    "    max_kp = max(max_kp, 0.1)\n",
    "    \n",
    "    # Calculate weighted score\n",
    "    mid_score = (\n",
    "        mid_data['Total Cmp%'] * 0.20 +                         # Pass accuracy 20%\n",
    "        (mid_data['Pass_90'] / max_pass * 100) * 0.15 +         # Pass volume 15%\n",
    "        (mid_data['Prog_90'] / max_prog * 100) * 0.20 +         # Progressive 20%\n",
    "        (mid_data['SCA_90'] / max_sca * 100) * 0.20 +           # Creativity 20%\n",
    "        (mid_data['KP_90'] / max_kp * 100) * 0.15 +             # Key passes 15%\n",
    "        (mid_data['Ast_90'] * 25) * 0.10                        # Assists 10%\n",
    "    )\n",
    "    \n",
    "    df.loc[mid_mask, 'Performance_Score'] = mid_score\n",
    "    min_score, max_score = safe_min_max(mid_score)\n",
    "    print(\"  ✓ Score range:\", round(min_score, 1), \"-\", round(max_score, 1))\n",
    "\n",
    "# DEFENDERS\n",
    "def_mask = df['Position_Group'] == 'Defense'\n",
    "if def_mask.sum() > 0:\n",
    "    print(\"\\nDefenders:\", def_mask.sum(), \"records\")\n",
    "    \n",
    "    def_data = df[def_mask].copy()\n",
    "    \n",
    "    # Calculate per-90 stats\n",
    "    def_data['Tkl_90'] = per_90(def_data['Tkl'], def_data['Min'])\n",
    "    def_data['Int_90'] = per_90(def_data['Int'], def_data['Min'])\n",
    "    def_data['Blk_90'] = per_90(def_data['Blocks'], def_data['Min'])\n",
    "    def_data['Clr_90'] = per_90(def_data['Clr'], def_data['Min'])\n",
    "    \n",
    "    # Get max values for normalization\n",
    "    _, max_tkl = safe_min_max(def_data['Tkl_90'])\n",
    "    _, max_int = safe_min_max(def_data['Int_90'])\n",
    "    _, max_blk = safe_min_max(def_data['Blk_90'])\n",
    "    _, max_clr = safe_min_max(def_data['Clr_90'])\n",
    "    \n",
    "    max_tkl = max(max_tkl, 0.1)\n",
    "    max_int = max(max_int, 0.1)\n",
    "    max_blk = max(max_blk, 0.1)\n",
    "    max_clr = max(max_clr, 0.1)\n",
    "    \n",
    "    # Calculate weighted score\n",
    "    def_score = (\n",
    "        (def_data['Tkl_90'] / max_tkl * 100) * 0.25 +           # Tackles 25%\n",
    "        (def_data['Int_90'] / max_int * 100) * 0.25 +           # Interceptions 25%\n",
    "        (def_data['Blk_90'] / max_blk * 100) * 0.20 +           # Blocks 20%\n",
    "        (def_data['Clr_90'] / max_clr * 100) * 0.15 +           # Clearances 15%\n",
    "        def_data['Total Cmp%'] * 0.15                           # Pass accuracy 15%\n",
    "    )\n",
    "    \n",
    "    df.loc[def_mask, 'Performance_Score'] = def_score\n",
    "    min_score, max_score = safe_min_max(def_score)\n",
    "    print(\"  ✓ Score range:\", round(min_score, 1), \"-\", round(max_score, 1))\n",
    "\n",
    "# Cap all scores at 100\n",
    "df['Performance_Score'] = df['Performance_Score'].clip(0, 100)\n",
    "\n",
    "print(\"\\n✅ SCORING COMPLETED\")\n",
    "overall_min = float(df['Performance_Score'].min())\n",
    "overall_max = float(df['Performance_Score'].max())\n",
    "print(\"Overall range:\", round(overall_min, 1), \"-\", round(overall_max, 1))\n",
    "\n",
    "# ==========================================\n",
    "# PHASE 3: ANALYSIS & RESULTS\n",
    "# ==========================================\n",
    "\n",
    "print(\"\\n📊 PHASE 3: ANALYSIS & RESULTS\")\n",
    "\n",
    "# Check Antonio Rüdiger specifically\n",
    "print(\"\\n=== VALIDATION CHECK ===\")\n",
    "rudiger = df[df['Player'].str.contains('Rüdiger', na=False, case=False)]\n",
    "if len(rudiger) > 0:\n",
    "    rudiger_avg = rudiger['Performance_Score'].mean()\n",
    "    print(\"✓ Rüdiger average score:\", round(rudiger_avg, 1), \"(should not be 50.0)\")\n",
    "    rudiger_best = rudiger.nlargest(3, 'Performance_Score')[\n",
    "        ['Date', 'Performance_Score', 'Min', 'Tkl', 'Int', 'Blocks', 'Total Cmp%']\n",
    "    ]\n",
    "    print(\"✓ Rüdiger's top performances:\")\n",
    "    print(rudiger_best.to_string(index=False))\n",
    "\n",
    "# Top performances\n",
    "print(\"\\n=== TOP 15 INDIVIDUAL PERFORMANCES ===\")\n",
    "top_individual = df.nlargest(15, 'Performance_Score')[\n",
    "    ['Date', 'Player', 'Position_Group', 'Performance_Score', 'Min', 'Gls', 'Ast', 'Opponent']\n",
    "]\n",
    "print(top_individual.to_string(index=False))\n",
    "\n",
    "# Player averages\n",
    "print(\"\\n=== BEST SEASON AVERAGES (500+ minutes) ===\")\n",
    "player_avg = df.groupby(['Player', 'Position_Group', 'Season']).agg({\n",
    "    'Performance_Score': 'mean',\n",
    "    'Min': 'sum',\n",
    "    'Gls': 'sum',\n",
    "    'Ast': 'sum',\n",
    "    'Age': 'first',\n",
    "    'Nation': 'first'\n",
    "}).round(2).reset_index()\n",
    "\n",
    "significant_players = player_avg[player_avg['Min'] >= 500]\n",
    "top_averages = significant_players.nlargest(15, 'Performance_Score')\n",
    "print(top_averages.to_string(index=False))\n",
    "\n",
    "# ==========================================\n",
    "# PHASE 4: SAVE RESULTS\n",
    "# ==========================================\n",
    "\n",
    "print(\"\\n💾 PHASE 4: SAVING RESULTS\")\n",
    "\n",
    "output_dir = '/Users/mariamoramora/Documents/GitHub/ADS599_Capstone/Soccer_Performance_Score/data/real_madrid_combined'\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Save complete cleaned dataset\n",
    "final_path = output_dir + '/real_madrid_cleaned_with_scores.csv'\n",
    "df.to_csv(final_path, index=False)\n",
    "\n",
    "# Save player averages\n",
    "averages_path = output_dir + '/player_season_averages_clean.csv'\n",
    "player_avg.to_csv(averages_path, index=False)\n",
    "\n",
    "print(\"✅ SAVED:\")\n",
    "print(\"📊 Complete cleaned data:\", final_path)\n",
    "print(\"🏆 Player averages:\", averages_path)\n",
    "\n",
    "print(\"\\n🎯 FINAL SUMMARY:\")\n",
    "print(\"• Processed\", len(df), \"match records\")\n",
    "print(\"• Unique players:\", df['Player'].nunique())\n",
    "print(\"• Age range:\", df['Age'].min(), \"-\", df['Age'].max(), \"years\")\n",
    "print(\"• Nations:\", df['Nation'].nunique(), \"different countries\")\n",
    "print(\"• Players with 500+ minutes:\", len(significant_players))\n",
    "best_performer = df.loc[df['Performance_Score'].idxmax(), 'Player']\n",
    "best_score = float(df['Performance_Score'].max())\n",
    "print(\"• Best performer:\", best_performer, \"(\" + str(round(best_score, 1)) + \")\")\n",
    "\n",
    "print(\"\\n🏆 REAL MADRID ANALYSIS COMPLETE! 🏆\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== REAL MADRID DATA PREPROCESSING & PERFORMANCE ANALYSIS ===\n",
      "✓ Loaded dataset: (1550, 73)\n",
      "Original columns: 73\n",
      "\n",
      "🧹 PHASE 1: DATA CLEANING & PREPROCESSING\n",
      "✓ Removed columns: ['Match URL', 'Challenges Tkl%', 'number']\n",
      "✓ Cleaning Age column...\n",
      "  Age range: 17 - 39\n",
      "✓ Cleaning Nation column...\n",
      "  Sample nations: ['BRA', 'CRO', 'ESP', 'ENG', 'FRA', 'GER', 'URU', 'AUT', 'UKR', 'MAR']\n",
      "✓ Column names cleaned\n",
      "✓ Basic setup complete\n",
      "Cleaned dataset shape: (1550, 72)\n",
      "Position distribution: {'Defense': 483, 'Midfield': 410, 'Forward': 211, 'Goalkeeper': 104}\n",
      "\n",
      "Cleaning statistical columns...\n",
      "  Processing Min\n",
      "    ✓ Range: 1 - 120\n",
      "  Processing Gls\n",
      "    ✓ Range: 0 - 3\n",
      "  Processing Ast\n",
      "    ⚠️ Could not calculate range, but column processed\n",
      "  Processing Sh\n",
      "    ✓ Range: 0 - 11\n",
      "  Processing SoT\n",
      "    ✓ Range: 0 - 5\n",
      "  Processing Tkl\n",
      "    ✓ Range: 0 - 10\n",
      "  Processing Int\n",
      "    ⚠️ Could not calculate range, but column processed\n",
      "  Processing Blocks\n",
      "    ✓ Range: 0 - 7\n",
      "  Processing Clr\n",
      "    ✓ Range: 0 - 14\n",
      "  Processing SCA\n",
      "    ✓ Range: 0 - 13\n",
      "  Processing KP\n",
      "    ✓ Range: 0 - 8\n",
      "  Processing Expected xG\n",
      "    ✓ Range: 0.0 - 2.1\n",
      "  Processing Total Cmp%\n",
      "    ✓ Range: 0.0 - 100.0\n",
      "  Processing Long Cmp%\n",
      "    ✓ Range: 0.0 - 100.0\n",
      "  Processing Total Att\n",
      "    ✓ Range: 0 - 135\n",
      "  Processing Passes PrgP\n",
      "    ✓ Range: 0 - 23\n",
      "✓ Take-on statistics calculated\n",
      "✓ Data preprocessing completed\n",
      "\n",
      "⚽ PHASE 2: CALCULATING PERFORMANCE SCORES\n",
      "\n",
      "Goalkeepers: 104 records\n",
      "  ✓ Score range: 44.0 - 100.0\n",
      "\n",
      "Forwards: 211 records\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "operands could not be broadcast together with shapes (211,2) (211,) ",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[31], line 178\u001b[0m\n\u001b[1;32m    176\u001b[0m \u001b[38;5;66;03m# Calculate per-90 stats using numpy operations\u001b[39;00m\n\u001b[1;32m    177\u001b[0m fw_data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mGls_90\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mwhere(min_values \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m, gls_values \u001b[38;5;241m/\u001b[39m min_values \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m90\u001b[39m, \u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m--> 178\u001b[0m fw_data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAst_90\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mwhere(min_values \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m, ast_values \u001b[38;5;241m/\u001b[39m min_values \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m90\u001b[39m, \u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m    179\u001b[0m fw_data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSh_90\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mwhere(min_values \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m, sh_values \u001b[38;5;241m/\u001b[39m min_values \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m90\u001b[39m, \u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m    180\u001b[0m fw_data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSoT_90\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mwhere(min_values \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m, sot_values \u001b[38;5;241m/\u001b[39m min_values \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m90\u001b[39m, \u001b[38;5;241m0\u001b[39m)\n",
      "\u001b[0;31mValueError\u001b[0m: operands could not be broadcast together with shapes (211,2) (211,) "
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "print(\"=== REAL MADRID DATA PREPROCESSING & PERFORMANCE ANALYSIS ===\")\n",
    "\n",
    "# Load the data\n",
    "original_path = '/Users/mariamoramora/Documents/GitHub/ADS599_Capstone/Soccer_Performance_Score/data/real_madrid_combined/combined_real_madrid.csv'\n",
    "\n",
    "try:\n",
    "    df = pd.read_csv(original_path)\n",
    "    print(\"✓ Loaded dataset:\", df.shape)\n",
    "except FileNotFoundError:\n",
    "    print(\"❌ File not found:\", original_path)\n",
    "    exit()\n",
    "\n",
    "print(\"Original columns:\", len(df.columns))\n",
    "\n",
    "# ==========================================\n",
    "# PHASE 1: DATA CLEANING & PREPROCESSING\n",
    "# ==========================================\n",
    "\n",
    "print(\"\\n🧹 PHASE 1: DATA CLEANING & PREPROCESSING\")\n",
    "\n",
    "# 1. Remove problematic columns\n",
    "columns_to_remove = ['Match URL', 'Challenges Tkl%', 'number']\n",
    "existing_cols_to_remove = [col for col in columns_to_remove if col in df.columns]\n",
    "if existing_cols_to_remove:\n",
    "    df = df.drop(columns=existing_cols_to_remove)\n",
    "    print(\"✓ Removed columns:\", existing_cols_to_remove)\n",
    "\n",
    "# 2. Clean Age column (remove everything after the dash)\n",
    "if 'Age' in df.columns:\n",
    "    print(\"✓ Cleaning Age column...\")\n",
    "    df['Age'] = df['Age'].astype(str).str.split('-').str[0]\n",
    "    df['Age'] = pd.to_numeric(df['Age'], errors='coerce').fillna(0).astype(int)\n",
    "    print(\"  Age range:\", df['Age'].min(), \"-\", df['Age'].max())\n",
    "\n",
    "# 3. Clean Nation column (keep only last 3 characters)\n",
    "if 'Nation' in df.columns:\n",
    "    print(\"✓ Cleaning Nation column...\")\n",
    "    df['Nation'] = df['Nation'].astype(str).str[-3:]\n",
    "    print(\"  Sample nations:\", df['Nation'].unique()[:10].tolist())\n",
    "\n",
    "# 4. Clean column names\n",
    "df.columns = df.columns.str.strip()\n",
    "print(\"✓ Column names cleaned\")\n",
    "\n",
    "# 5. Setup Date and Season\n",
    "df['Date'] = pd.to_datetime(df['Date'], format='%m/%d/%y', errors='coerce')\n",
    "df['Season'] = df['Date'].apply(lambda x: \n",
    "    str(x.year) + \"-\" + str(x.year + 1)[-2:] if pd.notna(x) and x.month >= 8 \n",
    "    else str(x.year - 1) + \"-\" + str(x.year)[-2:] if pd.notna(x) else \"Unknown\"\n",
    ")\n",
    "\n",
    "# 6. Position mapping\n",
    "position_mapping = {\n",
    "    'GK': 'Goalkeeper', 'CB': 'Defense', 'LB': 'Defense', 'RB': 'Defense',\n",
    "    'DM': 'Midfield', 'CM': 'Midfield', 'LM': 'Midfield', 'RM': 'Midfield', 'AM': 'Midfield',\n",
    "    'FW': 'Forward'\n",
    "}\n",
    "df['Position_Group'] = df['Pos'].map(position_mapping)\n",
    "\n",
    "print(\"✓ Basic setup complete\")\n",
    "print(\"Cleaned dataset shape:\", df.shape)\n",
    "print(\"Position distribution:\", df['Position_Group'].value_counts().to_dict())\n",
    "\n",
    "# 7. Clean key statistical columns\n",
    "def safe_numeric_conversion(series, default_value=0):\n",
    "    \"\"\"Convert series to numeric safely\"\"\"\n",
    "    try:\n",
    "        # Convert to string first, handle empty/null values\n",
    "        series_str = series.astype(str).replace(['nan', 'NaN', '', ' ', 'None'], '0')\n",
    "        # Convert to numeric\n",
    "        result = pd.to_numeric(series_str, errors='coerce').fillna(default_value)\n",
    "        return result\n",
    "    except:\n",
    "        # If anything fails, return default values\n",
    "        return pd.Series([default_value] * len(series))\n",
    "\n",
    "# Key columns we need for analysis\n",
    "key_stats = {\n",
    "    'Min': 0, 'Gls': 0, 'Ast': 0, 'Sh': 0, 'SoT': 0, 'Tkl': 0, 'Int': 0, \n",
    "    'Blocks': 0, 'Clr': 0, 'SCA': 0, 'KP': 0, 'Expected xG': 0,\n",
    "    'Total Cmp%': 0, 'Long Cmp%': 0, 'Total Att': 0, 'Passes PrgP': 0\n",
    "}\n",
    "\n",
    "print(\"\\nCleaning statistical columns...\")\n",
    "for col, default in key_stats.items():\n",
    "    if col in df.columns:\n",
    "        print(\"  Processing\", col)\n",
    "        df[col] = safe_numeric_conversion(df[col], default)\n",
    "        \n",
    "        # Safe min/max calculation with error handling\n",
    "        try:\n",
    "            col_values = df[col]\n",
    "            if len(col_values) > 0:\n",
    "                # Ensure all values are numeric\n",
    "                numeric_values = pd.to_numeric(col_values, errors='coerce')\n",
    "                if not numeric_values.isnull().all():\n",
    "                    min_val = numeric_values.min()\n",
    "                    max_val = numeric_values.max()\n",
    "                    print(\"    ✓ Range:\", round(min_val, 1), \"-\", round(max_val, 1))\n",
    "                else:\n",
    "                    print(\"    ✓ All values set to default:\", default)\n",
    "            else:\n",
    "                print(\"    ✓ Empty column, set to default:\", default)\n",
    "        except Exception as e:\n",
    "            print(\"    ⚠️ Could not calculate range, but column processed\")\n",
    "    else:\n",
    "        df[col] = default\n",
    "        print(\"  + Created\", col, \"=\", default)\n",
    "\n",
    "# 8. Handle Take-ons\n",
    "if 'Take-Ons Att' in df.columns and 'Take-Ons Succ' in df.columns:\n",
    "    df['Take-Ons Att'] = safe_numeric_conversion(df['Take-Ons Att'], 0)\n",
    "    df['Take-Ons Succ'] = safe_numeric_conversion(df['Take-Ons Succ'], 0)\n",
    "    df['Take-Ons Succ%'] = np.where(df['Take-Ons Att'] > 0, \n",
    "                                   (df['Take-Ons Succ'] / df['Take-Ons Att'] * 100), 0)\n",
    "    print(\"✓ Take-on statistics calculated\")\n",
    "else:\n",
    "    df['Take-Ons Succ%'] = 0\n",
    "    print(\"✓ Take-on columns not found, set to 0\")\n",
    "\n",
    "print(\"✓ Data preprocessing completed\")\n",
    "\n",
    "# ==========================================\n",
    "# PHASE 2: PERFORMANCE SCORING\n",
    "# ==========================================\n",
    "\n",
    "print(\"\\n⚽ PHASE 2: CALCULATING PERFORMANCE SCORES\")\n",
    "\n",
    "df['Performance_Score'] = 0.0\n",
    "\n",
    "# Helper function for per-90 calculations\n",
    "def per_90(stat, minutes):\n",
    "    return np.where(minutes > 0, stat / minutes * 90, 0)\n",
    "\n",
    "# Safe function to get numeric min/max\n",
    "def safe_min_max(series):\n",
    "    try:\n",
    "        numeric_series = pd.to_numeric(series, errors='coerce')\n",
    "        if not numeric_series.isnull().all():\n",
    "            return numeric_series.min(), numeric_series.max()\n",
    "        else:\n",
    "            return 0.0, 0.0\n",
    "    except:\n",
    "        return 0.0, 0.0\n",
    "\n",
    "# GOALKEEPERS\n",
    "gk_mask = df['Position_Group'] == 'Goalkeeper'\n",
    "if gk_mask.sum() > 0:\n",
    "    print(\"\\nGoalkeepers:\", gk_mask.sum(), \"records\")\n",
    "    gk_score = df.loc[gk_mask, 'Total Cmp%'] * 0.6 + df.loc[gk_mask, 'Long Cmp%'] * 0.4\n",
    "    df.loc[gk_mask, 'Performance_Score'] = gk_score\n",
    "    min_score, max_score = safe_min_max(gk_score)\n",
    "    print(\"  ✓ Score range:\", round(min_score, 1), \"-\", round(max_score, 1))\n",
    "\n",
    "# FORWARDS\n",
    "fw_mask = df['Position_Group'] == 'Forward'\n",
    "if fw_mask.sum() > 0:\n",
    "    print(\"\\nForwards:\", fw_mask.sum(), \"records\")\n",
    "    \n",
    "    # Create clean copy with reset index to avoid duplicate index issues\n",
    "    fw_data = df[fw_mask].copy().reset_index(drop=True)\n",
    "    \n",
    "    # Calculate per-90 stats using numpy arrays to avoid pandas alignment issues\n",
    "    min_values = fw_data['Min'].values\n",
    "    gls_values = fw_data['Gls'].values\n",
    "    ast_values = fw_data['Ast'].values\n",
    "    sh_values = fw_data['Sh'].values\n",
    "    sot_values = fw_data['SoT'].values\n",
    "    xg_values = fw_data['Expected xG'].values\n",
    "    takeon_values = fw_data['Take-Ons Succ%'].values\n",
    "    \n",
    "    # Calculate per-90 stats using numpy operations\n",
    "    fw_data['Gls_90'] = np.where(min_values > 0, gls_values / min_values * 90, 0)\n",
    "    fw_data['Ast_90'] = np.where(min_values > 0, ast_values / min_values * 90, 0)\n",
    "    fw_data['Sh_90'] = np.where(min_values > 0, sh_values / min_values * 90, 0)\n",
    "    fw_data['SoT_90'] = np.where(min_values > 0, sot_values / min_values * 90, 0)\n",
    "    fw_data['xG_90'] = np.where(min_values > 0, xg_values / min_values * 90, 0)\n",
    "    \n",
    "    # Get max values for normalization\n",
    "    _, max_g = safe_min_max(fw_data['Gls_90'])\n",
    "    _, max_s = safe_min_max(fw_data['Sh_90'])\n",
    "    _, max_sot = safe_min_max(fw_data['SoT_90'])\n",
    "    _, max_xg = safe_min_max(fw_data['xG_90'])\n",
    "    \n",
    "    max_g = max(max_g, 0.1)\n",
    "    max_s = max(max_s, 0.1)\n",
    "    max_sot = max(max_sot, 0.1)\n",
    "    max_xg = max(max_xg, 0.1)\n",
    "    \n",
    "    # Calculate weighted score\n",
    "    fw_score = (\n",
    "        (fw_data['Gls_90'] / max_g * 100) * 0.35 +      # Goals 35%\n",
    "        (fw_data['Ast_90'] * 25) * 0.20 +               # Assists 20%\n",
    "        (fw_data['Sh_90'] / max_s * 100) * 0.05 +       # Shots 5%\n",
    "        (fw_data['SoT_90'] / max_sot * 100) * 0.15 +    # SoT 15%\n",
    "        (fw_data['xG_90'] / max_xg * 100) * 0.15 +      # xG 15%\n",
    "        takeon_values * 0.10                            # Take-ons 10%\n",
    "    )\n",
    "    \n",
    "    # Update main dataframe using the original indices\n",
    "    original_indices = df[fw_mask].index\n",
    "    df.loc[original_indices, 'Performance_Score'] = fw_score.values\n",
    "    \n",
    "    min_score, max_score = safe_min_max(fw_score)\n",
    "    print(\"  ✓ Score range:\", round(min_score, 1), \"-\", round(max_score, 1))\n",
    "\n",
    "# MIDFIELDERS\n",
    "mid_mask = df['Position_Group'] == 'Midfield'\n",
    "if mid_mask.sum() > 0:\n",
    "    print(\"\\nMidfielders:\", mid_mask.sum(), \"records\")\n",
    "    \n",
    "    # Create clean copy with reset index\n",
    "    mid_data = df[mid_mask].copy().reset_index(drop=True)\n",
    "    \n",
    "    # Calculate per-90 stats using numpy arrays\n",
    "    min_values = mid_data['Min'].values\n",
    "    att_values = mid_data['Total Att'].values\n",
    "    prog_values = mid_data['Passes PrgP'].values\n",
    "    sca_values = mid_data['SCA'].values\n",
    "    kp_values = mid_data['KP'].values\n",
    "    ast_values = mid_data['Ast'].values\n",
    "    cmp_pct_values = mid_data['Total Cmp%'].values\n",
    "    \n",
    "    # Calculate per-90 stats\n",
    "    mid_data['Pass_90'] = np.where(min_values > 0, att_values / min_values * 90, 0)\n",
    "    mid_data['Prog_90'] = np.where(min_values > 0, prog_values / min_values * 90, 0)\n",
    "    mid_data['SCA_90'] = np.where(min_values > 0, sca_values / min_values * 90, 0)\n",
    "    mid_data['KP_90'] = np.where(min_values > 0, kp_values / min_values * 90, 0)\n",
    "    mid_data['Ast_90'] = np.where(min_values > 0, ast_values / min_values * 90, 0)\n",
    "    \n",
    "    # Get max values for normalization\n",
    "    _, max_pass = safe_min_max(mid_data['Pass_90'])\n",
    "    _, max_prog = safe_min_max(mid_data['Prog_90'])\n",
    "    _, max_sca = safe_min_max(mid_data['SCA_90'])\n",
    "    _, max_kp = safe_min_max(mid_data['KP_90'])\n",
    "    \n",
    "    max_pass = max(max_pass, 0.1)\n",
    "    max_prog = max(max_prog, 0.1)\n",
    "    max_sca = max(max_sca, 0.1)\n",
    "    max_kp = max(max_kp, 0.1)\n",
    "    \n",
    "    # Calculate weighted score\n",
    "    mid_score = (\n",
    "        cmp_pct_values * 0.20 +                                 # Pass accuracy 20%\n",
    "        (mid_data['Pass_90'] / max_pass * 100) * 0.15 +         # Pass volume 15%\n",
    "        (mid_data['Prog_90'] / max_prog * 100) * 0.20 +         # Progressive 20%\n",
    "        (mid_data['SCA_90'] / max_sca * 100) * 0.20 +           # Creativity 20%\n",
    "        (mid_data['KP_90'] / max_kp * 100) * 0.15 +             # Key passes 15%\n",
    "        (mid_data['Ast_90'] * 25) * 0.10                        # Assists 10%\n",
    "    )\n",
    "    \n",
    "    # Update main dataframe\n",
    "    original_indices = df[mid_mask].index\n",
    "    df.loc[original_indices, 'Performance_Score'] = mid_score.values\n",
    "    \n",
    "    min_score, max_score = safe_min_max(mid_score)\n",
    "    print(\"  ✓ Score range:\", round(min_score, 1), \"-\", round(max_score, 1))\n",
    "\n",
    "# DEFENDERS\n",
    "def_mask = df['Position_Group'] == 'Defense'\n",
    "if def_mask.sum() > 0:\n",
    "    print(\"\\nDefenders:\", def_mask.sum(), \"records\")\n",
    "    \n",
    "    # Create clean copy with reset index\n",
    "    def_data = df[def_mask].copy().reset_index(drop=True)\n",
    "    \n",
    "    # Calculate per-90 stats using numpy arrays\n",
    "    min_values = def_data['Min'].values\n",
    "    tkl_values = def_data['Tkl'].values\n",
    "    int_values = def_data['Int'].values\n",
    "    blk_values = def_data['Blocks'].values\n",
    "    clr_values = def_data['Clr'].values\n",
    "    cmp_pct_values = def_data['Total Cmp%'].values\n",
    "    \n",
    "    # Calculate per-90 stats\n",
    "    def_data['Tkl_90'] = np.where(min_values > 0, tkl_values / min_values * 90, 0)\n",
    "    def_data['Int_90'] = np.where(min_values > 0, int_values / min_values * 90, 0)\n",
    "    def_data['Blk_90'] = np.where(min_values > 0, blk_values / min_values * 90, 0)\n",
    "    def_data['Clr_90'] = np.where(min_values > 0, clr_values / min_values * 90, 0)\n",
    "    \n",
    "    # Get max values for normalization\n",
    "    _, max_tkl = safe_min_max(def_data['Tkl_90'])\n",
    "    _, max_int = safe_min_max(def_data['Int_90'])\n",
    "    _, max_blk = safe_min_max(def_data['Blk_90'])\n",
    "    _, max_clr = safe_min_max(def_data['Clr_90'])\n",
    "    \n",
    "    max_tkl = max(max_tkl, 0.1)\n",
    "    max_int = max(max_int, 0.1)\n",
    "    max_blk = max(max_blk, 0.1)\n",
    "    max_clr = max(max_clr, 0.1)\n",
    "    \n",
    "    # Calculate weighted score\n",
    "    def_score = (\n",
    "        (def_data['Tkl_90'] / max_tkl * 100) * 0.25 +           # Tackles 25%\n",
    "        (def_data['Int_90'] / max_int * 100) * 0.25 +           # Interceptions 25%\n",
    "        (def_data['Blk_90'] / max_blk * 100) * 0.20 +           # Blocks 20%\n",
    "        (def_data['Clr_90'] / max_clr * 100) * 0.15 +           # Clearances 15%\n",
    "        cmp_pct_values * 0.15                                   # Pass accuracy 15%\n",
    "    )\n",
    "    \n",
    "    # Update main dataframe\n",
    "    original_indices = df[def_mask].index\n",
    "    df.loc[original_indices, 'Performance_Score'] = def_score.values\n",
    "    \n",
    "    min_score, max_score = safe_min_max(def_score)\n",
    "    print(\"  ✓ Score range:\", round(min_score, 1), \"-\", round(max_score, 1))\n",
    "\n",
    "# Cap all scores at 100\n",
    "df['Performance_Score'] = df['Performance_Score'].clip(0, 100)\n",
    "\n",
    "print(\"\\n✅ SCORING COMPLETED\")\n",
    "overall_min = float(df['Performance_Score'].min())\n",
    "overall_max = float(df['Performance_Score'].max())\n",
    "print(\"Overall range:\", round(overall_min, 1), \"-\", round(overall_max, 1))\n",
    "\n",
    "# ==========================================\n",
    "# PHASE 3: ANALYSIS & RESULTS\n",
    "# ==========================================\n",
    "\n",
    "print(\"\\n📊 PHASE 3: ANALYSIS & RESULTS\")\n",
    "\n",
    "# Check Antonio Rüdiger specifically\n",
    "print(\"\\n=== VALIDATION CHECK ===\")\n",
    "rudiger = df[df['Player'].str.contains('Rüdiger', na=False, case=False)]\n",
    "if len(rudiger) > 0:\n",
    "    rudiger_avg = rudiger['Performance_Score'].mean()\n",
    "    print(\"✓ Rüdiger average score:\", round(rudiger_avg, 1), \"(should not be 50.0)\")\n",
    "    rudiger_best = rudiger.nlargest(3, 'Performance_Score')[\n",
    "        ['Date', 'Performance_Score', 'Min', 'Tkl', 'Int', 'Blocks', 'Total Cmp%']\n",
    "    ]\n",
    "    print(\"✓ Rüdiger's top performances:\")\n",
    "    print(rudiger_best.to_string(index=False))\n",
    "\n",
    "# Top performances\n",
    "print(\"\\n=== TOP 15 INDIVIDUAL PERFORMANCES ===\")\n",
    "top_individual = df.nlargest(15, 'Performance_Score')[\n",
    "    ['Date', 'Player', 'Position_Group', 'Performance_Score', 'Min', 'Gls', 'Ast', 'Opponent']\n",
    "]\n",
    "print(top_individual.to_string(index=False))\n",
    "\n",
    "# Player averages\n",
    "print(\"\\n=== BEST SEASON AVERAGES (500+ minutes) ===\")\n",
    "player_avg = df.groupby(['Player', 'Position_Group', 'Season']).agg({\n",
    "    'Performance_Score': 'mean',\n",
    "    'Min': 'sum',\n",
    "    'Gls': 'sum',\n",
    "    'Ast': 'sum',\n",
    "    'Age': 'first',\n",
    "    'Nation': 'first'\n",
    "}).round(2).reset_index()\n",
    "\n",
    "significant_players = player_avg[player_avg['Min'] >= 500]\n",
    "top_averages = significant_players.nlargest(15, 'Performance_Score')\n",
    "print(top_averages.to_string(index=False))\n",
    "\n",
    "# ==========================================\n",
    "# PHASE 4: SAVE RESULTS\n",
    "# ==========================================\n",
    "\n",
    "print(\"\\n💾 PHASE 4: SAVING RESULTS\")\n",
    "\n",
    "output_dir = '/Users/mariamoramora/Documents/GitHub/ADS599_Capstone/Soccer_Performance_Score/data/real_madrid_combined'\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Save complete cleaned dataset\n",
    "final_path = output_dir + '/real_madrid_cleaned_with_scores.csv'\n",
    "df.to_csv(final_path, index=False)\n",
    "\n",
    "# Save player averages\n",
    "averages_path = output_dir + '/player_season_averages_clean.csv'\n",
    "player_avg.to_csv(averages_path, index=False)\n",
    "\n",
    "print(\"✅ SAVED:\")\n",
    "print(\"📊 Complete cleaned data:\", final_path)\n",
    "print(\"🏆 Player averages:\", averages_path)\n",
    "\n",
    "print(\"\\n🎯 FINAL SUMMARY:\")\n",
    "print(\"• Processed\", len(df), \"match records\")\n",
    "print(\"• Unique players:\", df['Player'].nunique())\n",
    "print(\"• Age range:\", df['Age'].min(), \"-\", df['Age'].max(), \"years\")\n",
    "print(\"• Nations:\", df['Nation'].nunique(), \"different countries\")\n",
    "print(\"• Players with 500+ minutes:\", len(significant_players))\n",
    "best_performer = df.loc[df['Performance_Score'].idxmax(), 'Player']\n",
    "best_score = float(df['Performance_Score'].max())\n",
    "print(\"• Best performer:\", best_performer, \"(\" + str(round(best_score, 1)) + \")\")\n",
    "\n",
    "print(\"\\n🏆 REAL MADRID ANALYSIS COMPLETE! 🏆\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
