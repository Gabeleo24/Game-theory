{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "import pandas as pd\n",
    "from datetime import datetime, timedelta\n",
    "import time\n",
    "import os\n",
    "import re\n",
    "from typing import Dict, List, Optional\n",
    "\n",
    "class RealMadridPerformanceAPI:\n",
    "    \"\"\"\n",
    "    Specialized API client for Real Madrid team and player performance data\n",
    "    Focus: Match results, player stats, team performance, injuries, ratings\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, api_key: str):\n",
    "        self.api_key = api_key\n",
    "        self.base_url = \"https://content.guardianapis.com\"\n",
    "        self.rate_limit_delay = 0.2  # 200ms between requests for safety\n",
    "        \n",
    "        # Real Madrid players (current squad 2024-25)\n",
    "        self.current_squad = [\n",
    "            # Goalkeepers\n",
    "            \"Courtois\", \"Lunin\", \"Fran Gonz√°lez\",\n",
    "            # Defenders  \n",
    "            \"Carvajal\", \"Milit√£o\", \"Alaba\", \"Nacho\", \"Mendy\", \"R√ºdiger\", \"Vallejo\", \"Fran Garc√≠a\",\n",
    "            # Midfielders\n",
    "            \"Modriƒá\", \"Kroos\", \"Valverde\", \"Camavinga\", \"Tchouam√©ni\", \"Bellingham\", \"Ceballos\", \"Arda G√ºler\",\n",
    "            # Forwards\n",
    "            \"Vin√≠cius\", \"Benzema\", \"Rodrygo\", \"Asensio\", \"Mariano\", \"Joselu\", \"Brahim\", \"Mbapp√©\"\n",
    "        ]\n",
    "        \n",
    "    def get_match_performance(self, days_back: int = 30, max_articles_per_query: int = 50) -> List[Dict]:\n",
    "        \"\"\"\n",
    "        Get Real Madrid match performance and results with pagination\n",
    "        \"\"\"\n",
    "        \n",
    "        from_date = (datetime.now() - timedelta(days=days_back)).strftime('%Y-%m-%d')\n",
    "        \n",
    "        # Specific search for match reports and performance\n",
    "        match_queries = [\n",
    "            'Real Madrid AND (match report OR player ratings OR performance)',\n",
    "            'Real Madrid AND (goals OR assists OR \"man of the match\")',\n",
    "            'Real Madrid AND (La Liga OR Champions League OR Copa del Rey)',\n",
    "            'Real Madrid AND (result OR score OR \"Real Madrid\" AND won)',\n",
    "            'Real Madrid AND (Bernab√©u OR Santiago Bernab√©u OR home OR away)'\n",
    "        ]\n",
    "        \n",
    "        all_articles = []\n",
    "        total_requests = 0\n",
    "        \n",
    "        for query_idx, query in enumerate(match_queries, 1):\n",
    "            print(f\"üîç Query {query_idx}/{len(match_queries)}: {query[:50]}...\")\n",
    "            \n",
    "            # Paginate through results for this query\n",
    "            query_articles = []\n",
    "            page = 1\n",
    "            page_size = 10  # Smaller page size to control API usage\n",
    "            \n",
    "            while len(query_articles) < max_articles_per_query:\n",
    "                params = {\n",
    "                    'api-key': self.api_key,\n",
    "                    'q': query,\n",
    "                    'section': 'football',\n",
    "                    'from-date': from_date,\n",
    "                    'page-size': page_size,\n",
    "                    'page': page,\n",
    "                    'show-fields': 'headline,byline,body,thumbnail,publication',\n",
    "                    'show-tags': 'sport',\n",
    "                    'order-by': 'newest'\n",
    "                }\n",
    "                \n",
    "                try:\n",
    "                    print(f\"   üìÑ Page {page} (Request #{total_requests + 1})\")\n",
    "                    response = requests.get(f\"{self.base_url}/search\", params=params)\n",
    "                    response.raise_for_status()\n",
    "                    total_requests += 1\n",
    "                    \n",
    "                    data = response.json()\n",
    "                    page_articles = data['response']['results']\n",
    "                    \n",
    "                    if not page_articles:\n",
    "                        print(f\"   ‚úÖ No more articles on page {page}\")\n",
    "                        break\n",
    "                    \n",
    "                    # Filter for Real Madrid specific content\n",
    "                    filtered_articles = self._filter_real_madrid_content(page_articles)\n",
    "                    query_articles.extend(filtered_articles)\n",
    "                    \n",
    "                    print(f\"   üì∞ Found {len(filtered_articles)} relevant articles\")\n",
    "                    \n",
    "                    # Rate limiting - respect API limits\n",
    "                    time.sleep(self.rate_limit_delay)\n",
    "                    \n",
    "                    # Check if we have enough articles or hit API limits\n",
    "                    if len(query_articles) >= max_articles_per_query:\n",
    "                        break\n",
    "                    if total_requests >= 30:  # Conservative limit per method\n",
    "                        print(f\"   ‚ö†Ô∏è  Reached request limit for this query\")\n",
    "                        break\n",
    "                        \n",
    "                    page += 1\n",
    "                    \n",
    "                except Exception as e:\n",
    "                    print(f\"   ‚ùå Error on page {page}: {e}\")\n",
    "                    break\n",
    "            \n",
    "            all_articles.extend(query_articles[:max_articles_per_query])\n",
    "            print(f\"   üéØ Collected {len(query_articles)} articles for this query\")\n",
    "            \n",
    "            # Stop if we're approaching API limits\n",
    "            if total_requests >= 100:  # Daily limit protection\n",
    "                print(f\"‚ö†Ô∏è  Approaching API limits, stopping early\")\n",
    "                break\n",
    "        \n",
    "        # Remove duplicates by URL\n",
    "        unique_articles = {article['webUrl']: article for article in all_articles}\n",
    "        \n",
    "        print(f\"‚öΩ Total: {len(unique_articles)} unique match performance articles\")\n",
    "        print(f\"üìä API requests used: {total_requests}\")\n",
    "        return list(unique_articles.values())\n",
    "    \n",
    "    def get_player_performance(self, player_name: str = None, days_back: int = 60, max_articles_per_query: int = 30) -> List[Dict]:\n",
    "        \"\"\"\n",
    "        Get individual player performance data with pagination\n",
    "        \"\"\"\n",
    "        \n",
    "        from_date = (datetime.now() - timedelta(days=days_back)).strftime('%Y-%m-%d')\n",
    "        \n",
    "        if player_name:\n",
    "            # Search for specific player\n",
    "            player_queries = [\n",
    "                f'Real Madrid AND \"{player_name}\" AND (performance OR goal OR assist)',\n",
    "                f'Real Madrid AND \"{player_name}\" AND (rating OR stats OR minutes)',\n",
    "                f'\"{player_name}\" AND Real Madrid AND (injury OR fitness OR return)'\n",
    "            ]\n",
    "        else:\n",
    "            # Search for key players performance\n",
    "            player_queries = [\n",
    "                'Real Madrid AND (Vin√≠cius OR Bellingham OR Modriƒá OR Mbapp√©) AND performance',\n",
    "                'Real Madrid AND (Courtois OR Milit√£o OR Carvajal OR R√ºdiger) AND performance', \n",
    "                'Real Madrid AND (Valverde OR Camavinga OR Tchouam√©ni) AND performance'\n",
    "            ]\n",
    "        \n",
    "        all_articles = []\n",
    "        total_requests = 0\n",
    "        \n",
    "        for query_idx, query in enumerate(player_queries, 1):\n",
    "            print(f\"üë§ Player Query {query_idx}/{len(player_queries)}: {query[:50]}...\")\n",
    "            \n",
    "            # Paginate through results\n",
    "            query_articles = []\n",
    "            page = 1\n",
    "            page_size = 8  # Smaller page size for player searches\n",
    "            \n",
    "            while len(query_articles) < max_articles_per_query:\n",
    "                params = {\n",
    "                    'api-key': self.api_key,\n",
    "                    'q': query,\n",
    "                    'section': 'football',\n",
    "                    'from-date': from_date,\n",
    "                    'page-size': page_size,\n",
    "                    'page': page,\n",
    "                    'show-fields': 'headline,byline,body,thumbnail,publication',\n",
    "                    'order-by': 'newest'\n",
    "                }\n",
    "                \n",
    "                try:\n",
    "                    print(f\"   üìÑ Page {page} (Request #{total_requests + 1})\")\n",
    "                    response = requests.get(f\"{self.base_url}/search\", params=params)\n",
    "                    response.raise_for_status()\n",
    "                    total_requests += 1\n",
    "                    \n",
    "                    data = response.json()\n",
    "                    page_articles = data['response']['results']\n",
    "                    \n",
    "                    if not page_articles:\n",
    "                        print(f\"   ‚úÖ No more articles on page {page}\")\n",
    "                        break\n",
    "                    \n",
    "                    filtered_articles = self._filter_real_madrid_content(page_articles)\n",
    "                    query_articles.extend(filtered_articles)\n",
    "                    \n",
    "                    print(f\"   üåü Found {len(filtered_articles)} relevant player articles\")\n",
    "                    \n",
    "                    time.sleep(self.rate_limit_delay)\n",
    "                    \n",
    "                    if len(query_articles) >= max_articles_per_query:\n",
    "                        break\n",
    "                    if total_requests >= 20:  # Conservative limit for player searches\n",
    "                        print(f\"   ‚ö†Ô∏è  Reached request limit for this query\")\n",
    "                        break\n",
    "                        \n",
    "                    page += 1\n",
    "                    \n",
    "                except Exception as e:\n",
    "                    print(f\"   ‚ùå Error on page {page}: {e}\")\n",
    "                    break\n",
    "            \n",
    "            all_articles.extend(query_articles[:max_articles_per_query])\n",
    "            print(f\"   üéØ Collected {len(query_articles)} player articles\")\n",
    "            \n",
    "            if total_requests >= 50:\n",
    "                print(f\"‚ö†Ô∏è  Approaching API limits, stopping player search\")\n",
    "                break\n",
    "        \n",
    "        # Remove duplicates\n",
    "        unique_articles = {article['webUrl']: article for article in all_articles}\n",
    "        \n",
    "        print(f\"üåü Total: {len(unique_articles)} unique player performance articles\")\n",
    "        print(f\"üìä API requests used: {total_requests}\")\n",
    "        return list(unique_articles.values())\n",
    "    \n",
    "    def get_team_statistics(self, days_back: int = 90, max_articles_per_query: int = 20) -> List[Dict]:\n",
    "        \"\"\"\n",
    "        Get Real Madrid team statistics and analysis with pagination\n",
    "        \"\"\"\n",
    "        \n",
    "        from_date = (datetime.now() - timedelta(days=days_back)).strftime('%Y-%m-%d')\n",
    "        \n",
    "        stats_queries = [\n",
    "            'Real Madrid AND (statistics OR stats OR analysis OR tactics)',\n",
    "            'Real Madrid AND (formation OR strategy OR \"playing style\")',\n",
    "            'Real Madrid AND (league table OR standings OR position OR points)'\n",
    "        ]\n",
    "        \n",
    "        all_articles = []\n",
    "        total_requests = 0\n",
    "        \n",
    "        for query_idx, query in enumerate(stats_queries, 1):\n",
    "            print(f\"üìä Stats Query {query_idx}/{len(stats_queries)}: {query[:50]}...\")\n",
    "            \n",
    "            query_articles = []\n",
    "            page = 1\n",
    "            page_size = 6  # Small page size for statistics\n",
    "            \n",
    "            while len(query_articles) < max_articles_per_query:\n",
    "                params = {\n",
    "                    'api-key': self.api_key,\n",
    "                    'q': query,\n",
    "                    'section': 'football',\n",
    "                    'from-date': from_date,\n",
    "                    'page-size': page_size,\n",
    "                    'page': page,\n",
    "                    'show-fields': 'headline,byline,body,thumbnail,publication',\n",
    "                    'order-by': 'relevance'\n",
    "                }\n",
    "                \n",
    "                try:\n",
    "                    print(f\"   üìÑ Page {page} (Request #{total_requests + 1})\")\n",
    "                    response = requests.get(f\"{self.base_url}/search\", params=params)\n",
    "                    response.raise_for_status()\n",
    "                    total_requests += 1\n",
    "                    \n",
    "                    data = response.json()\n",
    "                    page_articles = data['response']['results']\n",
    "                    \n",
    "                    if not page_articles:\n",
    "                        break\n",
    "                    \n",
    "                    filtered_articles = self._filter_real_madrid_content(page_articles)\n",
    "                    query_articles.extend(filtered_articles)\n",
    "                    \n",
    "                    print(f\"   üìà Found {len(filtered_articles)} stats articles\")\n",
    "                    \n",
    "                    time.sleep(self.rate_limit_delay)\n",
    "                    \n",
    "                    if len(query_articles) >= max_articles_per_query:\n",
    "                        break\n",
    "                    if total_requests >= 15:  # Limit for team stats\n",
    "                        break\n",
    "                        \n",
    "                    page += 1\n",
    "                    \n",
    "                except Exception as e:\n",
    "                    print(f\"   ‚ùå Error on page {page}: {e}\")\n",
    "                    break\n",
    "            \n",
    "            all_articles.extend(query_articles[:max_articles_per_query])\n",
    "            \n",
    "            if total_requests >= 30:\n",
    "                break\n",
    "        \n",
    "        unique_articles = {article['webUrl']: article for article in all_articles}\n",
    "        \n",
    "        print(f\"üìà Total: {len(unique_articles)} team statistics articles\")\n",
    "        print(f\"üìä API requests used: {total_requests}\")\n",
    "        return list(unique_articles.values())\n",
    "    \n",
    "    def get_injury_updates(self, days_back: int = 30, max_articles_per_query: int = 15) -> List[Dict]:\n",
    "        \"\"\"\n",
    "        Get player injury and fitness updates with pagination\n",
    "        \"\"\"\n",
    "        \n",
    "        from_date = (datetime.now() - timedelta(days=days_back)).strftime('%Y-%m-%d')\n",
    "        \n",
    "        injury_queries = [\n",
    "            'Real Madrid AND (injury OR injured OR fitness OR \"injury update\")',\n",
    "            'Real Madrid AND (return OR recovered OR \"back to training\")'\n",
    "        ]\n",
    "        \n",
    "        all_articles = []\n",
    "        total_requests = 0\n",
    "        \n",
    "        for query_idx, query in enumerate(injury_queries, 1):\n",
    "            print(f\"üè• Injury Query {query_idx}/{len(injury_queries)}: {query[:50]}...\")\n",
    "            \n",
    "            query_articles = []\n",
    "            page = 1\n",
    "            page_size = 5  # Small page size for injury news\n",
    "            \n",
    "            while len(query_articles) < max_articles_per_query:\n",
    "                params = {\n",
    "                    'api-key': self.api_key,\n",
    "                    'q': query,\n",
    "                    'section': 'football',\n",
    "                    'from-date': from_date,\n",
    "                    'page-size': page_size,\n",
    "                    'page': page,\n",
    "                    'show-fields': 'headline,byline,body,thumbnail,publication',\n",
    "                    'order-by': 'newest'\n",
    "                }\n",
    "                \n",
    "                try:\n",
    "                    print(f\"   üìÑ Page {page} (Request #{total_requests + 1})\")\n",
    "                    response = requests.get(f\"{self.base_url}/search\", params=params)\n",
    "                    response.raise_for_status()\n",
    "                    total_requests += 1\n",
    "                    \n",
    "                    data = response.json()\n",
    "                    page_articles = data['response']['results']\n",
    "                    \n",
    "                    if not page_articles:\n",
    "                        break\n",
    "                    \n",
    "                    filtered_articles = self._filter_real_madrid_content(page_articles)\n",
    "                    query_articles.extend(filtered_articles)\n",
    "                    \n",
    "                    print(f\"   ü©π Found {len(filtered_articles)} injury articles\")\n",
    "                    \n",
    "                    time.sleep(self.rate_limit_delay)\n",
    "                    \n",
    "                    if len(query_articles) >= max_articles_per_query:\n",
    "                        break\n",
    "                    if total_requests >= 10:  # Conservative limit for injury news\n",
    "                        break\n",
    "                        \n",
    "                    page += 1\n",
    "                    \n",
    "                except Exception as e:\n",
    "                    print(f\"   ‚ùå Error on page {page}: {e}\")\n",
    "                    break\n",
    "            \n",
    "            all_articles.extend(query_articles[:max_articles_per_query])\n",
    "            \n",
    "            if total_requests >= 15:\n",
    "                break\n",
    "        \n",
    "        unique_articles = {article['webUrl']: article for article in all_articles}\n",
    "        \n",
    "        print(f\"ü©π Total: {len(unique_articles)} injury update articles\")\n",
    "        print(f\"üìä API requests used: {total_requests}\")\n",
    "        return list(unique_articles.values())\n",
    "    \n",
    "    def _filter_real_madrid_content(self, articles: List[Dict]) -> List[Dict]:\n",
    "        \"\"\"\n",
    "        Filter articles to ensure they're actually about Real Madrid\n",
    "        \"\"\"\n",
    "        \n",
    "        filtered = []\n",
    "        real_madrid_keywords = [\n",
    "            'real madrid', 'bernab√©u', 'santiago bernabeu', 'los blancos', \n",
    "            'madrid cf', 'real madrid cf', 'gal√°cticos'\n",
    "        ]\n",
    "        \n",
    "        for article in articles:\n",
    "            title = article.get('webTitle', '').lower()\n",
    "            body = article.get('fields', {}).get('body', '').lower()\n",
    "            \n",
    "            # Check if it's actually about Real Madrid (not other Madrid teams)\n",
    "            if any(keyword in title or keyword in body[:500] for keyword in real_madrid_keywords):\n",
    "                # Exclude other Madrid teams\n",
    "                if not any(exclude in title.lower() for exclude in ['atl√©tico', 'atletico', 'getafe', 'rayo']):\n",
    "                    filtered.append(article)\n",
    "        \n",
    "        return filtered\n",
    "    \n",
    "    def extract_performance_data(self, articles: List[Dict]) -> pd.DataFrame:\n",
    "        \"\"\"\n",
    "        Extract structured performance data from articles\n",
    "        \"\"\"\n",
    "        \n",
    "        performance_data = []\n",
    "        \n",
    "        for article in articles:\n",
    "            fields = article.get('fields', {})\n",
    "            title = fields.get('headline', article.get('webTitle', ''))\n",
    "            body = fields.get('body', '')\n",
    "            \n",
    "            # Extract performance metrics from text\n",
    "            performance_info = {\n",
    "                'id': article.get('id'),\n",
    "                'title': title,\n",
    "                'url': article.get('webUrl'),\n",
    "                'date': article.get('webPublicationDate')[:10],\n",
    "                'author': fields.get('byline', 'Unknown'),\n",
    "                \n",
    "                # Performance indicators\n",
    "                'contains_player_ratings': 'rating' in body.lower() or 'out of 10' in body.lower(),\n",
    "                'contains_stats': any(word in body.lower() for word in ['goals', 'assists', 'passes', 'shots']),\n",
    "                'contains_match_result': any(word in title.lower() for word in ['win', 'lose', 'draw', 'defeat', 'victory']),\n",
    "                'contains_injury_news': any(word in body.lower() for word in ['injury', 'injured', 'fitness', 'doubt']),\n",
    "                \n",
    "                # Extract mentioned players\n",
    "                'mentioned_players': [player for player in self.current_squad \n",
    "                                   if player.lower() in body.lower()],\n",
    "                \n",
    "                # Competition detection\n",
    "                'competition': self._detect_competition(title + ' ' + body),\n",
    "                \n",
    "                # Performance type\n",
    "                'content_type': self._classify_content_type(title, body)\n",
    "            }\n",
    "            \n",
    "            performance_data.append(performance_info)\n",
    "        \n",
    "        return pd.DataFrame(performance_data)\n",
    "    \n",
    "    def _detect_competition(self, text: str) -> str:\n",
    "        \"\"\"Detect which competition the article is about\"\"\"\n",
    "        \n",
    "        text_lower = text.lower()\n",
    "        \n",
    "        if any(comp in text_lower for comp in ['champions league', 'ucl', 'european cup']):\n",
    "            return 'Champions League'\n",
    "        elif any(comp in text_lower for comp in ['la liga', 'league', 'primera divisi√≥n']):\n",
    "            return 'La Liga'\n",
    "        elif any(comp in text_lower for comp in ['copa del rey', 'cup']):\n",
    "            return 'Copa del Rey'\n",
    "        elif any(comp in text_lower for comp in ['super cup', 'supercopa']):\n",
    "            return 'Super Cup'\n",
    "        elif any(comp in text_lower for comp in ['club world cup', 'fifa']):\n",
    "            return 'Club World Cup'\n",
    "        else:\n",
    "            return 'General'\n",
    "    \n",
    "    def _classify_content_type(self, title: str, body: str) -> str:\n",
    "        \"\"\"Classify the type of performance content\"\"\"\n",
    "        \n",
    "        text = (title + ' ' + body).lower()\n",
    "        \n",
    "        if any(word in text for word in ['match report', 'player ratings', 'performance']):\n",
    "            return 'Match Analysis'\n",
    "        elif any(word in text for word in ['injury', 'fitness', 'return', 'doubt']):\n",
    "            return 'Injury News'\n",
    "        elif any(word in text for word in ['statistics', 'stats', 'analysis']):\n",
    "            return 'Statistics'\n",
    "        elif any(word in text for word in ['goal', 'assist', 'scored']):\n",
    "            return 'Goal/Assist News'\n",
    "        elif any(word in text for word in ['tactics', 'formation', 'strategy']):\n",
    "            return 'Tactical Analysis'\n",
    "        else:\n",
    "            return 'General Performance'\n",
    "    \n",
    "    def generate_performance_report(self, days_back: int = 14) -> Dict:\n",
    "        \"\"\"\n",
    "        Generate a comprehensive performance report with API usage tracking\n",
    "        \"\"\"\n",
    "        \n",
    "        print(f\"üìã Generating Real Madrid Performance Report ({days_back} days)\")\n",
    "        print(\"=\" * 60)\n",
    "        \n",
    "        # Check if we can proceed with the analysis\n",
    "        if not usage_tracker.check_limits():\n",
    "            print(\"‚ùå Cannot proceed - API limits reached\")\n",
    "            return {}\n",
    "        \n",
    "        # Collect performance data with controlled pagination\n",
    "        print(\"\\nüîÑ Collecting performance data...\")\n",
    "        \n",
    "        # Get match performance (limited to prevent API overuse)\n",
    "        matches = self.get_match_performance(days_back, max_articles_per_query=30)\n",
    "        usage_tracker.print_usage()\n",
    "        \n",
    "        if not usage_tracker.check_limits():\n",
    "            print(\"‚ö†Ô∏è  Stopping early due to API limits\")\n",
    "            return self._create_partial_report(matches, [], [], [], days_back)\n",
    "        \n",
    "        # Get player performance\n",
    "        players = self.get_player_performance(days_back=days_back, max_articles_per_query=20)\n",
    "        usage_tracker.print_usage()\n",
    "        \n",
    "        if not usage_tracker.check_limits():\n",
    "            return self._create_partial_report(matches, players, [], [], days_back)\n",
    "        \n",
    "        # Get team statistics\n",
    "        team_stats = self.get_team_statistics(days_back, max_articles_per_query=15)\n",
    "        usage_tracker.print_usage()\n",
    "        \n",
    "        if not usage_tracker.check_limits():\n",
    "            return self._create_partial_report(matches, players, team_stats, [], days_back)\n",
    "        \n",
    "        # Get injury updates\n",
    "        injuries = self.get_injury_updates(days_back, max_articles_per_query=10)\n",
    "        usage_tracker.print_usage()\n",
    "        \n",
    "        # Combine all articles\n",
    "        all_articles = matches + players + team_stats + injuries\n",
    "        \n",
    "        # Remove duplicates\n",
    "        unique_articles = {article['webUrl']: article for article in all_articles}\n",
    "        final_articles = list(unique_articles.values())\n",
    "        \n",
    "        # Extract structured data\n",
    "        df = self.extract_performance_data(final_articles)\n",
    "        \n",
    "        # Generate report\n",
    "        report = {\n",
    "            'report_date': datetime.now().strftime('%Y-%m-%d %H:%M:%S'),\n",
    "            'period_days': days_back,\n",
    "            'total_articles': len(df),\n",
    "            'api_usage': usage_tracker.get_usage_report(),\n",
    "            \n",
    "            # Content breakdown\n",
    "            'content_types': df['content_type'].value_counts().to_dict() if len(df) > 0 else {},\n",
    "            'competitions': df['competition'].value_counts().to_dict() if len(df) > 0 else {},\n",
    "            \n",
    "            # Player mentions\n",
    "            'most_mentioned_players': self._get_top_mentioned_players(df) if len(df) > 0 else {},\n",
    "            \n",
    "            # Performance indicators\n",
    "            'articles_with_ratings': df['contains_player_ratings'].sum() if len(df) > 0 else 0,\n",
    "            'articles_with_stats': df['contains_stats'].sum() if len(df) > 0 else 0,\n",
    "            'articles_with_results': df['contains_match_result'].sum() if len(df) > 0 else 0,\n",
    "            'injury_articles': df['contains_injury_news'].sum() if len(df) > 0 else 0,\n",
    "            \n",
    "            # Recent highlights\n",
    "            'latest_match_reports': df[df['content_type'] == 'Match Analysis'].head(3).to_dict('records') if len(df) > 0 else [],\n",
    "            'latest_injury_news': df[df['content_type'] == 'Injury News'].head(3).to_dict('records') if len(df) > 0 else [],\n",
    "            'latest_performance_news': df.head(5).to_dict('records') if len(df) > 0 else [],\n",
    "            \n",
    "            # Full dataset\n",
    "            'all_articles': df.to_dict('records') if len(df) > 0 else []\n",
    "        }\n",
    "        \n",
    "        return report\n",
    "    \n",
    "    def _create_partial_report(self, matches: List, players: List, team_stats: List, injuries: List, days_back: int) -> Dict:\n",
    "        \"\"\"Create a partial report when API limits are reached\"\"\"\n",
    "        \n",
    "        all_articles = matches + players + team_stats + injuries\n",
    "        unique_articles = {article['webUrl']: article for article in all_articles}\n",
    "        final_articles = list(unique_articles.values())\n",
    "        \n",
    "        df = self.extract_performance_data(final_articles)\n",
    "        \n",
    "        return {\n",
    "            'report_date': datetime.now().strftime('%Y-%m-%d %H:%M:%S'),\n",
    "            'period_days': days_back,\n",
    "            'total_articles': len(df),\n",
    "            'api_usage': usage_tracker.get_usage_report(),\n",
    "            'status': 'PARTIAL - API limits reached',\n",
    "            'content_types': df['content_type'].value_counts().to_dict() if len(df) > 0 else {},\n",
    "            'all_articles': df.to_dict('records') if len(df) > 0 else []\n",
    "        }\n",
    "        all_articles = matches + players + team_stats + injuries\n",
    "        \n",
    "        # Remove duplicates\n",
    "        unique_articles = {article['webUrl']: article for article in all_articles}\n",
    "        final_articles = list(unique_articles.values())\n",
    "        \n",
    "        # Extract structured data\n",
    "        df = self.extract_performance_data(final_articles)\n",
    "        \n",
    "        # Generate report\n",
    "        report = {\n",
    "            'report_date': datetime.now().strftime('%Y-%m-%d %H:%M:%S'),\n",
    "            'period_days': days_back,\n",
    "            'total_articles': len(df),\n",
    "            \n",
    "            # Content breakdown\n",
    "            'content_types': df['content_type'].value_counts().to_dict(),\n",
    "            'competitions': df['competition'].value_counts().to_dict(),\n",
    "            \n",
    "            # Player mentions\n",
    "            'most_mentioned_players': self._get_top_mentioned_players(df),\n",
    "            \n",
    "            # Performance indicators\n",
    "            'articles_with_ratings': df['contains_player_ratings'].sum(),\n",
    "            'articles_with_stats': df['contains_stats'].sum(),\n",
    "            'articles_with_results': df['contains_match_result'].sum(),\n",
    "            'injury_articles': df['contains_injury_news'].sum(),\n",
    "            \n",
    "            # Recent highlights\n",
    "            'latest_match_reports': df[df['content_type'] == 'Match Analysis'].head(3).to_dict('records'),\n",
    "            'latest_injury_news': df[df['content_type'] == 'Injury News'].head(3).to_dict('records'),\n",
    "            'latest_performance_news': df.head(5).to_dict('records'),\n",
    "            \n",
    "            # Full dataset\n",
    "            'all_articles': df.to_dict('records')\n",
    "        }\n",
    "        \n",
    "        return report\n",
    "    \n",
    "    def _get_top_mentioned_players(self, df: pd.DataFrame) -> Dict:\n",
    "        \"\"\"Get most frequently mentioned players\"\"\"\n",
    "        \n",
    "        player_mentions = {}\n",
    "        \n",
    "        for _, row in df.iterrows():\n",
    "            for player in row['mentioned_players']:\n",
    "                player_mentions[player] = player_mentions.get(player, 0) + 1\n",
    "        \n",
    "        # Sort by mentions\n",
    "        sorted_players = sorted(player_mentions.items(), key=lambda x: x[1], reverse=True)\n",
    "        \n",
    "        return dict(sorted_players[:10])  # Top 10 most mentioned\n",
    "    \n",
    "    def save_performance_report(self, report: Dict, filename: str = None):\n",
    "        \"\"\"Save performance report to files\"\"\"\n",
    "        \n",
    "        if filename is None:\n",
    "            timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "            filename = f'real_madrid_performance_{timestamp}'\n",
    "        \n",
    "        # Save full report as JSON\n",
    "        with open(f'{filename}.json', 'w', encoding='utf-8') as f:\n",
    "            json.dump(report, f, indent=2, ensure_ascii=False)\n",
    "        \n",
    "        # Save articles as CSV\n",
    "        df = pd.DataFrame(report['all_articles'])\n",
    "        df.to_csv(f'{filename}.csv', index=False, encoding='utf-8')\n",
    "        \n",
    "        # Save summary as text\n",
    "        with open(f'{filename}_summary.txt', 'w', encoding='utf-8') as f:\n",
    "            f.write(f\"REAL MADRID PERFORMANCE REPORT\\n\")\n",
    "            f.write(f\"Generated: {report['report_date']}\\n\")\n",
    "            f.write(f\"Period: Last {report['period_days']} days\\n\")\n",
    "            f.write(f\"Total Articles: {report['total_articles']}\\n\\n\")\n",
    "            \n",
    "            f.write(\"CONTENT BREAKDOWN:\\n\")\n",
    "            for content_type, count in report['content_types'].items():\n",
    "                f.write(f\"  ‚Ä¢ {content_type}: {count}\\n\")\n",
    "            \n",
    "            f.write(f\"\\nCOMPETITIONS:\\n\")\n",
    "            for comp, count in report['competitions'].items():\n",
    "                f.write(f\"  ‚Ä¢ {comp}: {count}\\n\")\n",
    "            \n",
    "            f.write(f\"\\nTOP MENTIONED PLAYERS:\\n\")\n",
    "            for player, mentions in report['most_mentioned_players'].items():\n",
    "                f.write(f\"  ‚Ä¢ {player}: {mentions} mentions\\n\")\n",
    "            \n",
    "            f.write(f\"\\nPERFORMANCE INDICATORS:\\n\")\n",
    "            f.write(f\"  ‚Ä¢ Articles with player ratings: {report['articles_with_ratings']}\\n\")\n",
    "            f.write(f\"  ‚Ä¢ Articles with statistics: {report['articles_with_stats']}\\n\")\n",
    "            f.write(f\"  ‚Ä¢ Articles with match results: {report['articles_with_results']}\\n\")\n",
    "            f.write(f\"  ‚Ä¢ Injury-related articles: {report['injury_articles']}\\n\")\n",
    "        \n",
    "        print(f\"üíæ Performance report saved:\")\n",
    "        print(f\"   üìä {filename}.json (full data)\")\n",
    "        print(f\"   üìã {filename}.csv (articles)\")  \n",
    "        print(f\"   üìù {filename}_summary.txt (summary)\")\n",
    "\n",
    "class APIUsageTracker:\n",
    "    \"\"\"\n",
    "    Track API usage to prevent exceeding Guardian API limits\n",
    "    Daily: 12,000 requests | Weekly: 84,000 requests\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.requests_made = 0\n",
    "        self.start_time = datetime.now()\n",
    "        self.daily_limit = 12000\n",
    "        self.session_limit = 200  # Conservative limit per session\n",
    "        \n",
    "    def log_request(self):\n",
    "        \"\"\"Log an API request\"\"\"\n",
    "        self.requests_made += 1\n",
    "        \n",
    "    def check_limits(self) -> bool:\n",
    "        \"\"\"Check if we can make more requests\"\"\"\n",
    "        if self.requests_made >= self.session_limit:\n",
    "            print(f\"‚ö†Ô∏è  Session limit reached ({self.session_limit} requests)\")\n",
    "            return False\n",
    "        return True\n",
    "    \n",
    "    def get_usage_report(self) -> Dict:\n",
    "        \"\"\"Get current usage statistics\"\"\"\n",
    "        elapsed_time = datetime.now() - self.start_time\n",
    "        \n",
    "        return {\n",
    "            'requests_made': self.requests_made,\n",
    "            'session_limit': self.session_limit,\n",
    "            'remaining_in_session': self.session_limit - self.requests_made,\n",
    "            'elapsed_time': str(elapsed_time).split('.')[0],\n",
    "            'requests_per_minute': round(self.requests_made / max(elapsed_time.total_seconds() / 60, 0.1), 2),\n",
    "            'estimated_daily_usage': min(self.requests_made * 24, self.daily_limit)\n",
    "        }\n",
    "    \n",
    "    def print_usage(self):\n",
    "        \"\"\"Print current usage statistics\"\"\"\n",
    "        stats = self.get_usage_report()\n",
    "        print(f\"\\nüìä API USAGE STATISTICS:\")\n",
    "        print(f\"   ‚Ä¢ Requests made: {stats['requests_made']}\")\n",
    "        print(f\"   ‚Ä¢ Session remaining: {stats['remaining_in_session']}\")\n",
    "        print(f\"   ‚Ä¢ Time elapsed: {stats['elapsed_time']}\")\n",
    "        print(f\"   ‚Ä¢ Rate: {stats['requests_per_minute']} requests/minute\")\n",
    "        print(f\"   ‚Ä¢ Estimated daily usage: {stats['estimated_daily_usage']}\")\n",
    "\n",
    "# Initialize global usage tracker\n",
    "usage_tracker = APIUsageTracker()\n",
    "def validate_api_key(api_key: str) -> bool:\n",
    "    \"\"\"Test if the API key is valid\"\"\"\n",
    "    test_url = \"https://content.guardianapis.com/search\"\n",
    "    test_params = {'api-key': api_key, 'q': 'test', 'page-size': 1}\n",
    "    \n",
    "    try:\n",
    "        response = requests.get(test_url, params=test_params)\n",
    "        if response.status_code == 200:\n",
    "            print(\"‚úÖ API key is valid!\")\n",
    "            return True\n",
    "        elif response.status_code == 401:\n",
    "            print(\"‚ùå Invalid API key - get your free key at: https://open-platform.theguardian.com/access/\")\n",
    "            return False\n",
    "        else:\n",
    "            print(f\"‚ö†Ô∏è  API returned status: {response.status_code}\")\n",
    "            return False\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error testing API key: {e}\")\n",
    "        return False\n",
    "\n",
    "# Main execution\n",
    "def main():\n",
    "    \"\"\"\n",
    "    Real Madrid Performance Analysis - Main Function\n",
    "    \"\"\"\n",
    "    \n",
    "    print(\"‚öΩ REAL MADRID PERFORMANCE ANALYZER\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    # Set your Guardian API key here\n",
    "    API_KEY = \"test\"  # Replace with your real Guardian API key\n",
    "    \n",
    "    # Validate API key\n",
    "    if not validate_api_key(API_KEY):\n",
    "        print(\"\\nüîë Get your FREE Guardian API key:\")\n",
    "        print(\"   1. Go to: https://open-platform.theguardian.com/access/\")\n",
    "        print(\"   2. Register (takes 2 minutes)\")\n",
    "        print(\"   3. Replace 'test' with your real API key\")\n",
    "        return\n",
    "    \n",
    "    # Initialize the performance analyzer\n",
    "    rm_performance = RealMadridPerformanceAPI(API_KEY)\n",
    "    \n",
    "# Example 1: Comprehensive Performance Report\n",
    "    print(f\"\\nüèÜ Generating Comprehensive Performance Report...\")\n",
    "    report = rm_performance.generate_performance_report(days_back=7)  # Shorter period to save API calls\n",
    "    \n",
    "    if report:\n",
    "        # Save the report\n",
    "        rm_performance.save_performance_report(report)\n",
    "        \n",
    "        # Display key findings\n",
    "        print(f\"\\nüìà KEY FINDINGS:\")\n",
    "        print(f\"   ‚Ä¢ Total articles analyzed: {report['total_articles']}\")\n",
    "        print(f\"   ‚Ä¢ API requests used: {report.get('api_usage', {}).get('requests_made', 'N/A')}\")\n",
    "        \n",
    "        if report.get('most_mentioned_players'):\n",
    "            top_player = list(report['most_mentioned_players'].keys())[0]\n",
    "            top_mentions = list(report['most_mentioned_players'].values())[0]\n",
    "            print(f\"   ‚Ä¢ Most mentioned player: {top_player} ({top_mentions} mentions)\")\n",
    "        \n",
    "        if report.get('content_types'):\n",
    "            top_content = max(report['content_types'], key=report['content_types'].get)\n",
    "            print(f\"   ‚Ä¢ Primary content type: {top_content}\")\n",
    "        \n",
    "        print(f\"   ‚Ä¢ Match analysis articles: {report.get('articles_with_results', 0)}\")\n",
    "        print(f\"   ‚Ä¢ Performance statistics: {report.get('articles_with_stats', 0)}\")\n",
    "        print(f\"   ‚Ä¢ Injury updates: {report.get('injury_articles', 0)}\")\n",
    "    \n",
    "    # Example 2: Specific Player Analysis (if API usage allows)\n",
    "    if usage_tracker.check_limits():\n",
    "        print(f\"\\nüë§ Analyzing Specific Player Performance...\")\n",
    "        player_articles = rm_performance.get_player_performance(\"Bellingham\", days_back=14, max_articles_per_query=10)\n",
    "        \n",
    "        if player_articles:\n",
    "            player_df = rm_performance.extract_performance_data(player_articles)\n",
    "            print(f\"   ‚Ä¢ Found {len(player_df)} articles about Bellingham\")\n",
    "            \n",
    "            # Show recent headlines\n",
    "            for i, row in player_df.head(3).iterrows():\n",
    "                print(f\"   üì∞ {row['title'][:70]}...\")\n",
    "    \n",
    "    # Example 3: Quick Match Results (minimal API usage)\n",
    "    if usage_tracker.check_limits():\n",
    "        print(f\"\\n‚öΩ Recent Match Performance...\")\n",
    "        match_articles = rm_performance.get_match_performance(days_back=7, max_articles_per_query=15)\n",
    "        \n",
    "        if match_articles:\n",
    "            match_df = rm_performance.extract_performance_data(match_articles)\n",
    "            match_reports = match_df[match_df['content_type'] == 'Match Analysis']\n",
    "            \n",
    "            print(f\"   ‚Ä¢ Found {len(match_reports)} match analysis articles\")\n",
    "            for i, row in match_reports.head(2).iterrows():\n",
    "                print(f\"   üèÜ {row['title']}\")\n",
    "    \n",
    "    # Example 4: La Liga Weekly Focus (NEW FEATURE)\n",
    "    if usage_tracker.check_limits():\n",
    "        print(f\"\\nüá™üá∏ La Liga Weekly Performance Analysis...\")\n",
    "        \n",
    "        # Specialized La Liga queries for weekly reliability\n",
    "        la_liga_params = {\n",
    "            'api-key': API_KEY,\n",
    "            'q': 'Real Madrid AND \"La Liga\" AND (performance OR result OR standings)',\n",
    "            'section': 'football',\n",
    "            'from-date': (datetime.now() - timedelta(days=7)).strftime('%Y-%m-%d'),\n",
    "            'page-size': 10,\n",
    "            'show-fields': 'headline,byline,body,thumbnail,publication',\n",
    "            'order-by': 'newest'\n",
    "        }\n",
    "        \n",
    "        try:\n",
    "            print(f\"   üîç Searching La Liga specific coverage...\")\n",
    "            la_liga_response = requests.get(f\"https://content.guardianapis.com/search\", params=la_liga_params)\n",
    "            la_liga_response.raise_for_status()\n",
    "            usage_tracker.log_request()\n",
    "            \n",
    "            la_liga_articles = la_liga_response.json()['response']['results']\n",
    "            filtered_la_liga = rm_performance._filter_real_madrid_content(la_liga_articles)\n",
    "            \n",
    "            if filtered_la_liga:\n",
    "                la_liga_df = rm_performance.extract_performance_data(filtered_la_liga)\n",
    "                print(f\"   ‚Ä¢ Found {len(la_liga_df)} La Liga articles\")\n",
    "                \n",
    "                # La Liga specific analysis\n",
    "                la_liga_stats = la_liga_df[la_liga_df['competition'] == 'La Liga']\n",
    "                print(f\"   üìä La Liga tagged articles: {len(la_liga_stats)}\")\n",
    "                print(f\"   üìà With performance stats: {la_liga_stats['contains_stats'].sum()}\")\n",
    "                print(f\"   ‚≠ê With player ratings: {la_liga_stats['contains_player_ratings'].sum()}\")\n",
    "                \n",
    "                # Recent La Liga headlines\n",
    "                for i, row in la_liga_df.head(2).iterrows():\n",
    "                    print(f\"   üì∞ {row['title'][:60]}...\")\n",
    "            \n",
    "            time.sleep(rm_performance.rate_limit_delay)\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"   ‚ùå Error getting La Liga data: {e}\")\n",
    "    \n",
    "    # Example 5: Competition Comparison Analysis\n",
    "    if usage_tracker.check_limits() and report and 'all_articles' in report:\n",
    "        print(f\"\\nüèÜ Competition Performance Comparison...\")\n",
    "        \n",
    "        if len(report['all_articles']) > 0:\n",
    "            df = pd.DataFrame(report['all_articles'])\n",
    "            \n",
    "            # Competition breakdown analysis\n",
    "            competitions = ['La Liga', 'Champions League', 'Copa del Rey', 'General']\n",
    "            comp_analysis = {}\n",
    "            \n",
    "            for comp in competitions:\n",
    "                comp_articles = df[df['competition'] == comp]\n",
    "                if len(comp_articles) > 0:\n",
    "                    comp_analysis[comp] = {\n",
    "                        'total_articles': len(comp_articles),\n",
    "                        'with_stats': comp_articles['contains_stats'].sum(),\n",
    "                        'with_ratings': comp_articles['contains_player_ratings'].sum(),\n",
    "                        'match_results': comp_articles['contains_match_result'].sum(),\n",
    "                        'reliability_score': len(comp_articles) * 0.3 + comp_articles['contains_stats'].sum() * 0.4 + comp_articles['contains_player_ratings'].sum() * 0.3\n",
    "                    }\n",
    "            \n",
    "            print(f\"   üìä COMPETITION ANALYSIS (7 days):\")\n",
    "            for comp, stats in sorted(comp_analysis.items(), key=lambda x: x[1]['reliability_score'], reverse=True):\n",
    "                reliability = \"HIGH\" if stats['reliability_score'] > 5 else \"MEDIUM\" if stats['reliability_score'] > 2 else \"LOW\"\n",
    "                print(f\"   üèÜ {comp}: {stats['total_articles']} articles | Reliability: {reliability}\")\n",
    "                print(f\"      üìà Stats: {stats['with_stats']} | Ratings: {stats['with_ratings']} | Results: {stats['match_results']}\")\n",
    "            \n",
    "            # Weekly data reliability insight\n",
    "            la_liga_count = comp_analysis.get('La Liga', {}).get('total_articles', 0)\n",
    "            ucl_count = comp_analysis.get('Champions League', {}).get('total_articles', 0)\n",
    "            \n",
    "            if la_liga_count > ucl_count:\n",
    "                print(f\"   ‚úÖ La Liga shows better weekly coverage ({la_liga_count} vs {ucl_count} articles)\")\n",
    "            elif ucl_count > 0:\n",
    "                print(f\"   ‚ö†Ô∏è  Champions League active this week ({ucl_count} articles)\")\n",
    "            else:\n",
    "                print(f\"   üìÖ Off-season for European competitions - La Liga primary source\")\n",
    "    \n",
    "    # Example 6: Player Performance Trends\n",
    "    if usage_tracker.check_limits():\n",
    "        print(f\"\\nüåü Key Player Performance Trends...\")\n",
    "        \n",
    "        # Focus on current key players\n",
    "        key_players = [\"Bellingham\", \"Vin√≠cius\", \"Mbapp√©\", \"Modriƒá\", \"Courtois\"]\n",
    "        player_mentions = {}\n",
    "        \n",
    "        if report and 'all_articles' in report and len(report['all_articles']) > 0:\n",
    "            df = pd.DataFrame(report['all_articles'])\n",
    "            \n",
    "            for player in key_players:\n",
    "                mentions = 0\n",
    "                for _, row in df.iterrows():\n",
    "                    if player in row.get('mentioned_players', []):\n",
    "                        mentions += 1\n",
    "                if mentions > 0:\n",
    "                    player_mentions[player] = mentions\n",
    "            \n",
    "            if player_mentions:\n",
    "                sorted_players = sorted(player_mentions.items(), key=lambda x: x[1], reverse=True)\n",
    "                print(f\"   üëë MOST COVERED PLAYERS (this week):\")\n",
    "                for player, count in sorted_players[:3]:\n",
    "                    print(f\"      üåü {player}: {count} article mentions\")\n",
    "    \n",
    "    # Final comprehensive usage report\n",
    "    print(f\"\\n\" + \"=\"*60)\n",
    "    print(\"üìä FINAL ANALYSIS SUMMARY\")\n",
    "    usage_tracker.print_usage()\n",
    "    \n",
    "    remaining = usage_tracker.session_limit - usage_tracker.requests_made\n",
    "    print(f\"\\nüí° SESSION SUMMARY:\")\n",
    "    print(f\"   ‚Ä¢ Requests remaining: {remaining}\")\n",
    "    print(f\"   ‚Ä¢ Daily Guardian limit: 12,000 requests\")\n",
    "    print(f\"   ‚Ä¢ Weekly Guardian limit: 84,000 requests\")\n",
    "    \n",
    "    # Performance quality assessment\n",
    "    if report and 'total_articles' in report:\n",
    "        efficiency = report['total_articles'] / max(usage_tracker.requests_made, 1)\n",
    "        \n",
    "        if report['total_articles'] > 25:\n",
    "            print(f\"   ‚úÖ EXCELLENT data collection: {report['total_articles']} articles\")\n",
    "        elif report['total_articles'] > 15:\n",
    "            print(f\"   üëç GOOD data collection: {report['total_articles']} articles\")\n",
    "        elif report['total_articles'] > 5:\n",
    "            print(f\"   ‚ö†Ô∏è  MODERATE data collection: {report['total_articles']} articles\")\n",
    "        else:\n",
    "            print(f\"   ‚ùå LIMITED data collection: {report['total_articles']} articles\")\n",
    "        \n",
    "        print(f\"   üìà API efficiency: {efficiency:.1f} articles per request\")\n",
    "        \n",
    "        # Recommendations\n",
    "        if efficiency < 0.5:\n",
    "            print(f\"   üí° TIP: Try longer time periods or broader search terms\")\n",
    "        elif efficiency > 1.0:\n",
    "            print(f\"   üéØ OPTIMAL: Great API efficiency achieved!\")\n",
    "    \n",
    "    print(f\"\\nüèÅ Real Madrid Performance Analysis Complete!\")\n",
    "    print(f\"üìã Reports saved with timestamp for future reference\")\n",
    "\n",
    "# Additional utility functions\n",
    "def quick_la_liga_check(api_key: str, days: int = 3):\n",
    "    \"\"\"Quick La Liga reliability check\"\"\"\n",
    "    print(f\"üá™üá∏ QUICK LA LIGA RELIABILITY CHECK ({days} days)\")\n",
    "    print(\"-\" * 45)\n",
    "    \n",
    "    if not validate_api_key(api_key):\n",
    "        return\n",
    "    \n",
    "    params = {\n",
    "        'api-key': api_key,\n",
    "        'q': 'Real Madrid AND \"La Liga\"',\n",
    "        'section': 'football',\n",
    "        'from-date': (datetime.now() - timedelta(days=days)).strftime('%Y-%m-%d'),\n",
    "        'page-size': 15,\n",
    "        'show-fields': 'headline,publication',\n",
    "        'order-by': 'newest'\n",
    "    }\n",
    "    \n",
    "    try:\n",
    "        response = requests.get(\"https://content.guardianapis.com/search\", params=params)\n",
    "        response.raise_for_status()\n",
    "        \n",
    "        articles = response.json()['response']['results']\n",
    "        \n",
    "        print(f\"‚úÖ Found {len(articles)} La Liga articles in {days} days\")\n",
    "        print(f\"üìä Average: {len(articles)/days:.1f} articles per day\")\n",
    "        \n",
    "        if len(articles) > days * 2:\n",
    "            print(f\"üéØ EXCELLENT weekly La Liga coverage reliability\")\n",
    "        elif len(articles) > days:\n",
    "            print(f\"üëç GOOD weekly La Liga coverage\")\n",
    "        else:\n",
    "            print(f\"‚ö†Ô∏è  LIMITED La Liga coverage this period\")\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error: {e}\")\n",
    "\n",
    "def competition_schedule_info():\n",
    "    \"\"\"Show current competition schedule context\"\"\"\n",
    "    print(f\"\\nüìÖ CURRENT FOOTBALL SEASON CONTEXT:\")\n",
    "    print(f\"   üìç Date: {datetime.now().strftime('%B %d, %Y')}\")\n",
    "    \n",
    "    month = datetime.now().month\n",
    "    \n",
    "    if month in [8, 9, 10, 11, 12, 1, 2, 3, 4, 5]:\n",
    "        print(f\"   üá™üá∏ La Liga: ACTIVE SEASON (Weekly matches)\")\n",
    "        if month in [9, 10, 11, 12, 2, 3, 4, 5]:\n",
    "            print(f\"   üèÜ Champions League: ACTIVE (Tournament phase)\")\n",
    "        else:\n",
    "            print(f\"   üèÜ Champions League: Off-season\")\n",
    "    else:\n",
    "        print(f\"   üèñÔ∏è  Off-season: Pre-season friendlies only\")\n",
    "    \n",
    "    print(f\"   üí° RECOMMENDATION: Use La Liga data for weekly analysis\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Show season context\n",
    "    competition_schedule_info()\n",
    "    \n",
    "    # Run main analysis\n",
    "    main()\n",
    "    \n",
    "    # Optional quick checks\n",
    "    print(f\"\\n\" + \"=\"*60)\n",
    "    print(\"üîß OPTIONAL QUICK CHECKS:\")\n",
    "    print(\"1. quick_la_liga_check(API_KEY, days=3)\")\n",
    "    print(\"2. demo_pagination_control()\")\n",
    "    print(\"3. demo_weekly_analysis()\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
